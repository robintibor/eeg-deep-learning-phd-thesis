{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## old, copied"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "|Study |  Decoding problem |External Baseline|\n",
    "| :--- | --- | --- |\n",
    "| This manuscript, Schirrmeister et. al (2017) |Imagined and executed movement classes, within subject |FBCSP + rLDA|\n",
    "| Single-trial EEG classification of motor imagery using deep convolutional neural networks, citet{tang_single-trial_2017} |Imagined movement classes, within-subject | FBCSP ||\n",
    "| EEGNet: A Compact Convolutional Network for EEG-based Brain-Computer Interfaces, {cite}`lawhern_eegnet:_2016` | Oddball response (RSVP), error response (ERN), movement classes (voluntarily started and imagined) | [recheck] |\n",
    "| Remembered or Forgotten? –- An EEG-Based Computational Prediction Approach, {cite}`sun_remembered_2016` | Memory performance, within-subject ||\n",
    "|Multimodal Neural Network for Rapid Serial Visual Presentation Brain Computer Interface, {cite}`manor_multimodal_2016`|Oddball response using RSVP and image (combined image-EEG decoding), within-subject|Time, 0.3–20 Hz | 3/2 | | |  | Weights <br> Activations <br> Saliency maps by gradient |Weights showed typical P300 distribution <br>Activations were high at plausible times (300-500ms) <br>Saliency maps showed plausible spatio-temporal plots\n",
    "| A novel deep learning approach for classification of EEG motor imagery signals, {cite}`tabar_novel_2017` |Imagined and executed movement classes, within-subject |Frequency, 6–30 Hz | 1/1 | multicolumn{2}{p{0.285\textwidth}}{Addition of six-layer stacked autoencoder on ConvNet features <br> Kernel sizes} | FBCSP, Twin SVM, DDFBS, Bi-spectrum, RQNN  | Weights (spatial + frequential) |Some weights represented difference of values of two electrodes on different sides of head\n",
    "| Predicting Seizures from Electroencephalography Recordings: A Knowledge Transfer Strategy, {cite}`liang_predicting_2016` |Seizure prediction, within-subject | Frequency, 0–200 Hz | 1/2 | | Different subdivisions of frequency range <br>Different lengths of time crops <br>Transfer learning with auxiliary non-epilepsy datasets || Weights <br> Clustering of weights |Clusters of weights showed typical frequency band subdivision (delta, theta, alpha, beta, gamma)\n",
    "| EEG-based prediction of driver's cognitive performance by deep convolutional neural network, {cite}`hajinoroozi_eeg-based_2016` |Driver performance, within- and cross-subject |Time,  1–50 Hz | 1/3 |multicolumn{2}{p{0.285\textwidth}}{Replacement of convolutional layers by restricted Boltzmann machines with slightly varied network architecture}  | |\n",
    "| Deep learning for epileptic intracranial EEG data, {cite}`antoniades_deep_2016` |Epileptic discharges, cross-subject | Time,  0–100 HZ | 1–2/2 | 1 or 2 convolutional layers |  | |Weights <br>Correlation weights and interictal epileptic discharges (IED) <br>Activations |Weights increasingly correlated with IED waveforms with increasing number of training iterations <br>Second layer captured more complex and well-defined epileptic shapes than first layer <br>IEDs led to highly synchronized activations for neighbouring electrodes\n",
    "| Learning Robust Features using Deep Learning for Automatic Seizure Detection, {cite}`thodoroff_learning_2016` |Start of epileptic seizure, within- and cross-subject |Frequency, mean amplitude for 0–7 Hz, 7–14 Hz, 14–49 Hz | 3/1 (+ LSTM as postprocessor) | | | Hand crafted features + SVM | Input occlusion and effect on prediction accuracy |Allowed to locate areas critical for seizure \n",
    "|Single-trial EEG RSVP classification using convolutional neural networks, {cite}`george_single-trial_2016` |Oddball response (RSVP), groupwise (ConvNet trained on all subjects) |Time, 0.5–50 Hz | 4/3 | |  |  |Weights (spatial) |Some filter weights had expected topographic distributions for P300 <br>Others filters had large weights on areas not traditionally associated with P300\n",
    "|Wearable seizure detection using convolutional neural networks with transfer learning, {cite}`page_wearable_2016` |Seizure detection, cross-subject, within-subject, groupwise |Time,  0–128 Hz | 1-3/1-3 | | Cross-subject supervised training, within-subject finetuning of fully connected layers |Multiple: spectral features, higher order statistics + linear-SVM, RBF-SVM, ...| | \n",
    "|Learning Representations from EEG with Deep Recurrent-Convolutional Neural Networks, {cite}`bashivan_learning_2016`  |Cognitive load (number of characters to memorize), cross-subject | Frequency, mean power for 4–7 Hz, 8–13 Hz, 13–30 Hz | 3–7/2 (+ LSTM or other temporal post-processing (see design choices)) |Number of convolutional layers <br>Temporal processing of ConvNet output by max pooling, temporal convolution, LSTM or temporal convolution + LSTM | | |Inputs that maximally activate given filter <br>Activations of these inputs <br>\"Deconvolution\" for these inputs |Different filters were sensitive to different frequency bands <br>Later layers had more spatially localized activations <br>Learned features had noticeable links to well-known electrophysiological markers of cognitive load <br>\n",
    "|Deep Feature Learning for EEG Recordings, {cite}`stober_learning_2016` |Type of music rhythm, groupwise (ensembles of leave-one-subject-out trained models, evaluated on separate test set of same subjects) |Time, 0.5–30Hz | 2/1 | Kernel sizes | Pretraining first layer as convolutional autoencoder with different constraints |  | Weights (spatial+3 timesteps, pretrained as autoencoder) | Different constraints led to different weights, one type of constraints could enforce weights that are similar across subjects; other type of constraints led to weights that have similar spatial topographies under different architectural configurations and preprocessings\n",
    "|Convolutional Neural Network for Multi-Category Rapid Serial Visual Presentation BCI, {cite}`manor_convolutional_2015` |Oddball response (RSVP), within-subject |Time, 0.1–50 Hz | 3/3 (Spatio-temporal regularization) || ||Weights <br> Mean and single-trial activations |Spatiotemporal regularization led to softer peaks in weights <br>Spatial weights showed typical P300 distribution <br>Activations mostly had peaks at typical times (300-400ms)\n",
    "|Parallel Convolutional-Linear Neural Network for Motor Imagery Classification, {cite}`sakhavi_parallel_2015`  |Imagined movement classes, within-subject |Frequency, 4–40 Hz, using FBCSP | 2/2 (Final fully connected layer uses concatenated output by convolutionaland fully connected layers) |Combination ConvNet and MLP (trained on different features) vs. only ConvNet vs. only MLP | | | | \n",
    "|Using Convolutional Neural networks to Recognize Rhythm Stimuli form Electroencephalography Recordings, {cite}`stober_using_2014` |Type of music rhythm, within-subject | Time and frequency evaluated, 0-200 Hz | 1-2/1 |Best values from automatic hyperparameter optimization: frequency cutoff, one vs two layers, kernel sizes, number of channels, pooling width |Best values from automatic hyperparameter optimization: learning rate, learning rate decay, momentum, final momentum ||\n",
    "|Convolutional deep belief networks for feature extraction of EEG signal, {cite}`ren_convolutional_2014`  |Imagined movement classes, within-subject |Frequency, 8–30 Hz |2/0 (Convolutional deep belief network, separately trained RBF-SVM classifier) | | \n",
    "|Deep feature learning using target priors with applications in ECoG signal decoding for BCI, {cite}`wang_deep_2013`  |Finger flexion trajectory (regression), within-subject |Time, 0.15–200 Hz | 3/1 (Convolutional layers trained as convolutional stacked autoencoder with target prior) |Partially supervised CSA | \n",
    "|Convolutional neural networks for P300 detection with application to brain-computer interfaces, {cite}`cecotti_convolutional_2011`  |Oddball / attention response using P300 speller, within-subject | Time, 0.1-20 Hz | 2/2 |Electrode subset (fixed or automatically determined) <br>Using only one spatial filter <br>Different ensembling strategies | |Multiple: Linear SVM, gradient boosting, E-SVM, S-SVM, mLVQ, LDA, ... |Weights |Spatial filters were similar for different architectures <br>Spatial filters were different (more focal, more diffuse) for different subjects\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "|Study |  Decoding problem |  Input domain |  Conv/dense layers |  Design choices |  Training strategies |  External baseline |  Visualization type(s) |  Visualization findings|\n",
    "| :--- | --- | --- | --- | --- | --- | --- | --- | --- | \n",
    "| This manuscript, Schirrmeister et. al (2017) |Imagined and executed movement classes, within subject |Time,  0–125 Hz | 5/1 |Different ConvNet architectures <br>Nonlinearities and pooling modes <br>Regularization and intermediate normalization layers <br>Factorized convolutions <br>Splitted vs one-step convolutions |Trial-wise vs. cropped training strategy |FBCSP + rLDA | Feature activation correlation <br>Feature-perturbation prediction correlation |See Section \\ref{subsec:results-visualization}\n",
    "| Single-trial EEG classification of motor imagery using deep convolutional neural networks, citet{tang_single-trial_2017} |Imagined movement classes, within-subject |Time,  8–30 Hz | 2/2 | | | FBCSP | | |\n",
    "| EEGNet: A Compact Convolutional Network for EEG-based Brain-Computer Interfaces, {cite}`lawhern_eegnet:_2016` | Oddball response (RSVP), error response (ERN), movement classes (voluntarily started and imagined) |Time, 0.1–40 Hz | 3/1 |  Kernel sizes | |   | |\n",
    "| Remembered or Forgotten? –- An EEG-Based Computational Prediction Approach, {cite}`sun_remembered_2016` | Memory performance, within-subject |Time, 0.05–15 Hz | 2/2 | | Different time windows |  |Weights (spatial) | Largest weights found over p\\refrontal and temporal cortex\n",
    "|Multimodal Neural Network for Rapid Serial Visual Presentation Brain Computer Interface, {cite}`manor_multimodal_2016`|Oddball response using RSVP and image (combined image-EEG decoding), within-subject|Time, 0.3–20 Hz | 3/2 | | |  | Weights <br> Activations <br> Saliency maps by gradient |Weights showed typical P300 distribution <br>Activations were high at plausible times (300-500ms) <br>Saliency maps showed plausible spatio-temporal plots\n",
    "| A novel deep learning approach for classification of EEG motor imagery signals, {cite}`tabar_novel_2017` |Imagined and executed movement classes, within-subject |Frequency, 6–30 Hz | 1/1 | multicolumn{2}{p{0.285\textwidth}}{Addition of six-layer stacked autoencoder on ConvNet features <br> Kernel sizes} | FBCSP, Twin SVM, DDFBS, Bi-spectrum, RQNN  | Weights (spatial + frequential) |Some weights represented difference of values of two electrodes on different sides of head\n",
    "| Predicting Seizures from Electroencephalography Recordings: A Knowledge Transfer Strategy, {cite}`liang_predicting_2016` |Seizure prediction, within-subject | Frequency, 0–200 Hz | 1/2 | | Different subdivisions of frequency range <br>Different lengths of time crops <br>Transfer learning with auxiliary non-epilepsy datasets || Weights <br> Clustering of weights |Clusters of weights showed typical frequency band subdivision (delta, theta, alpha, beta, gamma)\n",
    "| EEG-based prediction of driver's cognitive performance by deep convolutional neural network, {cite}`hajinoroozi_eeg-based_2016` |Driver performance, within- and cross-subject |Time,  1–50 Hz | 1/3 |multicolumn{2}{p{0.285\textwidth}}{Replacement of convolutional layers by restricted Boltzmann machines with slightly varied network architecture}  | |\n",
    "| Deep learning for epileptic intracranial EEG data, {cite}`antoniades_deep_2016` |Epileptic discharges, cross-subject | Time,  0–100 HZ | 1–2/2 | 1 or 2 convolutional layers |  | |Weights <br>Correlation weights and interictal epileptic discharges (IED) <br>Activations |Weights increasingly correlated with IED waveforms with increasing number of training iterations <br>Second layer captured more complex and well-defined epileptic shapes than first layer <br>IEDs led to highly synchronized activations for neighbouring electrodes\n",
    "| Learning Robust Features using Deep Learning for Automatic Seizure Detection, {cite}`thodoroff_learning_2016` |Start of epileptic seizure, within- and cross-subject |Frequency, mean amplitude for 0–7 Hz, 7–14 Hz, 14–49 Hz | 3/1 (+ LSTM as postprocessor) | | | Hand crafted features + SVM | Input occlusion and effect on prediction accuracy |Allowed to locate areas critical for seizure \n",
    "|Single-trial EEG RSVP classification using convolutional neural networks, {cite}`george_single-trial_2016` |Oddball response (RSVP), groupwise (ConvNet trained on all subjects) |Time, 0.5–50 Hz | 4/3 | |  |  |Weights (spatial) |Some filter weights had expected topographic distributions for P300 <br>Others filters had large weights on areas not traditionally associated with P300\n",
    "|Wearable seizure detection using convolutional neural networks with transfer learning, {cite}`page_wearable_2016` |Seizure detection, cross-subject, within-subject, groupwise |Time,  0–128 Hz | 1-3/1-3 | | Cross-subject supervised training, within-subject finetuning of fully connected layers |Multiple: spectral features, higher order statistics + linear-SVM, RBF-SVM, ...| | \n",
    "|Learning Representations from EEG with Deep Recurrent-Convolutional Neural Networks, {cite}`bashivan_learning_2016`  |Cognitive load (number of characters to memorize), cross-subject | Frequency, mean power for 4–7 Hz, 8–13 Hz, 13–30 Hz | 3–7/2 (+ LSTM or other temporal post-processing (see design choices)) |Number of convolutional layers <br>Temporal processing of ConvNet output by max pooling, temporal convolution, LSTM or temporal convolution + LSTM | | |Inputs that maximally activate given filter <br>Activations of these inputs <br>\"Deconvolution\" for these inputs |Different filters were sensitive to different frequency bands <br>Later layers had more spatially localized activations <br>Learned features had noticeable links to well-known electrophysiological markers of cognitive load <br>\n",
    "|Deep Feature Learning for EEG Recordings, {cite}`stober_learning_2016` |Type of music rhythm, groupwise (ensembles of leave-one-subject-out trained models, evaluated on separate test set of same subjects) |Time, 0.5–30Hz | 2/1 | Kernel sizes | Pretraining first layer as convolutional autoencoder with different constraints |  | Weights (spatial+3 timesteps, pretrained as autoencoder) | Different constraints led to different weights, one type of constraints could enforce weights that are similar across subjects; other type of constraints led to weights that have similar spatial topographies under different architectural configurations and preprocessings\n",
    "|Convolutional Neural Network for Multi-Category Rapid Serial Visual Presentation BCI, {cite}`manor_convolutional_2015` |Oddball response (RSVP), within-subject |Time, 0.1–50 Hz | 3/3 (Spatio-temporal regularization) || ||Weights <br> Mean and single-trial activations |Spatiotemporal regularization led to softer peaks in weights <br>Spatial weights showed typical P300 distribution <br>Activations mostly had peaks at typical times (300-400ms)\n",
    "|Parallel Convolutional-Linear Neural Network for Motor Imagery Classification, {cite}`sakhavi_parallel_2015`  |Imagined movement classes, within-subject |Frequency, 4–40 Hz, using FBCSP | 2/2 (Final fully connected layer uses concatenated output by convolutionaland fully connected layers) |Combination ConvNet and MLP (trained on different features) vs. only ConvNet vs. only MLP | | | | \n",
    "|Using Convolutional Neural networks to Recognize Rhythm Stimuli form Electroencephalography Recordings, {cite}`stober_using_2014` |Type of music rhythm, within-subject | Time and frequency evaluated, 0-200 Hz | 1-2/1 |Best values from automatic hyperparameter optimization: frequency cutoff, one vs two layers, kernel sizes, number of channels, pooling width |Best values from automatic hyperparameter optimization: learning rate, learning rate decay, momentum, final momentum ||\n",
    "|Convolutional deep belief networks for feature extraction of EEG signal, {cite}`ren_convolutional_2014`  |Imagined movement classes, within-subject |Frequency, 8–30 Hz |2/0 (Convolutional deep belief network, separately trained RBF-SVM classifier) | | \n",
    "|Deep feature learning using target priors with applications in ECoG signal decoding for BCI, {cite}`wang_deep_2013`  |Finger flexion trajectory (regression), within-subject |Time, 0.15–200 Hz | 3/1 (Convolutional layers trained as convolutional stacked autoencoder with target prior) |Partially supervised CSA | \n",
    "|Convolutional neural networks for P300 detection with application to brain-computer interfaces, {cite}`cecotti_convolutional_2011`  |Oddball / attention response using P300 speller, within-subject | Time, 0.1-20 Hz | 2/2 |Electrode subset (fixed or automatically determined) <br>Using only one spatial filter <br>Different ensembling strategies | |Multiple: Linear SVM, gradient boosting, E-SVM, S-SVM, mLVQ, LDA, ... |Weights |Spatial filters were similar for different architectures <br>Spatial filters were different (more focal, more diffuse) for different subjects\n",
    "|  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| This manuscript, Schirrmeister et. al (2017) |Imagined and executed movement classes, within subject |Time,  0–125 Hz | 5/1 |Different ConvNet architectures <br>Nonlinearities and pooling modes <br>Regularization and intermediate normalization layers <br>Factorized convolutions <br>Splitted vs one-step convolutions |Trial-wise vs. cropped training strategy |FBCSP + rLDA | Feature activation correlation <br>Feature-perturbation prediction correlation |See Section \\ref{subsec:results-visualization}\n",
      "| Single-trial EEG classification of motor imagery using deep convolutional neural networks, citet{tang_single-trial_2017} |Imagined movement classes, within-subject |Time,  8–30 Hz | 2/2 | | | FBCSP | | |\n"
     ]
    }
   ],
   "source": [
    "a = r\"\"\"\n",
    "This manuscript, Schirrmeister et. al (2017) &\n",
    "Imagined and executed movement classes, within subject &\n",
    "Time, \\hspace{1cm} 0--125 Hz & 5/1 &\n",
    "Different ConvNet architectures \\cellbr\n",
    "Nonlinearities and pooling modes \\cellbr\n",
    "Regularization and intermediate normalization layers \\cellbr\n",
    "Factorized convolutions \\cellbr\n",
    "Splitted vs one-step convolutions &\n",
    "Trial-wise vs. cropped training strategy &\n",
    "FBCSP + rLDA & \n",
    "Feature activation correlation \\cellbr\n",
    "Feature-perturbation prediction correlation &\n",
    "See Section \\ref{subsec:results-visualization}\n",
    "\\\\\n",
    "\\hdashline \n",
    "\n",
    "Single-trial EEG classification of motor imagery using deep convolutional neural networks, \\citet{tang_single-trial_2017} &\n",
    "Imagined movement classes, within-subject &\n",
    "Time, \\hspace{1cm} 8--30 Hz & 2/2 & & \n",
    "& FBCSP & &\"\"\"\n",
    "\n",
    "b = a.replace(\"&\", \"|\").replace(\"\\n\", \"\").replace(\"\\cellbr\", \"<br>\").replace('\\hdashline', '\\n|').replace('\\\\', '')\n",
    "b = b.replace(\"ref\", r\"\\ref\").replace(\"--\", '–')\n",
    "b = re.sub(r'hspace{[^}]+}', r'', b)\n",
    "b = \"| \" + b + \" |\"\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| EEGNet: A Compact Convolutional Network for EEG-based Brain-Computer Interfaces, {cite}`lawhern_eegnet:_2016` | Oddball response (RSVP), error response (ERN), movement classes (voluntarily started and imagined) |Time, 0.1–40 Hz | 3/1 |  Kernel sizes | |   | |\n",
      "| Remembered or Forgotten? –- An EEG-Based Computational Prediction Approach, {cite}`sun_remembered_2016` | Memory performance, within-subject |Time, 0.05–15 Hz | 2/2 | | Different time windows |  |Weights (spatial) | Largest weights found over p\\refrontal and temporal cortex\n",
      "|Multimodal Neural Network for Rapid Serial Visual Presentation Brain Computer Interface, {cite}`manor_multimodal_2016`|Oddball response using RSVP and image (combined image-EEG decoding), within-subject|Time, 0.3–20 Hz | 3/2 | | |  | Weights <br> Activations <br> Saliency maps by gradient |Weights showed typical P300 distribution <br>Activations were high at plausible times (300-500ms) <br>Saliency maps showed plausible spatio-temporal plots\n",
      "| A novel deep learning approach for classification of EEG motor imagery signals, {cite}`tabar_novel_2017` |Imagined and executed movement classes, within-subject |Frequency, 6–30 Hz | 1/1 | multicolumn{2}{p{0.285\textwidth}}{Addition of six-layer stacked autoencoder on ConvNet features <br> Kernel sizes} | FBCSP, Twin SVM, DDFBS, Bi-spectrum, RQNN  | Weights (spatial + frequential) |Some weights represented difference of values of two electrodes on different sides of head\n",
      "| Predicting Seizures from Electroencephalography Recordings: A Knowledge Transfer Strategy, {cite}`liang_predicting_2016` |Seizure prediction, within-subject | Frequency, 0–200 Hz | 1/2 | | Different subdivisions of frequency range <br>Different lengths of time crops <br>Transfer learning with auxiliary non-epilepsy datasets || Weights <br> Clustering of weights |Clusters of weights showed typical frequency band subdivision (delta, theta, alpha, beta, gamma)\n",
      "| EEG-based prediction of driver's cognitive performance by deep convolutional neural network, {cite}`hajinoroozi_eeg-based_2016` |Driver performance, within- and cross-subject |Time,  1–50 Hz | 1/3 |multicolumn{2}{p{0.285\textwidth}}{Replacement of convolutional layers by restricted Boltzmann machines with slightly varied network architecture}  | |\n",
      "| Deep learning for epileptic intracranial EEG data, {cite}`antoniades_deep_2016` |Epileptic discharges, cross-subject | Time,  0–100 HZ | 1–2/2 | 1 or 2 convolutional layers |  | |Weights <br>Correlation weights and interictal epileptic discharges (IED) <br>Activations |Weights increasingly correlated with IED waveforms with increasing number of training iterations <br>Second layer captured more complex and well-defined epileptic shapes than first layer <br>IEDs led to highly synchronized activations for neighbouring electrodes\n",
      "| Learning Robust Features using Deep Learning for Automatic Seizure Detection, {cite}`thodoroff_learning_2016` |Start of epileptic seizure, within- and cross-subject |Frequency, mean amplitude for 0–7 Hz, 7–14 Hz, 14–49 Hz | 3/1 (+ LSTM as postprocessor) | | | Hand crafted features + SVM | Input occlusion and effect on prediction accuracy |Allowed to locate areas critical for seizure \n",
      "|Single-trial EEG RSVP classification using convolutional neural networks, {cite}`george_single-trial_2016` |Oddball response (RSVP), groupwise (ConvNet trained on all subjects) |Time, 0.5–50 Hz | 4/3 | |  |  |Weights (spatial) |Some filter weights had expected topographic distributions for P300 <br>Others filters had large weights on areas not traditionally associated with P300\n",
      "|Wearable seizure detection using convolutional neural networks with transfer learning, {cite}`page_wearable_2016` |Seizure detection, cross-subject, within-subject, groupwise |Time,  0–128 Hz | 1-3/1-3 | | Cross-subject supervised training, within-subject finetuning of fully connected layers |Multiple: spectral features, higher order statistics + linear-SVM, RBF-SVM, ...| | \n",
      "|Learning Representations from EEG with Deep Recurrent-Convolutional Neural Networks, {cite}`bashivan_learning_2016`  |Cognitive load (number of characters to memorize), cross-subject | Frequency, mean power for 4–7 Hz, 8–13 Hz, 13–30 Hz | 3–7/2 (+ LSTM or other temporal post-processing (see design choices)) |Number of convolutional layers <br>Temporal processing of ConvNet output by max pooling, temporal convolution, LSTM or temporal convolution + LSTM | | |Inputs that maximally activate given filter <br>Activations of these inputs <br>\"Deconvolution\" for these inputs |Different filters were sensitive to different frequency bands <br>Later layers had more spatially localized activations <br>Learned features had noticeable links to well-known electrophysiological markers of cognitive load <br>\n",
      "|Deep Feature Learning for EEG Recordings, {cite}`stober_learning_2016` |Type of music rhythm, groupwise (ensembles of leave-one-subject-out trained models, evaluated on separate test set of same subjects) |Time, 0.5–30Hz | 2/1 | Kernel sizes | Pretraining first layer as convolutional autoencoder with different constraints |  | Weights (spatial+3 timesteps, pretrained as autoencoder) | Different constraints led to different weights, one type of constraints could enforce weights that are similar across subjects; other type of constraints led to weights that have similar spatial topographies under different architectural configurations and preprocessings\n",
      "|Convolutional Neural Network for Multi-Category Rapid Serial Visual Presentation BCI, {cite}`manor_convolutional_2015` |Oddball response (RSVP), within-subject |Time, 0.1–50 Hz | 3/3 (Spatio-temporal regularization) || ||Weights <br> Mean and single-trial activations |Spatiotemporal regularization led to softer peaks in weights <br>Spatial weights showed typical P300 distribution <br>Activations mostly had peaks at typical times (300-400ms)\n",
      "|Parallel Convolutional-Linear Neural Network for Motor Imagery Classification, {cite}`sakhavi_parallel_2015`  |Imagined movement classes, within-subject |Frequency, 4–40 Hz, using FBCSP | 2/2 (Final fully connected layer uses concatenated output by convolutionaland fully connected layers) |Combination ConvNet and MLP (trained on different features) vs. only ConvNet vs. only MLP | | | | \n",
      "|Using Convolutional Neural networks to Recognize Rhythm Stimuli form Electroencephalography Recordings, {cite}`stober_using_2014` |Type of music rhythm, within-subject | Time and frequency evaluated, 0-200 Hz | 1-2/1 |Best values from automatic hyperparameter optimization: frequency cutoff, one vs two layers, kernel sizes, number of channels, pooling width |Best values from automatic hyperparameter optimization: learning rate, learning rate decay, momentum, final momentum ||\n",
      "|Convolutional deep belief networks for feature extraction of EEG signal, {cite}`ren_convolutional_2014`  |Imagined movement classes, within-subject |Frequency, 8–30 Hz |2/0 (Convolutional deep belief network, separately trained RBF-SVM classifier) | | \n",
      "|Deep feature learning using target priors with applications in ECoG signal decoding for BCI, {cite}`wang_deep_2013`  |Finger flexion trajectory (regression), within-subject |Time, 0.15–200 Hz | 3/1 (Convolutional layers trained as convolutional stacked autoencoder with target prior) |Partially supervised CSA | \n",
      "|Convolutional neural networks for P300 detection with application to brain-computer interfaces, {cite}`cecotti_convolutional_2011`  |Oddball / attention response using P300 speller, within-subject | Time, 0.1-20 Hz | 2/2 |Electrode subset (fixed or automatically determined) <br>Using only one spatial filter <br>Different ensembling strategies | |Multiple: Linear SVM, gradient boosting, E-SVM, S-SVM, mLVQ, LDA, ... |Weights |Spatial filters were similar for different architectures <br>Spatial filters were different (more focal, more diffuse) for different subjects\n",
      "|  |\n"
     ]
    }
   ],
   "source": [
    "a = \"\"\"\n",
    "EEGNet: A Compact Convolutional Network for EEG-based Brain-Computer Interfaces, \\citet{lawhern_eegnet:_2016} & \n",
    "Oddball response (RSVP), error response (ERN), movement classes (voluntarily started and imagined) &\n",
    "Time, 0.1--40 Hz & 3/1 &  Kernel sizes & \n",
    "&   & &\n",
    "\\\\\n",
    "\\hdashline\n",
    " \n",
    "Remembered or Forgotten? --- An EEG-Based Computational Prediction Approach, \\citet{sun_remembered_2016} & \n",
    "Memory performance, within-subject &\n",
    "Time, 0.05--15 Hz & 2/2 & & Different time windows &  &\n",
    "Weights (spatial) & \n",
    "Largest weights found over prefrontal and temporal cortex\n",
    "\\\\\n",
    "\\hdashline\n",
    "\n",
    "Multimodal Neural Network for Rapid Serial Visual Presentation Brain Computer Interface, \\citet{manor_multimodal_2016}\n",
    "&\n",
    "Oddball response using RSVP and image (combined image-EEG decoding), within-subject&\n",
    "Time, 0.3--20 Hz & 3/2 & & &  & \n",
    "Weights \\cellbr Activations \\cellbr Saliency maps by gradient &\n",
    "Weights showed typical P300 distribution \\cellbr\n",
    "Activations were high at plausible times (300-500ms) \\cellbr\n",
    "Saliency maps showed plausible spatio-temporal plots\n",
    "\\\\\n",
    "\\hdashline\n",
    " \n",
    "A novel deep learning approach for classification of EEG motor imagery signals, \\citet{tabar_novel_2017} &\n",
    "Imagined and executed movement classes, within-subject &\n",
    "Frequency, 6--30 Hz & 1/1 & \n",
    "\\multicolumn{2}{p{0.285\\textwidth}}{Addition of six-layer stacked autoencoder on ConvNet features \\cellbr Kernel sizes} \n",
    "& FBCSP, Twin SVM, DDFBS, Bi-spectrum, RQNN  & Weights (spatial + frequential) &\n",
    "Some weights represented difference of values of two electrodes on different sides of head\n",
    "\\\\\n",
    "\\hdashline\n",
    " \n",
    "Predicting Seizures from Electroencephalography Recordings: A Knowledge Transfer Strategy, \\citet{liang_predicting_2016} &\n",
    "Seizure prediction, within-subject & Frequency, 0--200 Hz & 1/2 & & \n",
    "Different subdivisions of frequency range \\cellbr\n",
    "Different lengths of time crops \\cellbr\n",
    "Transfer learning with auxiliary non-epilepsy datasets &\n",
    "& Weights \\cellbr Clustering of weights &\n",
    "Clusters of weights showed typical frequency band subdivision (delta, theta, alpha, beta, gamma)\n",
    "\\\\\n",
    "\\hdashline\n",
    " \n",
    "EEG-based prediction of driver's cognitive performance by deep convolutional neural network, \\citet{hajinoroozi_eeg-based_2016} &\n",
    "Driver performance, within- and cross-subject &\n",
    "Time, \\hspace{1cm} 1--50 Hz & 1/3 &\n",
    "\\multicolumn{2}{p{0.285\\textwidth}}{Replacement of convolutional layers by restricted Boltzmann machines with slightly varied network architecture}  & \n",
    "&\n",
    "\\\\\n",
    "\\hdashline\n",
    " \n",
    "Deep learning for epileptic intracranial EEG data, \\citet{antoniades_deep_2016} &\n",
    "Epileptic discharges, cross-subject & Time, \\hspace{1cm} 0--100 HZ & 1--2/2 & 1 or 2 convolutional layers &  & &\n",
    "Weights \\cellbr\n",
    "Correlation weights and interictal epileptic discharges (IED) \\cellbr\n",
    "Activations &\n",
    "Weights increasingly correlated with IED waveforms with increasing number of training iterations \\cellbr\n",
    "Second layer captured more complex and well-defined epileptic shapes than first layer \\cellbr\n",
    "IEDs led to highly synchronized activations for neighbouring electrodes\n",
    "\\\\\n",
    "\\hdashline\n",
    " \n",
    "Learning Robust Features using Deep Learning for Automatic Seizure Detection, \\citet{thodoroff_learning_2016} &\n",
    "Start of epileptic seizure, within- and cross-subject &\n",
    "Frequency, mean amplitude for 0--7 Hz, 7--14 Hz, 14--49 Hz & 3/1 (+ LSTM as postprocessor) & &\n",
    " & Hand crafted features + SVM & Input occlusion and effect on prediction accuracy &\n",
    "Allowed to locate areas critical for seizure \n",
    "\\\\\n",
    "\\hdashline\n",
    "\n",
    "Single-trial EEG RSVP classification using convolutional neural networks, \\citet{george_single-trial_2016} &\n",
    "Oddball response (RSVP), groupwise (ConvNet trained on all subjects) &\n",
    "Time, 0.5--50 Hz & 4/3 & &  &  &\n",
    "Weights (spatial) &\n",
    "Some filter weights had expected topographic distributions for P300 \\cellbr\n",
    "Others filters had large weights on areas not traditionally associated with P300\n",
    "\\\\\n",
    "\\hdashline\n",
    "\n",
    "Wearable seizure detection using convolutional neural networks with transfer learning, \\citet{page_wearable_2016} &\n",
    "Seizure detection, cross-subject, within-subject, groupwise &\n",
    "Time, \\hspace{1cm} 0--128 Hz & 1-3/1-3 & & Cross-subject supervised training, within-subject finetuning of fully connected layers &\n",
    "Multiple: spectral features, higher order statistics + linear-SVM, RBF-SVM, ...& & \n",
    "\\\\\n",
    "\\hdashline\n",
    "\n",
    "Learning Representations from EEG with Deep Recurrent-Convolutional Neural Networks, \\citet{bashivan_learning_2016}  &\n",
    "Cognitive load (number of characters to memorize), cross-subject & \n",
    "Frequency, mean power for 4--7 Hz, 8--13 Hz, 13--30 Hz & 3--7/2 (+ LSTM or other temporal post-processing (see design choices)) &\n",
    "Number of convolutional layers \\cellbr\n",
    "Temporal processing of ConvNet output by max pooling, temporal convolution, LSTM or temporal convolution + LSTM & & &\n",
    "Inputs that maximally activate given filter \\cellbr\n",
    "Activations of these inputs \\cellbr\n",
    "\"Deconvolution\" for these inputs &\n",
    "Different filters were sensitive to different frequency bands \\cellbr\n",
    "Later layers had more spatially localized activations \\cellbr\n",
    "Learned features had noticeable links to well-known electrophysiological markers of cognitive load \\cellbr\n",
    "\\\\\n",
    "\\hdashline\n",
    "\n",
    "Deep Feature Learning for EEG Recordings, \\citet{stober_learning_2016} &\n",
    "Type of music rhythm, groupwise (ensembles of leave-one-subject-out trained models, evaluated on separate test set of same subjects) &\n",
    "Time, 0.5--30Hz & 2/1 & Kernel sizes & \n",
    "Pretraining first layer as convolutional autoencoder with different constraints &  & \n",
    "Weights (spatial+3 timesteps, pretrained as autoencoder) & \n",
    "Different constraints led to different weights, one type of constraints could enforce weights that are similar across subjects; other type of constraints led to weights that have similar spatial topographies under different architectural configurations and preprocessings\n",
    "\\\\\n",
    "\\hdashline\n",
    "\n",
    "Convolutional Neural Network for Multi-Category Rapid Serial Visual Presentation BCI, \\citet{manor_convolutional_2015} &\n",
    "Oddball response (RSVP), within-subject &\n",
    "Time, 0.1--50 Hz & 3/3 (Spatio-temporal regularization) && &&\n",
    "Weights \\cellbr Mean and single-trial activations &\n",
    "Spatiotemporal regularization led to softer peaks in weights \\cellbr\n",
    "Spatial weights showed typical P300 distribution \\cellbr\n",
    "Activations mostly had peaks at typical times (300-400ms)\n",
    "\\\\\n",
    "\\hdashline\n",
    "\n",
    "Parallel Convolutional-Linear Neural Network for Motor Imagery Classification, \\citet{sakhavi_parallel_2015}  &\n",
    "Imagined movement classes, within-subject &\n",
    "Frequency, 4--40 Hz, using FBCSP & 2/2 (Final fully connected layer uses concatenated output by convolutional\n",
    "and fully connected layers) &\n",
    "Combination ConvNet and MLP (trained on different features) vs. only ConvNet vs. only MLP & \n",
    "& & & \n",
    "\\\\\n",
    "\\hdashline\n",
    "\n",
    "Using Convolutional Neural networks to Recognize Rhythm Stimuli form Electroencephalography Recordings, \\citet{stober_using_2014} &\n",
    "Type of music rhythm, within-subject & Time and frequency evaluated, 0-200 Hz & 1-2/1 &\n",
    "Best values from automatic hyperparameter optimization: frequency cutoff, one vs two layers, kernel sizes, number of channels, pooling width &\n",
    "Best values from automatic hyperparameter optimization: learning rate, learning rate decay, momentum, final momentum &\n",
    "&\n",
    "\\\\\n",
    "\\hdashline\n",
    "\n",
    "Convolutional deep belief networks for feature extraction of EEG signal, \\citet{ren_convolutional_2014}  &\n",
    "Imagined movement classes, within-subject &\n",
    "Frequency, 8--30 Hz &\n",
    "2/0 (Convolutional deep belief network, separately trained RBF-SVM classifier) & & \n",
    "\\\\\n",
    "\\hdashline\n",
    "\n",
    "Deep feature learning using target priors with applications in ECoG signal decoding for BCI, \\citet{wang_deep_2013}  &\n",
    "Finger flexion trajectory (regression), within-subject &\n",
    "Time, 0.15--200 Hz & 3/1 (Convolutional layers trained as convolutional stacked autoencoder with target prior) &\n",
    "Partially supervised CSA & \n",
    "\\\\\n",
    "\\hdashline\n",
    "\n",
    "Convolutional neural networks for P300 detection with application to brain-computer interfaces, \\citet{cecotti_convolutional_2011}  &\n",
    "Oddball / attention response using P300 speller, within-subject & Time, 0.1-20 Hz & 2/2 &\n",
    "Electrode subset (fixed or automatically determined) \\cellbr\n",
    "Using only one spatial filter \\cellbr\n",
    "Different ensembling strategies & \n",
    "&\n",
    "Multiple: Linear SVM, gradient boosting, E-SVM, S-SVM, mLVQ, LDA, ... &\n",
    "Weights &\n",
    "Spatial filters were similar for different architectures \\cellbr\n",
    "Spatial filters were different (more focal, more diffuse) for different subjects\n",
    "\\\\\n",
    "\\hdashline\n",
    " \"\"\"\n",
    "\n",
    "b = a.replace(\"&\", \"|\").replace(\"\\n\", \"\").replace(\"\\cellbr\", \"<br>\").replace('\\hdashline', '\\n|').replace('\\\\', '')\n",
    "b = b.replace(\"ref\", r\"\\ref\").replace(\"--\", '–').replace(\"cite\", r\"\\cite\").replace(\"citet\", r\"cite\")\n",
    "b = re.sub(r'hspace{[^}]+}', r'', b)\n",
    "b = re.sub(r\"\\\\cite{([^}]+)}\", \"{cite}`\\g<1>`\", b)\n",
    "b = \"| \" + b + \" |\"\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a =  \"network, \\cite{hajinoroozi_eeg-based_2016} |D\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'network, {cite}`hajinoroozi_eeg-based_2016` |D'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r\"\\\\cite{([^}]+)}\", \"{cite}`\\g<1>`\", a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"\"\"\n",
    "| This manuscript, Schirrmeister et. al (2017) |Imagined and executed movement classes, within subject |Time,  0–125 Hz | 5/1 |Different ConvNet architectures <br>Nonlinearities and pooling modes <br>Regularization and intermediate normalization layers <br>Factorized convolutions <br>Splitted vs one-step convolutions |Trial-wise vs. cropped training strategy |FBCSP + rLDA | Feature activation correlation <br>Feature-perturbation prediction correlation |See Section \\ref{subsec:results-visualization}\n",
    "| Single-trial EEG classification of motor imagery using deep convolutional neural networks, citet{tang_single-trial_2017} |Imagined movement classes, within-subject |Time,  8–30 Hz | 2/2 | | | FBCSP | | \n",
    "| EEGNet: A Compact Convolutional Network for EEG-based Brain-Computer Interfaces, {cite}`lawhern_eegnet:_2016` | Oddball response (RSVP), error response (ERN), movement classes (voluntarily started and imagined) |Time, 0.1–40 Hz | 3/1 |  Kernel sizes | |   | |\n",
    "| Remembered or Forgotten? –- An EEG-Based Computational Prediction Approach, {cite}`sun_remembered_2016` | Memory performance, within-subject |Time, 0.05–15 Hz | 2/2 | | Different time windows |  |Weights (spatial) | Largest weights found over p\\refrontal and temporal cortex\n",
    "|Multimodal Neural Network for Rapid Serial Visual Presentation Brain Computer Interface, {cite}`manor_multimodal_2016`|Oddball response using RSVP and image (combined image-EEG decoding), within-subject|Time, 0.3–20 Hz | 3/2 | | |  | Weights <br> Activations <br> Saliency maps by gradient |Weights showed typical P300 distribution <br>Activations were high at plausible times (300-500ms) <br>Saliency maps showed plausible spatio-temporal plots\n",
    "| A novel deep learning approach for classification of EEG motor imagery signals, {cite}`tabar_novel_2017` |Imagined and executed movement classes, within-subject |Frequency, 6–30 Hz | 1/1 |Addition of six-layer stacked autoencoder on ConvNet features <br> Kernel sizes} |  | FBCSP, Twin SVM, DDFBS, Bi-spectrum, RQNN  | Weights (spatial + frequential) |Some weights represented difference of values of two electrodes on different sides of head\n",
    "| Predicting Seizures from Electroencephalography Recordings: A Knowledge Transfer Strategy, {cite}`liang_predicting_2016` |Seizure prediction, within-subject | Frequency, 0–200 Hz | 1/2 | | Different subdivisions of frequency range <br>Different lengths of time crops <br>Transfer learning with auxiliary non-epilepsy datasets || Weights <br> Clustering of weights |Clusters of weights showed typical frequency band subdivision (delta, theta, alpha, beta, gamma)\n",
    "| EEG-based prediction of driver's cognitive performance by deep convolutional neural network, {cite}`hajinoroozi_eeg-based_2016` |Driver performance, within- and cross-subject |Time,  1–50 Hz | 1/3 |Replacement of convolutional layers by restricted Boltzmann machines with slightly varied network architecture}  | | |\n",
    "| Deep learning for epileptic intracranial EEG data, {cite}`antoniades_deep_2016` |Epileptic discharges, cross-subject | Time,  0–100 HZ | 1–2/2 | 1 or 2 convolutional layers |  | |Weights <br>Correlation weights and interictal epileptic discharges (IED) <br>Activations |Weights increasingly correlated with IED waveforms with increasing number of training iterations <br>Second layer captured more complex and well-defined epileptic shapes than first layer <br>IEDs led to highly synchronized activations for neighbouring electrodes\n",
    "| Learning Robust Features using Deep Learning for Automatic Seizure Detection, {cite}`thodoroff_learning_2016` |Start of epileptic seizure, within- and cross-subject |Frequency, mean amplitude for 0–7 Hz, 7–14 Hz, 14–49 Hz | 3/1 (+ LSTM as postprocessor) | | | Hand crafted features + SVM | Input occlusion and effect on prediction accuracy |Allowed to locate areas critical for seizure \n",
    "|Single-trial EEG RSVP classification using convolutional neural networks, {cite}`george_single-trial_2016` |Oddball response (RSVP), groupwise (ConvNet trained on all subjects) |Time, 0.5–50 Hz | 4/3 | |  |  |Weights (spatial) |Some filter weights had expected topographic distributions for P300 <br>Others filters had large weights on areas not traditionally associated with P300\n",
    "|Wearable seizure detection using convolutional neural networks with transfer learning, {cite}`page_wearable_2016` |Seizure detection, cross-subject, within-subject, groupwise |Time,  0–128 Hz | 1-3/1-3 | | Cross-subject supervised training, within-subject finetuning of fully connected layers |Multiple: spectral features, higher order statistics + linear-SVM, RBF-SVM, ...| | \n",
    "|Learning Representations from EEG with Deep Recurrent-Convolutional Neural Networks, {cite}`bashivan_learning_2016`  |Cognitive load (number of characters to memorize), cross-subject | Frequency, mean power for 4–7 Hz, 8–13 Hz, 13–30 Hz | 3–7/2 (+ LSTM or other temporal post-processing (see design choices)) |Number of convolutional layers <br>Temporal processing of ConvNet output by max pooling, temporal convolution, LSTM or temporal convolution + LSTM | | |Inputs that maximally activate given filter <br>Activations of these inputs <br>\"Deconvolution\" for these inputs |Different filters were sensitive to different frequency bands <br>Later layers had more spatially localized activations <br>Learned features had noticeable links to well-known electrophysiological markers of cognitive load <br>\n",
    "|Deep Feature Learning for EEG Recordings, {cite}`stober_learning_2016` |Type of music rhythm, groupwise (ensembles of leave-one-subject-out trained models, evaluated on separate test set of same subjects) |Time, 0.5–30Hz | 2/1 | Kernel sizes | Pretraining first layer as convolutional autoencoder with different constraints |  | Weights (spatial+3 timesteps, pretrained as autoencoder) | Different constraints led to different weights, one type of constraints could enforce weights that are similar across subjects; other type of constraints led to weights that have similar spatial topographies under different architectural configurations and preprocessings\n",
    "|Convolutional Neural Network for Multi-Category Rapid Serial Visual Presentation BCI, {cite}`manor_convolutional_2015` |Oddball response (RSVP), within-subject |Time, 0.1–50 Hz | 3/3 (Spatio-temporal regularization) || ||Weights <br> Mean and single-trial activations |Spatiotemporal regularization led to softer peaks in weights <br>Spatial weights showed typical P300 distribution <br>Activations mostly had peaks at typical times (300-400ms)\n",
    "|Parallel Convolutional-Linear Neural Network for Motor Imagery Classification, {cite}`sakhavi_parallel_2015`  |Imagined movement classes, within-subject |Frequency, 4–40 Hz, using FBCSP | 2/2 (Final fully connected layer uses concatenated output by convolutionaland fully connected layers) |Combination ConvNet and MLP (trained on different features) vs. only ConvNet vs. only MLP | | | | \n",
    "|Using Convolutional Neural networks to Recognize Rhythm Stimuli form Electroencephalography Recordings, {cite}`stober_using_2014` |Type of music rhythm, within-subject | Time and frequency evaluated, 0-200 Hz | 1-2/1 |Best values from automatic hyperparameter optimization: frequency cutoff, one vs two layers, kernel sizes, number of channels, pooling width |Best values from automatic hyperparameter optimization: learning rate, learning rate decay, momentum, final momentum ||\n",
    "|Convolutional deep belief networks for feature extraction of EEG signal, {cite}`ren_convolutional_2014`  |Imagined movement classes, within-subject |Frequency, 8–30 Hz |2/0 (Convolutional deep belief network, separately trained RBF-SVM classifier) | | \n",
    "|Deep feature learning using target priors with applications in ECoG signal decoding for BCI, {cite}`wang_deep_2013`  |Finger flexion trajectory (regression), within-subject |Time, 0.15–200 Hz | 3/1 (Convolutional layers trained as convolutional stacked autoencoder with target prior) |Partially supervised CSA | \n",
    "|Convolutional neural networks for P300 detection with application to brain-computer interfaces, {cite}`cecotti_convolutional_2011`  |Oddball / attention response using P300 speller, within-subject | Time, 0.1-20 Hz | 2/2 |Electrode subset (fixed or automatically determined) <br>Using only one spatial filter <br>Different ensembling strategies | |Multiple: Linear SVM, gradient boosting, E-SVM, S-SVM, mLVQ, LDA, ... |Weights |Spatial filters were similar for different architectures <br>Spatial filters were different (more focal, more diffuse) for different subjects\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "parts = [l.split('|')[1:] for l in a.split('\\n')[1:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9, 9, 9, 9, 9, 9, 9, 8, 9, 9, 9, 9, 9, 9, 9, 9, 8, 6, 6, 9]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(p) for p in parts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "headings = ['Study', 'Decoding problem', 'Input domain', 'Conv/dense layers', 'Design choices', \n",
    "'Training strategies', 'External baseline', 'Visualization type(s)', 'Visualization findings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "parts = [p + [''] * (9 - len(p)) for p in parts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Study',\n",
       "  ' Remembered or Forgotten? –- An EEG-Based Computational Prediction Approach, {cite}`sun_remembered_2016` '),\n",
       " ('Decoding problem', ' Memory performance, within-subject '),\n",
       " ('Input domain', 'Time, 0.05–15 Hz '),\n",
       " ('Conv/dense layers', ' 2/2 '),\n",
       " ('Design choices', ' '),\n",
       " ('Training strategies', ' Different time windows '),\n",
       " ('External baseline', '  '),\n",
       " ('Visualization type(s)', 'Weights (spatial) '),\n",
       " ('Visualization findings',\n",
       "  ' Largest weights found over p\\refrontal and temporal cortex')]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(headings, parts[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(p) for p in parts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "part_arr = np.array(parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df  = pd.DataFrame(data=part_arr, columns=headings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Study                                                                                                                              | Design choices                                                                                                                                                                                  | Training strategies                                                                                                                      |\n",
      "|:-----------------------------------------------------------------------------------------------------------------------------------|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:-----------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| This manuscript, Schirrmeister et. al (2017)                                                                                       | Different ConvNet architectures <br>Nonlinearities and pooling modes <br>Regularization and intermediate normalization layers <br>Factorized convolutions <br>Splitted vs one-step convolutions | Trial-wise vs. cropped training strategy                                                                                                 |\n",
      "| Single-trial EEG classification of motor imagery using deep convolutional neural networks, citet{tang_single-trial_2017}           |                                                                                                                                                                                                 |                                                                                                                                          |\n",
      "| EEGNet: A Compact Convolutional Network for EEG-based Brain-Computer Interfaces, {cite}`lawhern_eegnet:_2016`                      | Kernel sizes                                                                                                                                                                                    |                                                                                                                                          |\n",
      "| Remembered or Forgotten? –- An EEG-Based Computational Prediction Approach, {cite}`sun_remembered_2016`                            |                                                                                                                                                                                                 | Different time windows                                                                                                                   |\n",
      "| Multimodal Neural Network for Rapid Serial Visual Presentation Brain Computer Interface, {cite}`manor_multimodal_2016`             |                                                                                                                                                                                                 |                                                                                                                                          |\n",
      "| A novel deep learning approach for classification of EEG motor imagery signals, {cite}`tabar_novel_2017`                           | Addition of six-layer stacked autoencoder on ConvNet features <br> Kernel sizes}                                                                                                                |                                                                                                                                          |\n",
      "| Predicting Seizures from Electroencephalography Recordings: A Knowledge Transfer Strategy, {cite}`liang_predicting_2016`           |                                                                                                                                                                                                 | Different subdivisions of frequency range <br>Different lengths of time crops <br>Transfer learning with auxiliary non-epilepsy datasets |\n",
      "| EEG-based prediction of driver's cognitive performance by deep convolutional neural network, {cite}`hajinoroozi_eeg-based_2016`    | Replacement of convolutional layers by restricted Boltzmann machines with slightly varied network architecture}                                                                                 |                                                                                                                                          |\n",
      "| Deep learning for epileptic intracranial EEG data, {cite}`antoniades_deep_2016`                                                    | 1 or 2 convolutional layers                                                                                                                                                                     |                                                                                                                                          |\n",
      "| Learning Robust Features using Deep Learning for Automatic Seizure Detection, {cite}`thodoroff_learning_2016`                      |                                                                                                                                                                                                 |                                                                                                                                          |\n",
      "| Single-trial EEG RSVP classification using convolutional neural networks, {cite}`george_single-trial_2016`                         |                                                                                                                                                                                                 |                                                                                                                                          |\n",
      "| Wearable seizure detection using convolutional neural networks with transfer learning, {cite}`page_wearable_2016`                  |                                                                                                                                                                                                 | Cross-subject supervised training, within-subject finetuning of fully connected layers                                                   |\n",
      "| Learning Representations from EEG with Deep Recurrent-Convolutional Neural Networks, {cite}`bashivan_learning_2016`                | Number of convolutional layers <br>Temporal processing of ConvNet output by max pooling, temporal convolution, LSTM or temporal convolution + LSTM                                              |                                                                                                                                          |\n",
      "| Deep Feature Learning for EEG Recordings, {cite}`stober_learning_2016`                                                             | Kernel sizes                                                                                                                                                                                    | Pretraining first layer as convolutional autoencoder with different constraints                                                          |\n",
      "| Convolutional Neural Network for Multi-Category Rapid Serial Visual Presentation BCI, {cite}`manor_convolutional_2015`             |                                                                                                                                                                                                 |                                                                                                                                          |\n",
      "| Parallel Convolutional-Linear Neural Network for Motor Imagery Classification, {cite}`sakhavi_parallel_2015`                       | Combination ConvNet and MLP (trained on different features) vs. only ConvNet vs. only MLP                                                                                                       |                                                                                                                                          |\n",
      "| Using Convolutional Neural networks to Recognize Rhythm Stimuli form Electroencephalography Recordings, {cite}`stober_using_2014`  | Best values from automatic hyperparameter optimization: frequency cutoff, one vs two layers, kernel sizes, number of channels, pooling width                                                    | Best values from automatic hyperparameter optimization: learning rate, learning rate decay, momentum, final momentum                     |\n",
      "| Convolutional deep belief networks for feature extraction of EEG signal, {cite}`ren_convolutional_2014`                            |                                                                                                                                                                                                 |                                                                                                                                          |\n",
      "| Deep feature learning using target priors with applications in ECoG signal decoding for BCI, {cite}`wang_deep_2013`                | Partially supervised CSA                                                                                                                                                                        |                                                                                                                                          |\n",
      "| Convolutional neural networks for P300 detection with application to brain-computer interfaces, {cite}`cecotti_convolutional_2011` | Electrode subset (fixed or automatically determined) <br>Using only one spatial filter <br>Different ensembling strategies                                                                      |                                                                                                                                          |\n"
     ]
    }
   ],
   "source": [
    "print(df.loc[:, ['Study', 'Design choices', 'Training strategies']].to_markdown(showindex=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Study                                                                                                                              | Design choices                                                                                                                                                                                  | Training strategies                                                                                                                      |\n",
    "|:-----------------------------------------------------------------------------------------------------------------------------------|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:-----------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| EEGNet: A Compact Convolutional Network for EEG-based Brain-Computer Interfaces, {cite}`lawhern_eegnet:_2016`                      | Kernel sizes                                                                                                                                                                                    |                                                                                                                                          |\n",
    "| Remembered or Forgotten? –- An EEG-Based Computational Prediction Approach, {cite}`sun_remembered_2016`                            |                                                                                                                                                                                                 | Different time windows                                                                                                                   |\n",
    "| A novel deep learning approach for classification of EEG motor imagery signals, {cite}`tabar_novel_2017`                           | Addition of six-layer stacked autoencoder on ConvNet features <br> Kernel sizes}                                                                                                                |                                                                                                                                          |\n",
    "| Predicting Seizures from Electroencephalography Recordings: A Knowledge Transfer Strategy, {cite}`liang_predicting_2016`           |                                                                                                                                                                                                 | Different subdivisions of frequency range <br>Different lengths of time crops <br>Transfer learning with auxiliary non-epilepsy datasets |\n",
    "| EEG-based prediction of driver's cognitive performance by deep convolutional neural network, {cite}`hajinoroozi_eeg-based_2016`    | Replacement of convolutional layers by restricted Boltzmann machines with slightly varied network architecture}                                                                                 |                                                                                                                                          |\n",
    "| Deep learning for epileptic intracranial EEG data, {cite}`antoniades_deep_2016`                                                    | 1 or 2 convolutional layers                                                                                                                                                                     |                                                                                                                                          |\n",
    "| Wearable seizure detection using convolutional neural networks with transfer learning, {cite}`page_wearable_2016`                  |                                                                                                                                                                                                 | Cross-subject supervised training, within-subject finetuning of fully connected layers                                                   |\n",
    "| Learning Representations from EEG with Deep Recurrent-Convolutional Neural Networks, {cite}`bashivan_learning_2016`                | Number of convolutional layers <br>Temporal processing of ConvNet output by max pooling, temporal convolution, LSTM or temporal convolution + LSTM                                              |                                                                                                                                          |\n",
    "| Deep Feature Learning for EEG Recordings, {cite}`stober_learning_2016`                                                             | Kernel sizes                                                                                                                                                                                    | Pretraining first layer as convolutional autoencoder with different constraints                                                          |\n",
    "| Parallel Convolutional-Linear Neural Network for Motor Imagery Classification, {cite}`sakhavi_parallel_2015`                       | Combination ConvNet and MLP (trained on different features) vs. only ConvNet vs. only MLP                                                                                                       |                                                                                                                                          |\n",
    "| Using Convolutional Neural networks to Recognize Rhythm Stimuli form Electroencephalography Recordings, {cite}`stober_using_2014`  | Best values from automatic hyperparameter optimization: frequency cutoff, one vs two layers, kernel sizes, number of channels, pooling width                                                    | Best values from automatic hyperparameter optimization: learning rate, learning rate decay, momentum, final momentum                     |\n",
    "| Deep feature learning using target priors with applications in ECoG signal decoding for BCI, {cite}`wang_deep_2013`                | Partially supervised CSA                                                                                                                                                                        |                                                                                                                                          |\n",
    "| Convolutional neural networks for P300 detection with application to brain-computer interfaces, {cite}`cecotti_convolutional_2011` | Electrode subset (fixed or automatically determined) <br>Using only one spatial filter <br>Different ensembling strategies                                                                      |                                                                                                                                          |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Study</th>\n",
       "      <th>Decoding problem</th>\n",
       "      <th>Input domain</th>\n",
       "      <th>Conv/dense layers</th>\n",
       "      <th>Design choices</th>\n",
       "      <th>Training strategies</th>\n",
       "      <th>External baseline</th>\n",
       "      <th>Visualization type(s)</th>\n",
       "      <th>Visualization findings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This manuscript, Schirrmeister et. al (2017)</td>\n",
       "      <td>Imagined and executed movement classes, within...</td>\n",
       "      <td>Time,  0–125 Hz</td>\n",
       "      <td>5/1</td>\n",
       "      <td>Different ConvNet architectures &lt;br&gt;Nonlineari...</td>\n",
       "      <td>Trial-wise vs. cropped training strategy</td>\n",
       "      <td>FBCSP + rLDA</td>\n",
       "      <td>Feature activation correlation &lt;br&gt;Feature-pe...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Single-trial EEG classification of motor imag...</td>\n",
       "      <td>Imagined movement classes, within-subject</td>\n",
       "      <td>Time,  8–30 Hz</td>\n",
       "      <td>2/2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>FBCSP</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EEGNet: A Compact Convolutional Network for E...</td>\n",
       "      <td>Oddball response (RSVP), error response (ERN)...</td>\n",
       "      <td>Time, 0.1–40 Hz</td>\n",
       "      <td>3/1</td>\n",
       "      <td>Kernel sizes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Remembered or Forgotten? –- An EEG-Based Comp...</td>\n",
       "      <td>Memory performance, within-subject</td>\n",
       "      <td>Time, 0.05–15 Hz</td>\n",
       "      <td>2/2</td>\n",
       "      <td></td>\n",
       "      <td>Different time windows</td>\n",
       "      <td></td>\n",
       "      <td>Weights (spatial)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Multimodal Neural Network for Rapid Serial Vis...</td>\n",
       "      <td>Oddball response using RSVP and image (combine...</td>\n",
       "      <td>Time, 0.3–20 Hz</td>\n",
       "      <td>3/2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Weights &lt;br&gt; Activations &lt;br&gt; Saliency maps b...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A novel deep learning approach for classifica...</td>\n",
       "      <td>Imagined and executed movement classes, within...</td>\n",
       "      <td>Frequency, 6–30 Hz</td>\n",
       "      <td>1/1</td>\n",
       "      <td>Addition of six-layer stacked autoencoder on C...</td>\n",
       "      <td></td>\n",
       "      <td>FBCSP, Twin SVM, DDFBS, Bi-spectrum, RQNN</td>\n",
       "      <td>Weights (spatial + frequential)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Predicting Seizures from Electroencephalograp...</td>\n",
       "      <td>Seizure prediction, within-subject</td>\n",
       "      <td>Frequency, 0–200 Hz</td>\n",
       "      <td>1/2</td>\n",
       "      <td></td>\n",
       "      <td>Different subdivisions of frequency range &lt;br...</td>\n",
       "      <td></td>\n",
       "      <td>Weights &lt;br&gt; Clustering of weights</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>EEG-based prediction of driver's cognitive pe...</td>\n",
       "      <td>Driver performance, within- and cross-subject</td>\n",
       "      <td>Time,  1–50 Hz</td>\n",
       "      <td>1/3</td>\n",
       "      <td>Replacement of convolutional layers by restric...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Deep learning for epileptic intracranial EEG ...</td>\n",
       "      <td>Epileptic discharges, cross-subject</td>\n",
       "      <td>Time,  0–100 HZ</td>\n",
       "      <td>1–2/2</td>\n",
       "      <td>1 or 2 convolutional layers</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Weights &lt;br&gt;Correlation weights and interictal...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Learning Robust Features using Deep Learning ...</td>\n",
       "      <td>Start of epileptic seizure, within- and cross-...</td>\n",
       "      <td>Frequency, mean amplitude for 0–7 Hz, 7–14 Hz,...</td>\n",
       "      <td>3/1 (+ LSTM as postprocessor)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Hand crafted features + SVM</td>\n",
       "      <td>Input occlusion and effect on prediction accu...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Single-trial EEG RSVP classification using con...</td>\n",
       "      <td>Oddball response (RSVP), groupwise (ConvNet tr...</td>\n",
       "      <td>Time, 0.5–50 Hz</td>\n",
       "      <td>4/3</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Weights (spatial)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Wearable seizure detection using convolutional...</td>\n",
       "      <td>Seizure detection, cross-subject, within-subje...</td>\n",
       "      <td>Time,  0–128 Hz</td>\n",
       "      <td>1-3/1-3</td>\n",
       "      <td></td>\n",
       "      <td>Cross-subject supervised training, within-sub...</td>\n",
       "      <td>Multiple: spectral features, higher order stat...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Learning Representations from EEG with Deep Re...</td>\n",
       "      <td>Cognitive load (number of characters to memori...</td>\n",
       "      <td>Frequency, mean power for 4–7 Hz, 8–13 Hz, 13...</td>\n",
       "      <td>3–7/2 (+ LSTM or other temporal post-processi...</td>\n",
       "      <td>Number of convolutional layers &lt;br&gt;Temporal pr...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Inputs that maximally activate given filter &lt;b...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Deep Feature Learning for EEG Recordings, {cit...</td>\n",
       "      <td>Type of music rhythm, groupwise (ensembles of ...</td>\n",
       "      <td>Time, 0.5–30Hz</td>\n",
       "      <td>2/1</td>\n",
       "      <td>Kernel sizes</td>\n",
       "      <td>Pretraining first layer as convolutional auto...</td>\n",
       "      <td></td>\n",
       "      <td>Weights (spatial+3 timesteps, pretrained as a...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Convolutional Neural Network for Multi-Categor...</td>\n",
       "      <td>Oddball response (RSVP), within-subject</td>\n",
       "      <td>Time, 0.1–50 Hz</td>\n",
       "      <td>3/3 (Spatio-temporal regularization)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Weights &lt;br&gt; Mean and single-trial activations</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Parallel Convolutional-Linear Neural Network f...</td>\n",
       "      <td>Imagined movement classes, within-subject</td>\n",
       "      <td>Frequency, 4–40 Hz, using FBCSP</td>\n",
       "      <td>2/2 (Final fully connected layer uses concate...</td>\n",
       "      <td>Combination ConvNet and MLP (trained on differ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Using Convolutional Neural networks to Recogni...</td>\n",
       "      <td>Type of music rhythm, within-subject</td>\n",
       "      <td>Time and frequency evaluated, 0-200 Hz</td>\n",
       "      <td>1-2/1</td>\n",
       "      <td>Best values from automatic hyperparameter opti...</td>\n",
       "      <td>Best values from automatic hyperparameter opti...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Convolutional deep belief networks for feature...</td>\n",
       "      <td>Imagined movement classes, within-subject</td>\n",
       "      <td>Frequency, 8–30 Hz</td>\n",
       "      <td>2/0 (Convolutional deep belief network, separa...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Deep feature learning using target priors with...</td>\n",
       "      <td>Finger flexion trajectory (regression), within...</td>\n",
       "      <td>Time, 0.15–200 Hz</td>\n",
       "      <td>3/1 (Convolutional layers trained as convolut...</td>\n",
       "      <td>Partially supervised CSA</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Convolutional neural networks for P300 detecti...</td>\n",
       "      <td>Oddball / attention response using P300 spelle...</td>\n",
       "      <td>Time, 0.1-20 Hz</td>\n",
       "      <td>2/2</td>\n",
       "      <td>Electrode subset (fixed or automatically deter...</td>\n",
       "      <td></td>\n",
       "      <td>Multiple: Linear SVM, gradient boosting, E-SVM...</td>\n",
       "      <td>Weights</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Study  \\\n",
       "0       This manuscript, Schirrmeister et. al (2017)    \n",
       "1    Single-trial EEG classification of motor imag...   \n",
       "2    EEGNet: A Compact Convolutional Network for E...   \n",
       "3    Remembered or Forgotten? –- An EEG-Based Comp...   \n",
       "4   Multimodal Neural Network for Rapid Serial Vis...   \n",
       "5    A novel deep learning approach for classifica...   \n",
       "6    Predicting Seizures from Electroencephalograp...   \n",
       "7    EEG-based prediction of driver's cognitive pe...   \n",
       "8    Deep learning for epileptic intracranial EEG ...   \n",
       "9    Learning Robust Features using Deep Learning ...   \n",
       "10  Single-trial EEG RSVP classification using con...   \n",
       "11  Wearable seizure detection using convolutional...   \n",
       "12  Learning Representations from EEG with Deep Re...   \n",
       "13  Deep Feature Learning for EEG Recordings, {cit...   \n",
       "14  Convolutional Neural Network for Multi-Categor...   \n",
       "15  Parallel Convolutional-Linear Neural Network f...   \n",
       "16  Using Convolutional Neural networks to Recogni...   \n",
       "17  Convolutional deep belief networks for feature...   \n",
       "18  Deep feature learning using target priors with...   \n",
       "19  Convolutional neural networks for P300 detecti...   \n",
       "\n",
       "                                     Decoding problem  \\\n",
       "0   Imagined and executed movement classes, within...   \n",
       "1          Imagined movement classes, within-subject    \n",
       "2    Oddball response (RSVP), error response (ERN)...   \n",
       "3                 Memory performance, within-subject    \n",
       "4   Oddball response using RSVP and image (combine...   \n",
       "5   Imagined and executed movement classes, within...   \n",
       "6                 Seizure prediction, within-subject    \n",
       "7      Driver performance, within- and cross-subject    \n",
       "8                Epileptic discharges, cross-subject    \n",
       "9   Start of epileptic seizure, within- and cross-...   \n",
       "10  Oddball response (RSVP), groupwise (ConvNet tr...   \n",
       "11  Seizure detection, cross-subject, within-subje...   \n",
       "12  Cognitive load (number of characters to memori...   \n",
       "13  Type of music rhythm, groupwise (ensembles of ...   \n",
       "14           Oddball response (RSVP), within-subject    \n",
       "15         Imagined movement classes, within-subject    \n",
       "16              Type of music rhythm, within-subject    \n",
       "17         Imagined movement classes, within-subject    \n",
       "18  Finger flexion trajectory (regression), within...   \n",
       "19  Oddball / attention response using P300 spelle...   \n",
       "\n",
       "                                         Input domain  \\\n",
       "0                                    Time,  0–125 Hz    \n",
       "1                                     Time,  8–30 Hz    \n",
       "2                                    Time, 0.1–40 Hz    \n",
       "3                                   Time, 0.05–15 Hz    \n",
       "4                                    Time, 0.3–20 Hz    \n",
       "5                                 Frequency, 6–30 Hz    \n",
       "6                                Frequency, 0–200 Hz    \n",
       "7                                     Time,  1–50 Hz    \n",
       "8                                    Time,  0–100 HZ    \n",
       "9   Frequency, mean amplitude for 0–7 Hz, 7–14 Hz,...   \n",
       "10                                   Time, 0.5–50 Hz    \n",
       "11                                   Time,  0–128 Hz    \n",
       "12   Frequency, mean power for 4–7 Hz, 8–13 Hz, 13...   \n",
       "13                                    Time, 0.5–30Hz    \n",
       "14                                   Time, 0.1–50 Hz    \n",
       "15                   Frequency, 4–40 Hz, using FBCSP    \n",
       "16            Time and frequency evaluated, 0-200 Hz    \n",
       "17                                Frequency, 8–30 Hz    \n",
       "18                                 Time, 0.15–200 Hz    \n",
       "19                                   Time, 0.1-20 Hz    \n",
       "\n",
       "                                    Conv/dense layers  \\\n",
       "0                                                5/1    \n",
       "1                                                2/2    \n",
       "2                                                3/1    \n",
       "3                                                2/2    \n",
       "4                                                3/2    \n",
       "5                                                1/1    \n",
       "6                                                1/2    \n",
       "7                                                1/3    \n",
       "8                                              1–2/2    \n",
       "9                      3/1 (+ LSTM as postprocessor)    \n",
       "10                                               4/3    \n",
       "11                                           1-3/1-3    \n",
       "12   3–7/2 (+ LSTM or other temporal post-processi...   \n",
       "13                                               2/1    \n",
       "14              3/3 (Spatio-temporal regularization)    \n",
       "15   2/2 (Final fully connected layer uses concate...   \n",
       "16                                             1-2/1    \n",
       "17  2/0 (Convolutional deep belief network, separa...   \n",
       "18   3/1 (Convolutional layers trained as convolut...   \n",
       "19                                               2/2    \n",
       "\n",
       "                                       Design choices  \\\n",
       "0   Different ConvNet architectures <br>Nonlineari...   \n",
       "1                                                       \n",
       "2                                       Kernel sizes    \n",
       "3                                                       \n",
       "4                                                       \n",
       "5   Addition of six-layer stacked autoencoder on C...   \n",
       "6                                                       \n",
       "7   Replacement of convolutional layers by restric...   \n",
       "8                        1 or 2 convolutional layers    \n",
       "9                                                       \n",
       "10                                                      \n",
       "11                                                      \n",
       "12  Number of convolutional layers <br>Temporal pr...   \n",
       "13                                      Kernel sizes    \n",
       "14                                                      \n",
       "15  Combination ConvNet and MLP (trained on differ...   \n",
       "16  Best values from automatic hyperparameter opti...   \n",
       "17                                                      \n",
       "18                          Partially supervised CSA    \n",
       "19  Electrode subset (fixed or automatically deter...   \n",
       "\n",
       "                                  Training strategies  \\\n",
       "0           Trial-wise vs. cropped training strategy    \n",
       "1                                                       \n",
       "2                                                       \n",
       "3                             Different time windows    \n",
       "4                                                       \n",
       "5                                                       \n",
       "6    Different subdivisions of frequency range <br...   \n",
       "7                                                       \n",
       "8                                                       \n",
       "9                                                       \n",
       "10                                                      \n",
       "11   Cross-subject supervised training, within-sub...   \n",
       "12                                                      \n",
       "13   Pretraining first layer as convolutional auto...   \n",
       "14                                                      \n",
       "15                                                      \n",
       "16  Best values from automatic hyperparameter opti...   \n",
       "17                                                      \n",
       "18                                                      \n",
       "19                                                      \n",
       "\n",
       "                                    External baseline  \\\n",
       "0                                       FBCSP + rLDA    \n",
       "1                                              FBCSP    \n",
       "2                                                       \n",
       "3                                                       \n",
       "4                                                       \n",
       "5         FBCSP, Twin SVM, DDFBS, Bi-spectrum, RQNN     \n",
       "6                                                       \n",
       "7                                                       \n",
       "8                                                       \n",
       "9                        Hand crafted features + SVM    \n",
       "10                                                      \n",
       "11  Multiple: spectral features, higher order stat...   \n",
       "12                                                      \n",
       "13                                                      \n",
       "14                                                      \n",
       "15                                                      \n",
       "16                                                      \n",
       "17                                                      \n",
       "18                                                      \n",
       "19  Multiple: Linear SVM, gradient boosting, E-SVM...   \n",
       "\n",
       "                                Visualization type(s) Visualization findings  \n",
       "0    Feature activation correlation <br>Feature-pe...                         \n",
       "1                                                                             \n",
       "2                                                                             \n",
       "3                                  Weights (spatial)                          \n",
       "4    Weights <br> Activations <br> Saliency maps b...                         \n",
       "5                    Weights (spatial + frequential)                          \n",
       "6                 Weights <br> Clustering of weights                          \n",
       "7                                                                             \n",
       "8   Weights <br>Correlation weights and interictal...                         \n",
       "9    Input occlusion and effect on prediction accu...                         \n",
       "10                                 Weights (spatial)                          \n",
       "11                                                                            \n",
       "12  Inputs that maximally activate given filter <b...                         \n",
       "13   Weights (spatial+3 timesteps, pretrained as a...                         \n",
       "14    Weights <br> Mean and single-trial activations                          \n",
       "15                                                                            \n",
       "16                                                                            \n",
       "17                                                                            \n",
       "18                                                                            \n",
       "19                                           Weights                          "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Study                                                                                                                              | Visualization type(s)                                                                                            | Visualization findings                                                                                                                                                                                                                                                          |\n",
      "|:-----------------------------------------------------------------------------------------------------------------------------------|:-----------------------------------------------------------------------------------------------------------------|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| Single-trial EEG classification of motor imagery using deep convolutional neural networks, citet{tang_single-trial_2017}           |                                                                                                                  |                                                                                                                                                                                                                                                                                 |\n",
      "| EEGNet: A Compact Convolutional Network for EEG-based Brain-Computer Interfaces, {cite}`lawhern_eegnet:_2016`                      |                                                                                                                  |                                                                                                                                                                                                                                                                                 |\n",
      "| Remembered or Forgotten? –- An EEG-Based Computational Prediction Approach, {cite}`sun_remembered_2016`                            | Weights (spatial)                                                                                                | Largest weights found over p                                                                                                                                                                                                                                                    |\n",
      "|                                                                                                                                    |                                                                                                                  | efrontal and temporal cortex                                                                                                                                                                                                                                                    |\n",
      "| Multimodal Neural Network for Rapid Serial Visual Presentation Brain Computer Interface, {cite}`manor_multimodal_2016`             | Weights <br> Activations <br> Saliency maps by gradient                                                          | Weights showed typical P300 distribution <br>Activations were high at plausible times (300-500ms) <br>Saliency maps showed plausible spatio-temporal plots                                                                                                                      |\n",
      "| A novel deep learning approach for classification of EEG motor imagery signals, {cite}`tabar_novel_2017`                           | Weights (spatial + frequential)                                                                                  | Some weights represented difference of values of two electrodes on different sides of head                                                                                                                                                                                      |\n",
      "| Predicting Seizures from Electroencephalography Recordings: A Knowledge Transfer Strategy, {cite}`liang_predicting_2016`           | Weights <br> Clustering of weights                                                                               | Clusters of weights showed typical frequency band subdivision (delta, theta, alpha, beta, gamma)                                                                                                                                                                                |\n",
      "| EEG-based prediction of driver's cognitive performance by deep convolutional neural network, {cite}`hajinoroozi_eeg-based_2016`    |                                                                                                                  |                                                                                                                                                                                                                                                                                 |\n",
      "| Deep learning for epileptic intracranial EEG data, {cite}`antoniades_deep_2016`                                                    | Weights <br>Correlation weights and interictal epileptic discharges (IED) <br>Activations                        | Weights increasingly correlated with IED waveforms with increasing number of training iterations <br>Second layer captured more complex and well-defined epileptic shapes than first layer <br>IEDs led to highly synchronized activations for neighbouring electrodes          |\n",
      "| Learning Robust Features using Deep Learning for Automatic Seizure Detection, {cite}`thodoroff_learning_2016`                      | Input occlusion and effect on prediction accuracy                                                                | Allowed to locate areas critical for seizure                                                                                                                                                                                                                                    |\n",
      "| Single-trial EEG RSVP classification using convolutional neural networks, {cite}`george_single-trial_2016`                         | Weights (spatial)                                                                                                | Some filter weights had expected topographic distributions for P300 <br>Others filters had large weights on areas not traditionally associated with P300                                                                                                                        |\n",
      "| Wearable seizure detection using convolutional neural networks with transfer learning, {cite}`page_wearable_2016`                  |                                                                                                                  |                                                                                                                                                                                                                                                                                 |\n",
      "| Learning Representations from EEG with Deep Recurrent-Convolutional Neural Networks, {cite}`bashivan_learning_2016`                | Inputs that maximally activate given filter <br>Activations of these inputs <br>\"Deconvolution\" for these inputs | Different filters were sensitive to different frequency bands <br>Later layers had more spatially localized activations <br>Learned features had noticeable links to well-known electrophysiological markers of cognitive load <br>                                             |\n",
      "| Deep Feature Learning for EEG Recordings, {cite}`stober_learning_2016`                                                             | Weights (spatial+3 timesteps, pretrained as autoencoder)                                                         | Different constraints led to different weights, one type of constraints could enforce weights that are similar across subjects; other type of constraints led to weights that have similar spatial topographies under different architectural configurations and preprocessings |\n",
      "| Convolutional Neural Network for Multi-Category Rapid Serial Visual Presentation BCI, {cite}`manor_convolutional_2015`             | Weights <br> Mean and single-trial activations                                                                   | Spatiotemporal regularization led to softer peaks in weights <br>Spatial weights showed typical P300 distribution <br>Activations mostly had peaks at typical times (300-400ms)                                                                                                 |\n",
      "| Parallel Convolutional-Linear Neural Network for Motor Imagery Classification, {cite}`sakhavi_parallel_2015`                       |                                                                                                                  |                                                                                                                                                                                                                                                                                 |\n",
      "| Using Convolutional Neural networks to Recognize Rhythm Stimuli form Electroencephalography Recordings, {cite}`stober_using_2014`  |                                                                                                                  |                                                                                                                                                                                                                                                                                 |\n",
      "| Convolutional deep belief networks for feature extraction of EEG signal, {cite}`ren_convolutional_2014`                            |                                                                                                                  |                                                                                                                                                                                                                                                                                 |\n",
      "| Deep feature learning using target priors with applications in ECoG signal decoding for BCI, {cite}`wang_deep_2013`                |                                                                                                                  |                                                                                                                                                                                                                                                                                 |\n",
      "| Convolutional neural networks for P300 detection with application to brain-computer interfaces, {cite}`cecotti_convolutional_2011` | Weights                                                                                                          | Spatial filters were similar for different architectures <br>Spatial filters were different (more focal, more diffuse) for different subjects                                                                                                                                   |\n"
     ]
    }
   ],
   "source": [
    "print(df.loc[1:, ['Study', 'Visualization type(s)', 'Visualization findings']].to_markdown(showindex=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| citet{tang_single-trial_2017}           |                                                                                                                  |                                                                                                                                                                                                                                                                                 |\n",
      "|{cite}`lawhern_eegnet:_2016`                      |                                                                                                                  |                                                                                                                                                                                                                                                                                 |\n",
      "|{cite}`sun_remembered_2016`                            | Weights (spatial)                                                                                                | Largest weights found over prefrontal and temporal cortex                                                                                                                                                                                                                                                                    |\n",
      "|{cite}`manor_multimodal_2016`             | Weights <br> Activations <br> Saliency maps by gradient                                                          | Weights showed typical P300 distribution <br>Activations were high at plausible times (300-500ms) <br>Saliency maps showed plausible spatio-temporal plots                                                                                                                      |\n",
      "|{cite}`tabar_novel_2017`                           | Weights (spatial + frequential)                                                                                  | Some weights represented difference of values of two electrodes on different sides of head                                                                                                                                                                                      |\n",
      "|{cite}`liang_predicting_2016`           | Weights <br> Clustering of weights                                                                               | Clusters of weights showed typical frequency band subdivision (delta, theta, alpha, beta, gamma)                                                                                                                                                                                |\n",
      "|{cite}`hajinoroozi_eeg-based_2016`    |                                                                                                                  |                                                                                                                                                                                                                                                                                 |\n",
      "|{cite}`antoniades_deep_2016`                                                    | Weights <br>Correlation weights and interictal epileptic discharges (IED) <br>Activations                        | Weights increasingly correlated with IED waveforms with increasing number of training iterations <br>Second layer captured more complex and well-defined epileptic shapes than first layer <br>IEDs led to highly synchronized activations for neighbouring electrodes          |\n",
      "|{cite}`thodoroff_learning_2016`                      | Input occlusion and effect on prediction accuracy                                                                | Allowed to locate areas critical for seizure                                                                                                                                                                                                                                    |\n",
      "|{cite}`george_single-trial_2016`                         | Weights (spatial)                                                                                                | Some filter weights had expected topographic distributions for P300 <br>Others filters had large weights on areas not traditionally associated with P300                                                                                                                        |\n",
      "|{cite}`page_wearable_2016`                  |                                                                                                                  |                                                                                                                                                                                                                                                                                 |\n",
      "|{cite}`bashivan_learning_2016`                | Inputs that maximally activate given filter <br>Activations of these inputs <br>\"Deconvolution\" for these inputs | Different filters were sensitive to different frequency bands <br>Later layers had more spatially localized activations <br>Learned features had noticeable links to well-known electrophysiological markers of cognitive load <br>                                             |\n",
      "|{cite}`stober_learning_2016`                                                             | Weights (spatial+3 timesteps, pretrained as autoencoder)                                                         | Different constraints led to different weights, one type of constraints could enforce weights that are similar across subjects; other type of constraints led to weights that have similar spatial topographies under different architectural configurations and preprocessings |\n",
      "|{cite}`manor_convolutional_2015`             | Weights <br> Mean and single-trial activations                                                                   | Spatiotemporal regularization led to softer peaks in weights <br>Spatial weights showed typical P300 distribution <br>Activations mostly had peaks at typical times (300-400ms)                                                                                                 |\n",
      "|{cite}`sakhavi_parallel_2015`                       |                                                                                                                  |                                                                                                                                                                                                                                                                                 |\n",
      "|{cite}`stober_using_2014`  |                                                                                                                  |                                                                                                                                                                                                                                                                                 |\n",
      "|{cite}`ren_convolutional_2014`                            |                                                                                                                  |                                                                                                                                                                                                                                                                                 |\n",
      "|{cite}`wang_deep_2013`                |                                                                                                                  |                                                                                                                                                                                                                                                                                 |\n",
      "|{cite}`cecotti_convolutional_2011` | Weights                                                                                                          | Spatial filters were similar for different architectures <br>Spatial filters were different (more focal, more diffuse) for different subjects                                                                                                                                   |\n"
     ]
    }
   ],
   "source": [
    "b = \"\"\"| Study                                                                                                                              | Visualization type(s)                                                                                            | Visualization findings                                                                                                                                                                                                                                                          |\n",
    "|:-----------------------------------------------------------------------------------------------------------------------------------|:-----------------------------------------------------------------------------------------------------------------|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| Single-trial EEG classification of motor imagery using deep convolutional neural networks, citet{tang_single-trial_2017}           |                                                                                                                  |                                                                                                                                                                                                                                                                                 |\n",
    "| EEGNet: A Compact Convolutional Network for EEG-based Brain-Computer Interfaces, {cite}`lawhern_eegnet:_2016`                      |                                                                                                                  |                                                                                                                                                                                                                                                                                 |\n",
    "| Remembered or Forgotten? –- An EEG-Based Computational Prediction Approach, {cite}`sun_remembered_2016`                            | Weights (spatial)                                                                                                | Largest weights found over prefrontal and temporal cortex                                                                                                                                                                                                                                                                    |\n",
    "| Multimodal Neural Network for Rapid Serial Visual Presentation Brain Computer Interface, {cite}`manor_multimodal_2016`             | Weights <br> Activations <br> Saliency maps by gradient                                                          | Weights showed typical P300 distribution <br>Activations were high at plausible times (300-500ms) <br>Saliency maps showed plausible spatio-temporal plots                                                                                                                      |\n",
    "| A novel deep learning approach for classification of EEG motor imagery signals, {cite}`tabar_novel_2017`                           | Weights (spatial + frequential)                                                                                  | Some weights represented difference of values of two electrodes on different sides of head                                                                                                                                                                                      |\n",
    "| Predicting Seizures from Electroencephalography Recordings: A Knowledge Transfer Strategy, {cite}`liang_predicting_2016`           | Weights <br> Clustering of weights                                                                               | Clusters of weights showed typical frequency band subdivision (delta, theta, alpha, beta, gamma)                                                                                                                                                                                |\n",
    "| EEG-based prediction of driver's cognitive performance by deep convolutional neural network, {cite}`hajinoroozi_eeg-based_2016`    |                                                                                                                  |                                                                                                                                                                                                                                                                                 |\n",
    "| Deep learning for epileptic intracranial EEG data, {cite}`antoniades_deep_2016`                                                    | Weights <br>Correlation weights and interictal epileptic discharges (IED) <br>Activations                        | Weights increasingly correlated with IED waveforms with increasing number of training iterations <br>Second layer captured more complex and well-defined epileptic shapes than first layer <br>IEDs led to highly synchronized activations for neighbouring electrodes          |\n",
    "| Learning Robust Features using Deep Learning for Automatic Seizure Detection, {cite}`thodoroff_learning_2016`                      | Input occlusion and effect on prediction accuracy                                                                | Allowed to locate areas critical for seizure                                                                                                                                                                                                                                    |\n",
    "| Single-trial EEG RSVP classification using convolutional neural networks, {cite}`george_single-trial_2016`                         | Weights (spatial)                                                                                                | Some filter weights had expected topographic distributions for P300 <br>Others filters had large weights on areas not traditionally associated with P300                                                                                                                        |\n",
    "| Wearable seizure detection using convolutional neural networks with transfer learning, {cite}`page_wearable_2016`                  |                                                                                                                  |                                                                                                                                                                                                                                                                                 |\n",
    "| Learning Representations from EEG with Deep Recurrent-Convolutional Neural Networks, {cite}`bashivan_learning_2016`                | Inputs that maximally activate given filter <br>Activations of these inputs <br>\"Deconvolution\" for these inputs | Different filters were sensitive to different frequency bands <br>Later layers had more spatially localized activations <br>Learned features had noticeable links to well-known electrophysiological markers of cognitive load <br>                                             |\n",
    "| Deep Feature Learning for EEG Recordings, {cite}`stober_learning_2016`                                                             | Weights (spatial+3 timesteps, pretrained as autoencoder)                                                         | Different constraints led to different weights, one type of constraints could enforce weights that are similar across subjects; other type of constraints led to weights that have similar spatial topographies under different architectural configurations and preprocessings |\n",
    "| Convolutional Neural Network for Multi-Category Rapid Serial Visual Presentation BCI, {cite}`manor_convolutional_2015`             | Weights <br> Mean and single-trial activations                                                                   | Spatiotemporal regularization led to softer peaks in weights <br>Spatial weights showed typical P300 distribution <br>Activations mostly had peaks at typical times (300-400ms)                                                                                                 |\n",
    "| Parallel Convolutional-Linear Neural Network for Motor Imagery Classification, {cite}`sakhavi_parallel_2015`                       |                                                                                                                  |                                                                                                                                                                                                                                                                                 |\n",
    "| Using Convolutional Neural networks to Recognize Rhythm Stimuli form Electroencephalography Recordings, {cite}`stober_using_2014`  |                                                                                                                  |                                                                                                                                                                                                                                                                                 |\n",
    "| Convolutional deep belief networks for feature extraction of EEG signal, {cite}`ren_convolutional_2014`                            |                                                                                                                  |                                                                                                                                                                                                                                                                                 |\n",
    "| Deep feature learning using target priors with applications in ECoG signal decoding for BCI, {cite}`wang_deep_2013`                |                                                                                                                  |                                                                                                                                                                                                                                                                                 |\n",
    "| Convolutional neural networks for P300 detection with application to brain-computer interfaces, {cite}`cecotti_convolutional_2011` | Weights                                                                                                          | Spatial filters were similar for different architectures <br>Spatial filters were different (more focal, more diffuse) for different subjects                                                                                                                                   |\"\"\"\n",
    "\n",
    "\n",
    "c = b.split('\\n')[2:]\n",
    "\n",
    "print('\\n'.join(['|' + l[l.index('cite') - 1:] for l in c]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visulization table with empty papers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Study                                                                                                                              | Visualization type(s)                                                                                            | Visualization findings   |\n",
    "|:-----------------------------------------------------------------------------------------------------------------------------------|:-----------------------------------------------------------------------------------------------------------------|:-------------------------|\n",
    "| {cite}`tang_single-trial_2017`          |                                                                                                                  |                                                                                                                                                                                                                                                                                 |\n",
    "|{cite}`lawhern_eegnet:_2016`                      |                                                                                                                  |                                                                                                                                                                                                                                                                                 |\n",
    "|{cite}`sun_remembered_2016`                            | Weights (spatial)                                                                                                | Largest weights found over prefrontal and temporal cortex                                                                                                                                                                                                                                                                    |\n",
    "|{cite}`manor_multimodal_2016`             | Weights <br> Activations <br> Saliency maps by gradient                                                          | Weights showed typical P300 distribution <br>Activations were high at plausible times (300-500ms) <br>Saliency maps showed plausible spatio-temporal plots                                                                                                                      |\n",
    "|{cite}`tabar_novel_2017`                           | Weights (spatial + frequential)                                                                                  | Some weights represented difference of values of two electrodes on different sides of head                                                                                                                                                                                      |\n",
    "|{cite}`liang_predicting_2016`           | Weights <br> Clustering of weights                                                                               | Clusters of weights showed typical frequency band subdivision (delta, theta, alpha, beta, gamma)                                                                                                                                                                                |\n",
    "|{cite}`hajinoroozi_eeg-based_2016`    |                                                                                                                  |                                                                                                                                                                                                                                                                                 |\n",
    "|{cite}`antoniades_deep_2016`                                                    | Weights <br>Correlation weights and interictal epileptic discharges (IED) <br>Activations                        | Weights increasingly correlated with IED waveforms with increasing number of training iterations <br>Second layer captured more complex and well-defined epileptic shapes than first layer <br>IEDs led to highly synchronized activations for neighbouring electrodes          |\n",
    "|{cite}`thodoroff_learning_2016`                      | Input occlusion and effect on prediction accuracy                                                                | Allowed to locate areas critical for seizure                                                                                                                                                                                                                                    |\n",
    "|{cite}`george_single-trial_2016`                         | Weights (spatial)                                                                                                | Some filter weights had expected topographic distributions for P300 <br>Others filters had large weights on areas not traditionally associated with P300                                                                                                                        |\n",
    "|{cite}`page_wearable_2016`                  |                                                                                                                  |                                                                                                                                                                                                                                                                                 |\n",
    "|{cite}`bashivan_learning_2016`                | Inputs that maximally activate given filter <br>Activations of these inputs <br>\"Deconvolution\" for these inputs | Different filters were sensitive to different frequency bands <br>Later layers had more spatially localized activations <br>Learned features had noticeable links to well-known electrophysiological markers of cognitive load <br>                                             |\n",
    "|{cite}`stober_learning_2016`                                                             | Weights (spatial+3 timesteps, pretrained as autoencoder)                                                         | Different constraints led to different weights, one type of constraints could enforce weights that are similar across subjects; other type of constraints led to weights that have similar spatial topographies under different architectural configurations and preprocessings |\n",
    "|{cite}`manor_convolutional_2015`             | Weights <br> Mean and single-trial activations                                                                   | Spatiotemporal regularization led to softer peaks in weights <br>Spatial weights showed typical P300 distribution <br>Activations mostly had peaks at typical times (300-400ms)                                                                                                 |\n",
    "|{cite}`sakhavi_parallel_2015`                       |                                                                                                                  |                                                                                                                                                                                                                                                                                 |\n",
    "|{cite}`stober_using_2014`  |                                                                                                                  |                                                                                                                                                                                                                                                                                 |\n",
    "|{cite}`ren_convolutional_2014`                            |                                                                                                                  |                                                                                                                                                                                                                                                                                 |\n",
    "|{cite}`wang_deep_2013`                |                                                                                                                  |                                                                                                                                                                                                                                                                                 |\n",
    "|{cite}`cecotti_convolutional_2011` | Weights                                                                                                          | Spatial filters were similar for different architectures <br>Spatial filters were different (more focal, more diffuse) for different subjects                                                                                                                                   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df.loc[:,'Input domain']\n",
    "\n",
    "import numpy as np\n",
    "a = np.array(a)[1:] # exclude our own study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array(['Time,  8–30 Hz ', 'Time, 0.1–40 Hz ', 'Time, 0.05–15 Hz ',\n",
    "       'Time, 0.3–20 Hz ', 'Frequency, 6–30 Hz ', ' Frequency, 0–200 Hz ',\n",
    "       'Time,  1–50 Hz ', ' Time,  0–100 HZ ',\n",
    "       'Frequency, mean amplitude for 0–7 Hz, 7–14 Hz, 14–49 Hz ',\n",
    "       'Time, 0.5–50 Hz ', 'Time,  0–128 Hz ',\n",
    "       ' Frequency, mean power for 4–7 Hz, 8–13 Hz, 13–30 Hz ',\n",
    "       'Time, 0.5–30Hz ', 'Time, 0.1–50 Hz ',\n",
    "       'Frequency, 4–40 Hz, using FBCSP ',\n",
    "       ' Time and frequency evaluated, 0-200 Hz ', 'Frequency, 8–30 Hz ',\n",
    "       'Time, 0.15–200 Hz ', ' Time, 0.1-20 Hz '])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "domain_strings = [s.split(',')[0] for s in a]\n",
    "start_fs = [float(re.sub(r'[a-z ]+',r'', re.split(r'[–-–-]',\" \".join(s.split(',')[1:]))[0])) for s in a]\n",
    "end_fs = [float(re.sub(r'[a-z HZFBCSP]+',r'', re.split(r'[–-–-]',\" \".join(s.split(',')[1:]))[1])) for s in a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import seaborn\n",
    "seaborn.set_palette('colorblind')\n",
    "seaborn.set_style('darkgrid')\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'png'\n",
    "#matplotlib.rcParams['figure.figsize'] = (12.0, 1.0)\n",
    "matplotlib.rcParams['font.size'] = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_mask = np.array(['freq' in s.lower() for s in domain_strings])\n",
    "time_mask = np.array(['time' in s.lower() for s in domain_strings])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.05, 'Input domains and frequency ranges in prior work')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rng = np.random.RandomState(98349384)\n",
    "color = 'grey'\n",
    "domain_strings = np.array(domain_strings)\n",
    "start_fs = np.array(start_fs)\n",
    "end_fs = np.array(end_fs)\n",
    "i_sort = np.flatnonzero(time_mask)[np.argsort(end_fs[time_mask])]\n",
    "for i, (d,s,e) in enumerate(zip(\n",
    "        domain_strings[i_sort], start_fs[i_sort], end_fs[i_sort])):\n",
    "    offset = 0.6*i/len(i_sort) - 0.3\n",
    "    plt.plot([offset,offset] , [s, e], marker='o', alpha=1, color=color, ls=':')\n",
    "i_sort = np.flatnonzero(freq_mask)[np.argsort(end_fs[freq_mask])]\n",
    "for i, (d,s,e) in enumerate(zip(\n",
    "        domain_strings[i_sort], start_fs[i_sort], end_fs[i_sort])):\n",
    "    offset = 0.6*i/len(i_sort) + 0.7\n",
    "    plt.plot([offset,offset] , [s, e], marker='o', alpha=1, color=color, ls=':')\n",
    "\n",
    "plt.xlim(-0.5,1.5)\n",
    "plt.xlabel(\"Input domain\")\n",
    "plt.ylabel(\"Frequency [Hz]\")\n",
    "plt.xticks([0,1], [\"Time\", \"Frequency\"], rotation=45)\n",
    "plt.title(\"Input domains and frequency ranges in prior work\", y=1.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(98349384)\n",
    "color = 'grey'\n",
    "for low_c, high_c in zip(low_conv_ls, high_conv_ls):\n",
    "    offset = rng.randn(1) * 0.1\n",
    "    tried_cs = np.arange(low_c, high_c+1)\n",
    "    plt.plot([offset,] * len(tried_cs), tried_cs, marker='o', alpha=0.5, color=color, ls=':')\n",
    "    \n",
    "for i_c, n_c in enumerate(bincount_conv):\n",
    "    plt.scatter(0.4, i_c, color=color, s=n_c*40)\n",
    "    plt.text(0.535, i_c, str(n_c)+ \"x\", ha='left', va='center')\n",
    "\n",
    "for low_c, high_c in zip(low_dense_ls, high_dense_ls):\n",
    "    offset = 1 + rng.randn(1) * 0.1\n",
    "    tried_cs = np.arange(low_c, high_c+1)\n",
    "    plt.plot([offset,] * len(tried_cs), tried_cs, marker='o', alpha=0.5, color=color, ls=':')\n",
    "    \n",
    "for i_c, n_c in enumerate(bincount_dense):\n",
    "    plt.scatter(1.4, i_c, color=color, s=n_c*40)\n",
    "    plt.text(1.535, i_c, str(n_c)+ \"x\", ha='left', va='center')\n",
    "\n",
    "plt.xlim(-0.5,2)\n",
    "plt.xlabel(\"Type of layer\")\n",
    "plt.ylabel(\"Number of layers\")\n",
    "plt.xticks([0,1], [\"Convolutional\", \"Dense\"], rotation=45)\n",
    "plt.yticks([1,2,3,4,5,6,7]);\n",
    "plt.title(\"Number of layers in prior works' architectures\", y=1.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## layer stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = np.array(df.loc[:, 'Conv/dense layers'])[1:] # exclude ourstudy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = np.array([' 2/2 ', ' 3/1 ', ' 2/2 ', ' 3/2 ', ' 1/1 ', ' 1/2 ', ' 1/3 ',\n",
    "       ' 1–2/2 ', ' 3/1 (+ LSTM as postprocessor) ', ' 4/3 ', ' 1-3/1-3 ',\n",
    "       ' 3–7/2 (+ LSTM or other temporal post-processing (see design choices)) ',\n",
    "       ' 2/1 ', ' 3/3 (Spatio-temporal regularization) ',\n",
    "       ' 2/2 (Final fully connected layer uses concatenated output by convolutionaland fully connected layers) ',\n",
    "       ' 1-2/1 ',\n",
    "       '2/0 (Convolutional deep belief network, separately trained RBF-SVM classifier) ',\n",
    "       ' 3/1 (Convolutional layers trained as convolutional stacked autoencoder with target prior) ',\n",
    "       ' 2/2 '])\n",
    "\n",
    "conv_ls = [l.split('/')[0] for l in ls]\n",
    "low_conv_ls = [int(re.split(r'[–-]', c)[0])for c in conv_ls]\n",
    "high_conv_ls = [int(re.split(r'[–-]', c)[-1])for c in conv_ls]\n",
    "dense_ls = [l.split('/')[1] for l in ls]\n",
    "low_dense_ls = [int(re.split(r'[–-]', c[:8])[0][:2])for c in dense_ls]\n",
    "high_dense_ls = [int(re.split(r'[–-]', c[:8])[-1][:2])for c in dense_ls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import seaborn\n",
    "seaborn.set_palette('colorblind')\n",
    "seaborn.set_style('darkgrid')\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'png'\n",
    "#matplotlib.rcParams['figure.figsize'] = (12.0, 1.0)\n",
    "matplotlib.rcParams['font.size'] = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_conv_ls = np.concatenate([np.arange(low_c, high_c+1) for low_c, high_c in zip(low_conv_ls, high_conv_ls)])\n",
    "all_dense_ls = np.concatenate([np.arange(low_c, high_c+1) for low_c, high_c in zip(low_dense_ls, high_dense_ls)])\n",
    "bincount_conv = np.bincount(all_conv_ls)\n",
    "bincount_dense = np.bincount(all_dense_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(98349384)\n",
    "color = 'grey'\n",
    "for low_c, high_c in zip(low_conv_ls, high_conv_ls):\n",
    "    offset = rng.randn(1) * 0.1\n",
    "    tried_cs = np.arange(low_c, high_c+1)\n",
    "    plt.plot([offset,] * len(tried_cs), tried_cs, marker='o', alpha=0.5, color=color, ls=':')\n",
    "    \n",
    "for i_c, n_c in enumerate(bincount_conv):\n",
    "    plt.scatter(0.4, i_c, color=color, s=n_c*40)\n",
    "    plt.text(0.535, i_c, str(n_c)+ \"x\", ha='left', va='center')\n",
    "\n",
    "for low_c, high_c in zip(low_dense_ls, high_dense_ls):\n",
    "    offset = 1 + rng.randn(1) * 0.1\n",
    "    tried_cs = np.arange(low_c, high_c+1)\n",
    "    plt.plot([offset,] * len(tried_cs), tried_cs, marker='o', alpha=0.5, color=color, ls=':')\n",
    "    \n",
    "for i_c, n_c in enumerate(bincount_dense):\n",
    "    plt.scatter(1.4, i_c, color=color, s=n_c*40)\n",
    "    plt.text(1.535, i_c, str(n_c)+ \"x\", ha='left', va='center')\n",
    "\n",
    "plt.xlim(-0.5,2)\n",
    "plt.xlabel(\"Type of layer\")\n",
    "plt.ylabel(\"Number of layers\")\n",
    "plt.xticks([0,1], [\"Convolutional\", \"Dense\"], rotation=45)\n",
    "plt.yticks([1,2,3,4,5,6,7]);\n",
    "plt.title(\"Number of layers in prior works' architectures\", y=1.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.loc[:, ['Study', 'Decoding problem', 'External baseline']].to_markdown(showindex=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Study                                                                                                                              | Decoding problem                                                                                                                     | External baseline                                                               |\n",
    "|:-----------------------------------------------------------------------------------------------------------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------|:--------------------------------------------------------------------------------|\n",
    "| This manuscript, Schirrmeister et. al (2017)                                                                                       | Imagined and executed movement classes, within subject                                                                               | FBCSP + rLDA                                                                    |\n",
    "| Single-trial EEG classification of motor imagery using deep convolutional neural networks, citet{tang_single-trial_2017}           | Imagined movement classes, within-subject                                                                                            | FBCSP                                                                           |\n",
    "| EEGNet: A Compact Convolutional Network for EEG-based Brain-Computer Interfaces, {cite}`lawhern_eegnet:_2016`                      | Oddball response (RSVP), error response (ERN), movement classes (voluntarily started and imagined)                                   |                                                                                 |\n",
    "| Remembered or Forgotten? –- An EEG-Based Computational Prediction Approach, {cite}`sun_remembered_2016`                            | Memory performance, within-subject                                                                                                   |                                                                                 |\n",
    "| Multimodal Neural Network for Rapid Serial Visual Presentation Brain Computer Interface, {cite}`manor_multimodal_2016`             | Oddball response using RSVP and image (combined image-EEG decoding), within-subject                                                  |                                                                                 |\n",
    "| A novel deep learning approach for classification of EEG motor imagery signals, {cite}`tabar_novel_2017`                           | Imagined and executed movement classes, within-subject                                                                               | Weights (spatial + frequential)                                                 |\n",
    "| Predicting Seizures from Electroencephalography Recordings: A Knowledge Transfer Strategy, {cite}`liang_predicting_2016`           | Seizure prediction, within-subject                                                                                                   |                                                                                 |\n",
    "| EEG-based prediction of driver's cognitive performance by deep convolutional neural network, {cite}`hajinoroozi_eeg-based_2016`    | Driver performance, within- and cross-subject                                                                                        |                                                                                 |\n",
    "| Deep learning for epileptic intracranial EEG data, {cite}`antoniades_deep_2016`                                                    | Epileptic discharges, cross-subject                                                                                                  |                                                                                 |\n",
    "| Learning Robust Features using Deep Learning for Automatic Seizure Detection, {cite}`thodoroff_learning_2016`                      | Start of epileptic seizure, within- and cross-subject                                                                                | Hand crafted features + SVM                                                     |\n",
    "| Single-trial EEG RSVP classification using convolutional neural networks, {cite}`george_single-trial_2016`                         | Oddball response (RSVP), groupwise (ConvNet trained on all subjects)                                                                 |                                                                                 |\n",
    "| Wearable seizure detection using convolutional neural networks with transfer learning, {cite}`page_wearable_2016`                  | Seizure detection, cross-subject, within-subject, groupwise                                                                          | Multiple: spectral features, higher order statistics + linear-SVM, RBF-SVM, ... |\n",
    "| Learning Representations from EEG with Deep Recurrent-Convolutional Neural Networks, {cite}`bashivan_learning_2016`                | Cognitive load (number of characters to memorize), cross-subject                                                                     |                                                                                 |\n",
    "| Deep Feature Learning for EEG Recordings, {cite}`stober_learning_2016`                                                             | Type of music rhythm, groupwise (ensembles of leave-one-subject-out trained models, evaluated on separate test set of same subjects) |                                                                                 |\n",
    "| Convolutional Neural Network for Multi-Category Rapid Serial Visual Presentation BCI, {cite}`manor_convolutional_2015`             | Oddball response (RSVP), within-subject                                                                                              |                                                                                 |\n",
    "| Parallel Convolutional-Linear Neural Network for Motor Imagery Classification, {cite}`sakhavi_parallel_2015`                       | Imagined movement classes, within-subject                                                                                            |                                                                                 |\n",
    "| Using Convolutional Neural networks to Recognize Rhythm Stimuli form Electroencephalography Recordings, {cite}`stober_using_2014`  | Type of music rhythm, within-subject                                                                                                 |                                                                                 |\n",
    "| Convolutional deep belief networks for feature extraction of EEG signal, {cite}`ren_convolutional_2014`                            | Imagined movement classes, within-subject                                                                                            |                                                                                 |\n",
    "| Deep feature learning using target priors with applications in ECoG signal decoding for BCI, {cite}`wang_deep_2013`                | Finger flexion trajectory (regression), within-subject                                                                               |                                                                                 |\n",
    "| Convolutional neural networks for P300 detection with application to brain-computer interfaces, {cite}`cecotti_convolutional_2011` | Oddball / attention response using P300 speller, within-subject                                                                      | Multiple: Linear SVM, gradient boosting, E-SVM, S-SVM, mLVQ, LDA, ...           |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
