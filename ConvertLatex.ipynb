{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## old, copied"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "|Study |  Decoding problem |External Baseline|\n",
    "| :--- | --- | --- |\n",
    "| This manuscript, Schirrmeister et. al (2017) |Imagined and executed movement classes, within subject |FBCSP + rLDA|\n",
    "| Single-trial EEG classification of motor imagery using deep convolutional neural networks, citet{tang_single-trial_2017} |Imagined movement classes, within-subject | FBCSP ||\n",
    "| EEGNet: A Compact Convolutional Network for EEG-based Brain-Computer Interfaces, {cite}`lawhern_eegnet:_2016` | Oddball response (RSVP), error response (ERN), movement classes (voluntarily started and imagined) | [recheck] |\n",
    "| Remembered or Forgotten? –- An EEG-Based Computational Prediction Approach, {cite}`sun_remembered_2016` | Memory performance, within-subject ||\n",
    "|Multimodal Neural Network for Rapid Serial Visual Presentation Brain Computer Interface, {cite}`manor_multimodal_2016`|Oddball response using RSVP and image (combined image-EEG decoding), within-subject|Time, 0.3–20 Hz | 3/2 | | |  | Weights <br> Activations <br> Saliency maps by gradient |Weights showed typical P300 distribution <br>Activations were high at plausible times (300-500ms) <br>Saliency maps showed plausible spatio-temporal plots\n",
    "| A novel deep learning approach for classification of EEG motor imagery signals, {cite}`tabar_novel_2017` |Imagined and executed movement classes, within-subject |Frequency, 6–30 Hz | 1/1 | multicolumn{2}{p{0.285\textwidth}}{Addition of six-layer stacked autoencoder on ConvNet features <br> Kernel sizes} | FBCSP, Twin SVM, DDFBS, Bi-spectrum, RQNN  | Weights (spatial + frequential) |Some weights represented difference of values of two electrodes on different sides of head\n",
    "| Predicting Seizures from Electroencephalography Recordings: A Knowledge Transfer Strategy, {cite}`liang_predicting_2016` |Seizure prediction, within-subject | Frequency, 0–200 Hz | 1/2 | | Different subdivisions of frequency range <br>Different lengths of time crops <br>Transfer learning with auxiliary non-epilepsy datasets || Weights <br> Clustering of weights |Clusters of weights showed typical frequency band subdivision (delta, theta, alpha, beta, gamma)\n",
    "| EEG-based prediction of driver's cognitive performance by deep convolutional neural network, {cite}`hajinoroozi_eeg-based_2016` |Driver performance, within- and cross-subject |Time,  1–50 Hz | 1/3 |multicolumn{2}{p{0.285\textwidth}}{Replacement of convolutional layers by restricted Boltzmann machines with slightly varied network architecture}  | |\n",
    "| Deep learning for epileptic intracranial EEG data, {cite}`antoniades_deep_2016` |Epileptic discharges, cross-subject | Time,  0–100 HZ | 1–2/2 | 1 or 2 convolutional layers |  | |Weights <br>Correlation weights and interictal epileptic discharges (IED) <br>Activations |Weights increasingly correlated with IED waveforms with increasing number of training iterations <br>Second layer captured more complex and well-defined epileptic shapes than first layer <br>IEDs led to highly synchronized activations for neighbouring electrodes\n",
    "| Learning Robust Features using Deep Learning for Automatic Seizure Detection, {cite}`thodoroff_learning_2016` |Start of epileptic seizure, within- and cross-subject |Frequency, mean amplitude for 0–7 Hz, 7–14 Hz, 14–49 Hz | 3/1 (+ LSTM as postprocessor) | | | Hand crafted features + SVM | Input occlusion and effect on prediction accuracy |Allowed to locate areas critical for seizure \n",
    "|Single-trial EEG RSVP classification using convolutional neural networks, {cite}`george_single-trial_2016` |Oddball response (RSVP), groupwise (ConvNet trained on all subjects) |Time, 0.5–50 Hz | 4/3 | |  |  |Weights (spatial) |Some filter weights had expected topographic distributions for P300 <br>Others filters had large weights on areas not traditionally associated with P300\n",
    "|Wearable seizure detection using convolutional neural networks with transfer learning, {cite}`page_wearable_2016` |Seizure detection, cross-subject, within-subject, groupwise |Time,  0–128 Hz | 1-3/1-3 | | Cross-subject supervised training, within-subject finetuning of fully connected layers |Multiple: spectral features, higher order statistics + linear-SVM, RBF-SVM, ...| | \n",
    "|Learning Representations from EEG with Deep Recurrent-Convolutional Neural Networks, {cite}`bashivan_learning_2016`  |Cognitive load (number of characters to memorize), cross-subject | Frequency, mean power for 4–7 Hz, 8–13 Hz, 13–30 Hz | 3–7/2 (+ LSTM or other temporal post-processing (see design choices)) |Number of convolutional layers <br>Temporal processing of ConvNet output by max pooling, temporal convolution, LSTM or temporal convolution + LSTM | | |Inputs that maximally activate given filter <br>Activations of these inputs <br>\"Deconvolution\" for these inputs |Different filters were sensitive to different frequency bands <br>Later layers had more spatially localized activations <br>Learned features had noticeable links to well-known electrophysiological markers of cognitive load <br>\n",
    "|Deep Feature Learning for EEG Recordings, {cite}`stober_learning_2016` |Type of music rhythm, groupwise (ensembles of leave-one-subject-out trained models, evaluated on separate test set of same subjects) |Time, 0.5–30Hz | 2/1 | Kernel sizes | Pretraining first layer as convolutional autoencoder with different constraints |  | Weights (spatial+3 timesteps, pretrained as autoencoder) | Different constraints led to different weights, one type of constraints could enforce weights that are similar across subjects; other type of constraints led to weights that have similar spatial topographies under different architectural configurations and preprocessings\n",
    "|Convolutional Neural Network for Multi-Category Rapid Serial Visual Presentation BCI, {cite}`manor_convolutional_2015` |Oddball response (RSVP), within-subject |Time, 0.1–50 Hz | 3/3 (Spatio-temporal regularization) || ||Weights <br> Mean and single-trial activations |Spatiotemporal regularization led to softer peaks in weights <br>Spatial weights showed typical P300 distribution <br>Activations mostly had peaks at typical times (300-400ms)\n",
    "|Parallel Convolutional-Linear Neural Network for Motor Imagery Classification, {cite}`sakhavi_parallel_2015`  |Imagined movement classes, within-subject |Frequency, 4–40 Hz, using FBCSP | 2/2 (Final fully connected layer uses concatenated output by convolutionaland fully connected layers) |Combination ConvNet and MLP (trained on different features) vs. only ConvNet vs. only MLP | | | | \n",
    "|Using Convolutional Neural networks to Recognize Rhythm Stimuli form Electroencephalography Recordings, {cite}`stober_using_2014` |Type of music rhythm, within-subject | Time and frequency evaluated, 0-200 Hz | 1-2/1 |Best values from automatic hyperparameter optimization: frequency cutoff, one vs two layers, kernel sizes, number of channels, pooling width |Best values from automatic hyperparameter optimization: learning rate, learning rate decay, momentum, final momentum ||\n",
    "|Convolutional deep belief networks for feature extraction of EEG signal, {cite}`ren_convolutional_2014`  |Imagined movement classes, within-subject |Frequency, 8–30 Hz |2/0 (Convolutional deep belief network, separately trained RBF-SVM classifier) | | \n",
    "|Deep feature learning using target priors with applications in ECoG signal decoding for BCI, {cite}`wang_deep_2013`  |Finger flexion trajectory (regression), within-subject |Time, 0.15–200 Hz | 3/1 (Convolutional layers trained as convolutional stacked autoencoder with target prior) |Partially supervised CSA | \n",
    "|Convolutional neural networks for P300 detection with application to brain-computer interfaces, {cite}`cecotti_convolutional_2011`  |Oddball / attention response using P300 speller, within-subject | Time, 0.1-20 Hz | 2/2 |Electrode subset (fixed or automatically determined) <br>Using only one spatial filter <br>Different ensembling strategies | |Multiple: Linear SVM, gradient boosting, E-SVM, S-SVM, mLVQ, LDA, ... |Weights |Spatial filters were similar for different architectures <br>Spatial filters were different (more focal, more diffuse) for different subjects\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "|Study |  Decoding problem |  Input domain |  Conv/dense layers |  Design choices |  Training strategies |  External baseline |  Visualization type(s) |  Visualization findings|\n",
    "| :--- | --- | --- | --- | --- | --- | --- | --- | --- | \n",
    "| This manuscript, Schirrmeister et. al (2017) |Imagined and executed movement classes, within subject |Time,  0–125 Hz | 5/1 |Different ConvNet architectures <br>Nonlinearities and pooling modes <br>Regularization and intermediate normalization layers <br>Factorized convolutions <br>Splitted vs one-step convolutions |Trial-wise vs. cropped training strategy |FBCSP + rLDA | Feature activation correlation <br>Feature-perturbation prediction correlation |See Section \\ref{subsec:results-visualization}\n",
    "| Single-trial EEG classification of motor imagery using deep convolutional neural networks, citet{tang_single-trial_2017} |Imagined movement classes, within-subject |Time,  8–30 Hz | 2/2 | | | FBCSP | | |\n",
    "| EEGNet: A Compact Convolutional Network for EEG-based Brain-Computer Interfaces, {cite}`lawhern_eegnet:_2016` | Oddball response (RSVP), error response (ERN), movement classes (voluntarily started and imagined) |Time, 0.1–40 Hz | 3/1 |  Kernel sizes | |   | |\n",
    "| Remembered or Forgotten? –- An EEG-Based Computational Prediction Approach, {cite}`sun_remembered_2016` | Memory performance, within-subject |Time, 0.05–15 Hz | 2/2 | | Different time windows |  |Weights (spatial) | Largest weights found over p\\refrontal and temporal cortex\n",
    "|Multimodal Neural Network for Rapid Serial Visual Presentation Brain Computer Interface, {cite}`manor_multimodal_2016`|Oddball response using RSVP and image (combined image-EEG decoding), within-subject|Time, 0.3–20 Hz | 3/2 | | |  | Weights <br> Activations <br> Saliency maps by gradient |Weights showed typical P300 distribution <br>Activations were high at plausible times (300-500ms) <br>Saliency maps showed plausible spatio-temporal plots\n",
    "| A novel deep learning approach for classification of EEG motor imagery signals, {cite}`tabar_novel_2017` |Imagined and executed movement classes, within-subject |Frequency, 6–30 Hz | 1/1 | multicolumn{2}{p{0.285\textwidth}}{Addition of six-layer stacked autoencoder on ConvNet features <br> Kernel sizes} | FBCSP, Twin SVM, DDFBS, Bi-spectrum, RQNN  | Weights (spatial + frequential) |Some weights represented difference of values of two electrodes on different sides of head\n",
    "| Predicting Seizures from Electroencephalography Recordings: A Knowledge Transfer Strategy, {cite}`liang_predicting_2016` |Seizure prediction, within-subject | Frequency, 0–200 Hz | 1/2 | | Different subdivisions of frequency range <br>Different lengths of time crops <br>Transfer learning with auxiliary non-epilepsy datasets || Weights <br> Clustering of weights |Clusters of weights showed typical frequency band subdivision (delta, theta, alpha, beta, gamma)\n",
    "| EEG-based prediction of driver's cognitive performance by deep convolutional neural network, {cite}`hajinoroozi_eeg-based_2016` |Driver performance, within- and cross-subject |Time,  1–50 Hz | 1/3 |multicolumn{2}{p{0.285\textwidth}}{Replacement of convolutional layers by restricted Boltzmann machines with slightly varied network architecture}  | |\n",
    "| Deep learning for epileptic intracranial EEG data, {cite}`antoniades_deep_2016` |Epileptic discharges, cross-subject | Time,  0–100 HZ | 1–2/2 | 1 or 2 convolutional layers |  | |Weights <br>Correlation weights and interictal epileptic discharges (IED) <br>Activations |Weights increasingly correlated with IED waveforms with increasing number of training iterations <br>Second layer captured more complex and well-defined epileptic shapes than first layer <br>IEDs led to highly synchronized activations for neighbouring electrodes\n",
    "| Learning Robust Features using Deep Learning for Automatic Seizure Detection, {cite}`thodoroff_learning_2016` |Start of epileptic seizure, within- and cross-subject |Frequency, mean amplitude for 0–7 Hz, 7–14 Hz, 14–49 Hz | 3/1 (+ LSTM as postprocessor) | | | Hand crafted features + SVM | Input occlusion and effect on prediction accuracy |Allowed to locate areas critical for seizure \n",
    "|Single-trial EEG RSVP classification using convolutional neural networks, {cite}`george_single-trial_2016` |Oddball response (RSVP), groupwise (ConvNet trained on all subjects) |Time, 0.5–50 Hz | 4/3 | |  |  |Weights (spatial) |Some filter weights had expected topographic distributions for P300 <br>Others filters had large weights on areas not traditionally associated with P300\n",
    "|Wearable seizure detection using convolutional neural networks with transfer learning, {cite}`page_wearable_2016` |Seizure detection, cross-subject, within-subject, groupwise |Time,  0–128 Hz | 1-3/1-3 | | Cross-subject supervised training, within-subject finetuning of fully connected layers |Multiple: spectral features, higher order statistics + linear-SVM, RBF-SVM, ...| | \n",
    "|Learning Representations from EEG with Deep Recurrent-Convolutional Neural Networks, {cite}`bashivan_learning_2016`  |Cognitive load (number of characters to memorize), cross-subject | Frequency, mean power for 4–7 Hz, 8–13 Hz, 13–30 Hz | 3–7/2 (+ LSTM or other temporal post-processing (see design choices)) |Number of convolutional layers <br>Temporal processing of ConvNet output by max pooling, temporal convolution, LSTM or temporal convolution + LSTM | | |Inputs that maximally activate given filter <br>Activations of these inputs <br>\"Deconvolution\" for these inputs |Different filters were sensitive to different frequency bands <br>Later layers had more spatially localized activations <br>Learned features had noticeable links to well-known electrophysiological markers of cognitive load <br>\n",
    "|Deep Feature Learning for EEG Recordings, {cite}`stober_learning_2016` |Type of music rhythm, groupwise (ensembles of leave-one-subject-out trained models, evaluated on separate test set of same subjects) |Time, 0.5–30Hz | 2/1 | Kernel sizes | Pretraining first layer as convolutional autoencoder with different constraints |  | Weights (spatial+3 timesteps, pretrained as autoencoder) | Different constraints led to different weights, one type of constraints could enforce weights that are similar across subjects; other type of constraints led to weights that have similar spatial topographies under different architectural configurations and preprocessings\n",
    "|Convolutional Neural Network for Multi-Category Rapid Serial Visual Presentation BCI, {cite}`manor_convolutional_2015` |Oddball response (RSVP), within-subject |Time, 0.1–50 Hz | 3/3 (Spatio-temporal regularization) || ||Weights <br> Mean and single-trial activations |Spatiotemporal regularization led to softer peaks in weights <br>Spatial weights showed typical P300 distribution <br>Activations mostly had peaks at typical times (300-400ms)\n",
    "|Parallel Convolutional-Linear Neural Network for Motor Imagery Classification, {cite}`sakhavi_parallel_2015`  |Imagined movement classes, within-subject |Frequency, 4–40 Hz, using FBCSP | 2/2 (Final fully connected layer uses concatenated output by convolutionaland fully connected layers) |Combination ConvNet and MLP (trained on different features) vs. only ConvNet vs. only MLP | | | | \n",
    "|Using Convolutional Neural networks to Recognize Rhythm Stimuli form Electroencephalography Recordings, {cite}`stober_using_2014` |Type of music rhythm, within-subject | Time and frequency evaluated, 0-200 Hz | 1-2/1 |Best values from automatic hyperparameter optimization: frequency cutoff, one vs two layers, kernel sizes, number of channels, pooling width |Best values from automatic hyperparameter optimization: learning rate, learning rate decay, momentum, final momentum ||\n",
    "|Convolutional deep belief networks for feature extraction of EEG signal, {cite}`ren_convolutional_2014`  |Imagined movement classes, within-subject |Frequency, 8–30 Hz |2/0 (Convolutional deep belief network, separately trained RBF-SVM classifier) | | \n",
    "|Deep feature learning using target priors with applications in ECoG signal decoding for BCI, {cite}`wang_deep_2013`  |Finger flexion trajectory (regression), within-subject |Time, 0.15–200 Hz | 3/1 (Convolutional layers trained as convolutional stacked autoencoder with target prior) |Partially supervised CSA | \n",
    "|Convolutional neural networks for P300 detection with application to brain-computer interfaces, {cite}`cecotti_convolutional_2011`  |Oddball / attention response using P300 speller, within-subject | Time, 0.1-20 Hz | 2/2 |Electrode subset (fixed or automatically determined) <br>Using only one spatial filter <br>Different ensembling strategies | |Multiple: Linear SVM, gradient boosting, E-SVM, S-SVM, mLVQ, LDA, ... |Weights |Spatial filters were similar for different architectures <br>Spatial filters were different (more focal, more diffuse) for different subjects\n",
    "|  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = r\"\"\"\n",
    "This manuscript, Schirrmeister et. al (2017) &\n",
    "Imagined and executed movement classes, within subject &\n",
    "Time, \\hspace{1cm} 0--125 Hz & 5/1 &\n",
    "Different ConvNet architectures \\cellbr\n",
    "Nonlinearities and pooling modes \\cellbr\n",
    "Regularization and intermediate normalization layers \\cellbr\n",
    "Factorized convolutions \\cellbr\n",
    "Splitted vs one-step convolutions &\n",
    "Trial-wise vs. cropped training strategy &\n",
    "FBCSP + rLDA & \n",
    "Feature activation correlation \\cellbr\n",
    "Feature-perturbation prediction correlation &\n",
    "See Section \\ref{subsec:results-visualization}\n",
    "\\\\\n",
    "\\hdashline \n",
    "\n",
    "Single-trial EEG classification of motor imagery using deep convolutional neural networks, \\citet{tang_single-trial_2017} &\n",
    "Imagined movement classes, within-subject &\n",
    "Time, \\hspace{1cm} 8--30 Hz & 2/2 & & \n",
    "& FBCSP & &\"\"\"\n",
    "\n",
    "b = a.replace(\"&\", \"|\").replace(\"\\n\", \"\").replace(\"\\cellbr\", \"<br>\").replace('\\hdashline', '\\n|').replace('\\\\', '')\n",
    "b = b.replace(\"ref\", r\"\\ref\").replace(\"--\", '–')\n",
    "b = re.sub(r'hspace{[^}]+}', r'', b)\n",
    "b = \"| \" + b + \" |\"\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"\"\"\n",
    "EEGNet: A Compact Convolutional Network for EEG-based Brain-Computer Interfaces, \\citet{lawhern_eegnet:_2016} & \n",
    "Oddball response (RSVP), error response (ERN), movement classes (voluntarily started and imagined) &\n",
    "Time, 0.1--40 Hz & 3/1 &  Kernel sizes & \n",
    "&   & &\n",
    "\\\\\n",
    "\\hdashline\n",
    " \n",
    "Remembered or Forgotten? --- An EEG-Based Computational Prediction Approach, \\citet{sun_remembered_2016} & \n",
    "Memory performance, within-subject &\n",
    "Time, 0.05--15 Hz & 2/2 & & Different time windows &  &\n",
    "Weights (spatial) & \n",
    "Largest weights found over prefrontal and temporal cortex\n",
    "\\\\\n",
    "\\hdashline\n",
    "\n",
    "Multimodal Neural Network for Rapid Serial Visual Presentation Brain Computer Interface, \\citet{manor_multimodal_2016}\n",
    "&\n",
    "Oddball response using RSVP and image (combined image-EEG decoding), within-subject&\n",
    "Time, 0.3--20 Hz & 3/2 & & &  & \n",
    "Weights \\cellbr Activations \\cellbr Saliency maps by gradient &\n",
    "Weights showed typical P300 distribution \\cellbr\n",
    "Activations were high at plausible times (300-500ms) \\cellbr\n",
    "Saliency maps showed plausible spatio-temporal plots\n",
    "\\\\\n",
    "\\hdashline\n",
    " \n",
    "A novel deep learning approach for classification of EEG motor imagery signals, \\citet{tabar_novel_2017} &\n",
    "Imagined and executed movement classes, within-subject &\n",
    "Frequency, 6--30 Hz & 1/1 & \n",
    "\\multicolumn{2}{p{0.285\\textwidth}}{Addition of six-layer stacked autoencoder on ConvNet features \\cellbr Kernel sizes} \n",
    "& FBCSP, Twin SVM, DDFBS, Bi-spectrum, RQNN  & Weights (spatial + frequential) &\n",
    "Some weights represented difference of values of two electrodes on different sides of head\n",
    "\\\\\n",
    "\\hdashline\n",
    " \n",
    "Predicting Seizures from Electroencephalography Recordings: A Knowledge Transfer Strategy, \\citet{liang_predicting_2016} &\n",
    "Seizure prediction, within-subject & Frequency, 0--200 Hz & 1/2 & & \n",
    "Different subdivisions of frequency range \\cellbr\n",
    "Different lengths of time crops \\cellbr\n",
    "Transfer learning with auxiliary non-epilepsy datasets &\n",
    "& Weights \\cellbr Clustering of weights &\n",
    "Clusters of weights showed typical frequency band subdivision (delta, theta, alpha, beta, gamma)\n",
    "\\\\\n",
    "\\hdashline\n",
    " \n",
    "EEG-based prediction of driver's cognitive performance by deep convolutional neural network, \\citet{hajinoroozi_eeg-based_2016} &\n",
    "Driver performance, within- and cross-subject &\n",
    "Time, \\hspace{1cm} 1--50 Hz & 1/3 &\n",
    "\\multicolumn{2}{p{0.285\\textwidth}}{Replacement of convolutional layers by restricted Boltzmann machines with slightly varied network architecture}  & \n",
    "&\n",
    "\\\\\n",
    "\\hdashline\n",
    " \n",
    "Deep learning for epileptic intracranial EEG data, \\citet{antoniades_deep_2016} &\n",
    "Epileptic discharges, cross-subject & Time, \\hspace{1cm} 0--100 HZ & 1--2/2 & 1 or 2 convolutional layers &  & &\n",
    "Weights \\cellbr\n",
    "Correlation weights and interictal epileptic discharges (IED) \\cellbr\n",
    "Activations &\n",
    "Weights increasingly correlated with IED waveforms with increasing number of training iterations \\cellbr\n",
    "Second layer captured more complex and well-defined epileptic shapes than first layer \\cellbr\n",
    "IEDs led to highly synchronized activations for neighbouring electrodes\n",
    "\\\\\n",
    "\\hdashline\n",
    " \n",
    "Learning Robust Features using Deep Learning for Automatic Seizure Detection, \\citet{thodoroff_learning_2016} &\n",
    "Start of epileptic seizure, within- and cross-subject &\n",
    "Frequency, mean amplitude for 0--7 Hz, 7--14 Hz, 14--49 Hz & 3/1 (+ LSTM as postprocessor) & &\n",
    " & Hand crafted features + SVM & Input occlusion and effect on prediction accuracy &\n",
    "Allowed to locate areas critical for seizure \n",
    "\\\\\n",
    "\\hdashline\n",
    "\n",
    "Single-trial EEG RSVP classification using convolutional neural networks, \\citet{george_single-trial_2016} &\n",
    "Oddball response (RSVP), groupwise (ConvNet trained on all subjects) &\n",
    "Time, 0.5--50 Hz & 4/3 & &  &  &\n",
    "Weights (spatial) &\n",
    "Some filter weights had expected topographic distributions for P300 \\cellbr\n",
    "Others filters had large weights on areas not traditionally associated with P300\n",
    "\\\\\n",
    "\\hdashline\n",
    "\n",
    "Wearable seizure detection using convolutional neural networks with transfer learning, \\citet{page_wearable_2016} &\n",
    "Seizure detection, cross-subject, within-subject, groupwise &\n",
    "Time, \\hspace{1cm} 0--128 Hz & 1-3/1-3 & & Cross-subject supervised training, within-subject finetuning of fully connected layers &\n",
    "Multiple: spectral features, higher order statistics + linear-SVM, RBF-SVM, ...& & \n",
    "\\\\\n",
    "\\hdashline\n",
    "\n",
    "Learning Representations from EEG with Deep Recurrent-Convolutional Neural Networks, \\citet{bashivan_learning_2016}  &\n",
    "Cognitive load (number of characters to memorize), cross-subject & \n",
    "Frequency, mean power for 4--7 Hz, 8--13 Hz, 13--30 Hz & 3--7/2 (+ LSTM or other temporal post-processing (see design choices)) &\n",
    "Number of convolutional layers \\cellbr\n",
    "Temporal processing of ConvNet output by max pooling, temporal convolution, LSTM or temporal convolution + LSTM & & &\n",
    "Inputs that maximally activate given filter \\cellbr\n",
    "Activations of these inputs \\cellbr\n",
    "\"Deconvolution\" for these inputs &\n",
    "Different filters were sensitive to different frequency bands \\cellbr\n",
    "Later layers had more spatially localized activations \\cellbr\n",
    "Learned features had noticeable links to well-known electrophysiological markers of cognitive load \\cellbr\n",
    "\\\\\n",
    "\\hdashline\n",
    "\n",
    "Deep Feature Learning for EEG Recordings, \\citet{stober_learning_2016} &\n",
    "Type of music rhythm, groupwise (ensembles of leave-one-subject-out trained models, evaluated on separate test set of same subjects) &\n",
    "Time, 0.5--30Hz & 2/1 & Kernel sizes & \n",
    "Pretraining first layer as convolutional autoencoder with different constraints &  & \n",
    "Weights (spatial+3 timesteps, pretrained as autoencoder) & \n",
    "Different constraints led to different weights, one type of constraints could enforce weights that are similar across subjects; other type of constraints led to weights that have similar spatial topographies under different architectural configurations and preprocessings\n",
    "\\\\\n",
    "\\hdashline\n",
    "\n",
    "Convolutional Neural Network for Multi-Category Rapid Serial Visual Presentation BCI, \\citet{manor_convolutional_2015} &\n",
    "Oddball response (RSVP), within-subject &\n",
    "Time, 0.1--50 Hz & 3/3 (Spatio-temporal regularization) && &&\n",
    "Weights \\cellbr Mean and single-trial activations &\n",
    "Spatiotemporal regularization led to softer peaks in weights \\cellbr\n",
    "Spatial weights showed typical P300 distribution \\cellbr\n",
    "Activations mostly had peaks at typical times (300-400ms)\n",
    "\\\\\n",
    "\\hdashline\n",
    "\n",
    "Parallel Convolutional-Linear Neural Network for Motor Imagery Classification, \\citet{sakhavi_parallel_2015}  &\n",
    "Imagined movement classes, within-subject &\n",
    "Frequency, 4--40 Hz, using FBCSP & 2/2 (Final fully connected layer uses concatenated output by convolutional\n",
    "and fully connected layers) &\n",
    "Combination ConvNet and MLP (trained on different features) vs. only ConvNet vs. only MLP & \n",
    "& & & \n",
    "\\\\\n",
    "\\hdashline\n",
    "\n",
    "Using Convolutional Neural networks to Recognize Rhythm Stimuli form Electroencephalography Recordings, \\citet{stober_using_2014} &\n",
    "Type of music rhythm, within-subject & Time and frequency evaluated, 0-200 Hz & 1-2/1 &\n",
    "Best values from automatic hyperparameter optimization: frequency cutoff, one vs two layers, kernel sizes, number of channels, pooling width &\n",
    "Best values from automatic hyperparameter optimization: learning rate, learning rate decay, momentum, final momentum &\n",
    "&\n",
    "\\\\\n",
    "\\hdashline\n",
    "\n",
    "Convolutional deep belief networks for feature extraction of EEG signal, \\citet{ren_convolutional_2014}  &\n",
    "Imagined movement classes, within-subject &\n",
    "Frequency, 8--30 Hz &\n",
    "2/0 (Convolutional deep belief network, separately trained RBF-SVM classifier) & & \n",
    "\\\\\n",
    "\\hdashline\n",
    "\n",
    "Deep feature learning using target priors with applications in ECoG signal decoding for BCI, \\citet{wang_deep_2013}  &\n",
    "Finger flexion trajectory (regression), within-subject &\n",
    "Time, 0.15--200 Hz & 3/1 (Convolutional layers trained as convolutional stacked autoencoder with target prior) &\n",
    "Partially supervised CSA & \n",
    "\\\\\n",
    "\\hdashline\n",
    "\n",
    "Convolutional neural networks for P300 detection with application to brain-computer interfaces, \\citet{cecotti_convolutional_2011}  &\n",
    "Oddball / attention response using P300 speller, within-subject & Time, 0.1-20 Hz & 2/2 &\n",
    "Electrode subset (fixed or automatically determined) \\cellbr\n",
    "Using only one spatial filter \\cellbr\n",
    "Different ensembling strategies & \n",
    "&\n",
    "Multiple: Linear SVM, gradient boosting, E-SVM, S-SVM, mLVQ, LDA, ... &\n",
    "Weights &\n",
    "Spatial filters were similar for different architectures \\cellbr\n",
    "Spatial filters were different (more focal, more diffuse) for different subjects\n",
    "\\\\\n",
    "\\hdashline\n",
    " \"\"\"\n",
    "\n",
    "b = a.replace(\"&\", \"|\").replace(\"\\n\", \"\").replace(\"\\cellbr\", \"<br>\").replace('\\hdashline', '\\n|').replace('\\\\', '')\n",
    "b = b.replace(\"ref\", r\"\\ref\").replace(\"--\", '–').replace(\"cite\", r\"\\cite\").replace(\"citet\", r\"cite\")\n",
    "b = re.sub(r'hspace{[^}]+}', r'', b)\n",
    "b = re.sub(r\"\\\\cite{([^}]+)}\", \"{cite}`\\g<1>`\", b)\n",
    "b = \"| \" + b + \" |\"\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a =  \"network, \\cite{hajinoroozi_eeg-based_2016} |D\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.sub(r\"\\\\cite{([^}]+)}\", \"{cite}`\\g<1>`\", a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"\"\"\n",
    "| This manuscript, Schirrmeister et. al (2017) |Imagined and executed movement classes, within subject |Time,  0–125 Hz | 5/1 |Different ConvNet architectures <br>Nonlinearities and pooling modes <br>Regularization and intermediate normalization layers <br>Factorized convolutions <br>Splitted vs one-step convolutions |Trial-wise vs. cropped training strategy |FBCSP + rLDA | Feature activation correlation <br>Feature-perturbation prediction correlation |See Section \\ref{subsec:results-visualization}\n",
    "| Single-trial EEG classification of motor imagery using deep convolutional neural networks, citet{tang_single-trial_2017} |Imagined movement classes, within-subject |Time,  8–30 Hz | 2/2 | | | FBCSP | | |\n",
    "| EEGNet: A Compact Convolutional Network for EEG-based Brain-Computer Interfaces, {cite}`lawhern_eegnet:_2016` | Oddball response (RSVP), error response (ERN), movement classes (voluntarily started and imagined) |Time, 0.1–40 Hz | 3/1 |  Kernel sizes | |   | |\n",
    "| Remembered or Forgotten? –- An EEG-Based Computational Prediction Approach, {cite}`sun_remembered_2016` | Memory performance, within-subject |Time, 0.05–15 Hz | 2/2 | | Different time windows |  |Weights (spatial) | Largest weights found over p\\refrontal and temporal cortex\n",
    "|Multimodal Neural Network for Rapid Serial Visual Presentation Brain Computer Interface, {cite}`manor_multimodal_2016`|Oddball response using RSVP and image (combined image-EEG decoding), within-subject|Time, 0.3–20 Hz | 3/2 | | |  | Weights <br> Activations <br> Saliency maps by gradient |Weights showed typical P300 distribution <br>Activations were high at plausible times (300-500ms) <br>Saliency maps showed plausible spatio-temporal plots\n",
    "| A novel deep learning approach for classification of EEG motor imagery signals, {cite}`tabar_novel_2017` |Imagined and executed movement classes, within-subject |Frequency, 6–30 Hz | 1/1 |Addition of six-layer stacked autoencoder on ConvNet features <br> Kernel sizes} |  | FBCSP, Twin SVM, DDFBS, Bi-spectrum, RQNN  | Weights (spatial + frequential) |Some weights represented difference of values of two electrodes on different sides of head\n",
    "| Predicting Seizures from Electroencephalography Recordings: A Knowledge Transfer Strategy, {cite}`liang_predicting_2016` |Seizure prediction, within-subject | Frequency, 0–200 Hz | 1/2 | | Different subdivisions of frequency range <br>Different lengths of time crops <br>Transfer learning with auxiliary non-epilepsy datasets || Weights <br> Clustering of weights |Clusters of weights showed typical frequency band subdivision (delta, theta, alpha, beta, gamma)\n",
    "| EEG-based prediction of driver's cognitive performance by deep convolutional neural network, {cite}`hajinoroozi_eeg-based_2016` |Driver performance, within- and cross-subject |Time,  1–50 Hz | 1/3 |Replacement of convolutional layers by restricted Boltzmann machines with slightly varied network architecture}  | | |\n",
    "| Deep learning for epileptic intracranial EEG data, {cite}`antoniades_deep_2016` |Epileptic discharges, cross-subject | Time,  0–100 HZ | 1–2/2 | 1 or 2 convolutional layers |  | |Weights <br>Correlation weights and interictal epileptic discharges (IED) <br>Activations |Weights increasingly correlated with IED waveforms with increasing number of training iterations <br>Second layer captured more complex and well-defined epileptic shapes than first layer <br>IEDs led to highly synchronized activations for neighbouring electrodes\n",
    "| Learning Robust Features using Deep Learning for Automatic Seizure Detection, {cite}`thodoroff_learning_2016` |Start of epileptic seizure, within- and cross-subject |Frequency, mean amplitude for 0–7 Hz, 7–14 Hz, 14–49 Hz | 3/1 (+ LSTM as postprocessor) | | | Hand crafted features + SVM | Input occlusion and effect on prediction accuracy |Allowed to locate areas critical for seizure \n",
    "|Single-trial EEG RSVP classification using convolutional neural networks, {cite}`george_single-trial_2016` |Oddball response (RSVP), groupwise (ConvNet trained on all subjects) |Time, 0.5–50 Hz | 4/3 | |  |  |Weights (spatial) |Some filter weights had expected topographic distributions for P300 <br>Others filters had large weights on areas not traditionally associated with P300\n",
    "|Wearable seizure detection using convolutional neural networks with transfer learning, {cite}`page_wearable_2016` |Seizure detection, cross-subject, within-subject, groupwise |Time,  0–128 Hz | 1-3/1-3 | | Cross-subject supervised training, within-subject finetuning of fully connected layers |Multiple: spectral features, higher order statistics + linear-SVM, RBF-SVM, ...| | \n",
    "|Learning Representations from EEG with Deep Recurrent-Convolutional Neural Networks, {cite}`bashivan_learning_2016`  |Cognitive load (number of characters to memorize), cross-subject | Frequency, mean power for 4–7 Hz, 8–13 Hz, 13–30 Hz | 3–7/2 (+ LSTM or other temporal post-processing (see design choices)) |Number of convolutional layers <br>Temporal processing of ConvNet output by max pooling, temporal convolution, LSTM or temporal convolution + LSTM | | |Inputs that maximally activate given filter <br>Activations of these inputs <br>\"Deconvolution\" for these inputs |Different filters were sensitive to different frequency bands <br>Later layers had more spatially localized activations <br>Learned features had noticeable links to well-known electrophysiological markers of cognitive load <br>\n",
    "|Deep Feature Learning for EEG Recordings, {cite}`stober_learning_2016` |Type of music rhythm, groupwise (ensembles of leave-one-subject-out trained models, evaluated on separate test set of same subjects) |Time, 0.5–30Hz | 2/1 | Kernel sizes | Pretraining first layer as convolutional autoencoder with different constraints |  | Weights (spatial+3 timesteps, pretrained as autoencoder) | Different constraints led to different weights, one type of constraints could enforce weights that are similar across subjects; other type of constraints led to weights that have similar spatial topographies under different architectural configurations and preprocessings\n",
    "|Convolutional Neural Network for Multi-Category Rapid Serial Visual Presentation BCI, {cite}`manor_convolutional_2015` |Oddball response (RSVP), within-subject |Time, 0.1–50 Hz | 3/3 (Spatio-temporal regularization) || ||Weights <br> Mean and single-trial activations |Spatiotemporal regularization led to softer peaks in weights <br>Spatial weights showed typical P300 distribution <br>Activations mostly had peaks at typical times (300-400ms)\n",
    "|Parallel Convolutional-Linear Neural Network for Motor Imagery Classification, {cite}`sakhavi_parallel_2015`  |Imagined movement classes, within-subject |Frequency, 4–40 Hz, using FBCSP | 2/2 (Final fully connected layer uses concatenated output by convolutionaland fully connected layers) |Combination ConvNet and MLP (trained on different features) vs. only ConvNet vs. only MLP | | | | \n",
    "|Using Convolutional Neural networks to Recognize Rhythm Stimuli form Electroencephalography Recordings, {cite}`stober_using_2014` |Type of music rhythm, within-subject | Time and frequency evaluated, 0-200 Hz | 1-2/1 |Best values from automatic hyperparameter optimization: frequency cutoff, one vs two layers, kernel sizes, number of channels, pooling width |Best values from automatic hyperparameter optimization: learning rate, learning rate decay, momentum, final momentum ||\n",
    "|Convolutional deep belief networks for feature extraction of EEG signal, {cite}`ren_convolutional_2014`  |Imagined movement classes, within-subject |Frequency, 8–30 Hz |2/0 (Convolutional deep belief network, separately trained RBF-SVM classifier) | | \n",
    "|Deep feature learning using target priors with applications in ECoG signal decoding for BCI, {cite}`wang_deep_2013`  |Finger flexion trajectory (regression), within-subject |Time, 0.15–200 Hz | 3/1 (Convolutional layers trained as convolutional stacked autoencoder with target prior) |Partially supervised CSA | \n",
    "|Convolutional neural networks for P300 detection with application to brain-computer interfaces, {cite}`cecotti_convolutional_2011`  |Oddball / attention response using P300 speller, within-subject | Time, 0.1-20 Hz | 2/2 |Electrode subset (fixed or automatically determined) <br>Using only one spatial filter <br>Different ensembling strategies | |Multiple: Linear SVM, gradient boosting, E-SVM, S-SVM, mLVQ, LDA, ... |Weights |Spatial filters were similar for different architectures <br>Spatial filters were different (more focal, more diffuse) for different subjects\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parts = [l.split('|')[1:-1] for l in a.split('\\n')[1:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[len(p) for p in parts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headings = ['Study', 'Decoding problem', 'Input domain', 'Conv/dense layers', 'Design choices', \n",
    "'Training strategies', 'External baseline', 'Visualization type(s)', 'Visualization findings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parts = [p + [''] * (9 - len(p)) for p in parts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip(headings, parts[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[len(p) for p in parts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "part_arr = np.array(parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df  = pd.DataFrame(data=part_arr, columns=headings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.loc[:, ['Study', 'Design choices', 'Training strategies']].to_markdown(showindex=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Study                                                                                                                              | Design choices                                                                                                                                                                                  | Training strategies                                                                                                                      |\n",
    "|:-----------------------------------------------------------------------------------------------------------------------------------|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:-----------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| EEGNet: A Compact Convolutional Network for EEG-based Brain-Computer Interfaces, {cite}`lawhern_eegnet:_2016`                      | Kernel sizes                                                                                                                                                                                    |                                                                                                                                          |\n",
    "| Remembered or Forgotten? –- An EEG-Based Computational Prediction Approach, {cite}`sun_remembered_2016`                            |                                                                                                                                                                                                 | Different time windows                                                                                                                   |\n",
    "| A novel deep learning approach for classification of EEG motor imagery signals, {cite}`tabar_novel_2017`                           | Addition of six-layer stacked autoencoder on ConvNet features <br> Kernel sizes}                                                                                                                |                                                                                                                                          |\n",
    "| Predicting Seizures from Electroencephalography Recordings: A Knowledge Transfer Strategy, {cite}`liang_predicting_2016`           |                                                                                                                                                                                                 | Different subdivisions of frequency range <br>Different lengths of time crops <br>Transfer learning with auxiliary non-epilepsy datasets |\n",
    "| EEG-based prediction of driver's cognitive performance by deep convolutional neural network, {cite}`hajinoroozi_eeg-based_2016`    | Replacement of convolutional layers by restricted Boltzmann machines with slightly varied network architecture}                                                                                 |                                                                                                                                          |\n",
    "| Deep learning for epileptic intracranial EEG data, {cite}`antoniades_deep_2016`                                                    | 1 or 2 convolutional layers                                                                                                                                                                     |                                                                                                                                          |\n",
    "| Wearable seizure detection using convolutional neural networks with transfer learning, {cite}`page_wearable_2016`                  |                                                                                                                                                                                                 | Cross-subject supervised training, within-subject finetuning of fully connected layers                                                   |\n",
    "| Learning Representations from EEG with Deep Recurrent-Convolutional Neural Networks, {cite}`bashivan_learning_2016`                | Number of convolutional layers <br>Temporal processing of ConvNet output by max pooling, temporal convolution, LSTM or temporal convolution + LSTM                                              |                                                                                                                                          |\n",
    "| Deep Feature Learning for EEG Recordings, {cite}`stober_learning_2016`                                                             | Kernel sizes                                                                                                                                                                                    | Pretraining first layer as convolutional autoencoder with different constraints                                                          |\n",
    "| Parallel Convolutional-Linear Neural Network for Motor Imagery Classification, {cite}`sakhavi_parallel_2015`                       | Combination ConvNet and MLP (trained on different features) vs. only ConvNet vs. only MLP                                                                                                       |                                                                                                                                          |\n",
    "| Using Convolutional Neural networks to Recognize Rhythm Stimuli form Electroencephalography Recordings, {cite}`stober_using_2014`  | Best values from automatic hyperparameter optimization: frequency cutoff, one vs two layers, kernel sizes, number of channels, pooling width                                                    | Best values from automatic hyperparameter optimization: learning rate, learning rate decay, momentum, final momentum                     |\n",
    "| Deep feature learning using target priors with applications in ECoG signal decoding for BCI, {cite}`wang_deep_2013`                | Partially supervised CSA                                                                                                                                                                        |                                                                                                                                          |\n",
    "| Convolutional neural networks for P300 detection with application to brain-computer interfaces, {cite}`cecotti_convolutional_2011` | Electrode subset (fixed or automatically determined) <br>Using only one spatial filter <br>Different ensembling strategies                                                                      |                                                                                                                                          |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df.loc[:,'Input domain']\n",
    "\n",
    "import numpy as np\n",
    "a = np.array(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_strings = [s.split(',')[0] for s in a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_fs = [float(re.sub(r'[a-z ]+',r'', re.split(r'[–-–-]',\" \".join(s.split(',')[1:]))[0])) for s in a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_fs = [float(re.sub(r'[a-z HZFBCSP]+',r'', re.split(r'[–-–-]',\" \".join(s.split(',')[1:]))[1])) for s in a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import seaborn\n",
    "seaborn.set_palette('colorblind')\n",
    "seaborn.set_style('darkgrid')\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'png'\n",
    "#matplotlib.rcParams['figure.figsize'] = (12.0, 1.0)\n",
    "matplotlib.rcParams['font.size'] = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d,s,e in zip(domain_strings, start_fs, end_fs):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(98349384)\n",
    "color = 'grey'\n",
    "for low_c, high_c in zip(low_conv_ls, high_conv_ls):\n",
    "    offset = rng.randn(1) * 0.1\n",
    "    tried_cs = np.arange(low_c, high_c+1)\n",
    "    plt.plot([offset,] * len(tried_cs), tried_cs, marker='o', alpha=0.5, color=color, ls=':')\n",
    "    \n",
    "for i_c, n_c in enumerate(bincount_conv):\n",
    "    plt.scatter(0.4, i_c, color=color, s=n_c*40)\n",
    "    plt.text(0.535, i_c, str(n_c)+ \"x\", ha='left', va='center')\n",
    "\n",
    "for low_c, high_c in zip(low_dense_ls, high_dense_ls):\n",
    "    offset = 1 + rng.randn(1) * 0.1\n",
    "    tried_cs = np.arange(low_c, high_c+1)\n",
    "    plt.plot([offset,] * len(tried_cs), tried_cs, marker='o', alpha=0.5, color=color, ls=':')\n",
    "    \n",
    "for i_c, n_c in enumerate(bincount_dense):\n",
    "    plt.scatter(1.4, i_c, color=color, s=n_c*40)\n",
    "    plt.text(1.535, i_c, str(n_c)+ \"x\", ha='left', va='center')\n",
    "\n",
    "plt.xlim(-0.5,2)\n",
    "plt.xlabel(\"Type of layer\")\n",
    "plt.ylabel(\"Number of layers\")\n",
    "plt.xticks([0,1], [\"Convolutional\", \"Dense\"], rotation=45)\n",
    "plt.yticks([1,2,3,4,5,6,7]);\n",
    "plt.title(\"Number of layers in prior works' architectures\", y=1.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## layer stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = np.array(df.loc[:, 'Conv/dense layers'])[1:] # exclude ourstudy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = np.array([' 2/2 ', ' 3/1 ', ' 2/2 ', ' 3/2 ', ' 1/1 ', ' 1/2 ', ' 1/3 ',\n",
    "       ' 1–2/2 ', ' 3/1 (+ LSTM as postprocessor) ', ' 4/3 ', ' 1-3/1-3 ',\n",
    "       ' 3–7/2 (+ LSTM or other temporal post-processing (see design choices)) ',\n",
    "       ' 2/1 ', ' 3/3 (Spatio-temporal regularization) ',\n",
    "       ' 2/2 (Final fully connected layer uses concatenated output by convolutionaland fully connected layers) ',\n",
    "       ' 1-2/1 ',\n",
    "       '2/0 (Convolutional deep belief network, separately trained RBF-SVM classifier) ',\n",
    "       ' 3/1 (Convolutional layers trained as convolutional stacked autoencoder with target prior) ',\n",
    "       ' 2/2 '])\n",
    "\n",
    "conv_ls = [l.split('/')[0] for l in ls]\n",
    "low_conv_ls = [int(re.split(r'[–-]', c)[0])for c in conv_ls]\n",
    "high_conv_ls = [int(re.split(r'[–-]', c)[-1])for c in conv_ls]\n",
    "dense_ls = [l.split('/')[1] for l in ls]\n",
    "low_dense_ls = [int(re.split(r'[–-]', c[:8])[0][:2])for c in dense_ls]\n",
    "high_dense_ls = [int(re.split(r'[–-]', c[:8])[-1][:2])for c in dense_ls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import seaborn\n",
    "seaborn.set_palette('colorblind')\n",
    "seaborn.set_style('darkgrid')\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'png'\n",
    "#matplotlib.rcParams['figure.figsize'] = (12.0, 1.0)\n",
    "matplotlib.rcParams['font.size'] = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_conv_ls = np.concatenate([np.arange(low_c, high_c+1) for low_c, high_c in zip(low_conv_ls, high_conv_ls)])\n",
    "all_dense_ls = np.concatenate([np.arange(low_c, high_c+1) for low_c, high_c in zip(low_dense_ls, high_dense_ls)])\n",
    "bincount_conv = np.bincount(all_conv_ls)\n",
    "bincount_dense = np.bincount(all_dense_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(98349384)\n",
    "color = 'grey'\n",
    "for low_c, high_c in zip(low_conv_ls, high_conv_ls):\n",
    "    offset = rng.randn(1) * 0.1\n",
    "    tried_cs = np.arange(low_c, high_c+1)\n",
    "    plt.plot([offset,] * len(tried_cs), tried_cs, marker='o', alpha=0.5, color=color, ls=':')\n",
    "    \n",
    "for i_c, n_c in enumerate(bincount_conv):\n",
    "    plt.scatter(0.4, i_c, color=color, s=n_c*40)\n",
    "    plt.text(0.535, i_c, str(n_c)+ \"x\", ha='left', va='center')\n",
    "\n",
    "for low_c, high_c in zip(low_dense_ls, high_dense_ls):\n",
    "    offset = 1 + rng.randn(1) * 0.1\n",
    "    tried_cs = np.arange(low_c, high_c+1)\n",
    "    plt.plot([offset,] * len(tried_cs), tried_cs, marker='o', alpha=0.5, color=color, ls=':')\n",
    "    \n",
    "for i_c, n_c in enumerate(bincount_dense):\n",
    "    plt.scatter(1.4, i_c, color=color, s=n_c*40)\n",
    "    plt.text(1.535, i_c, str(n_c)+ \"x\", ha='left', va='center')\n",
    "\n",
    "plt.xlim(-0.5,2)\n",
    "plt.xlabel(\"Type of layer\")\n",
    "plt.ylabel(\"Number of layers\")\n",
    "plt.xticks([0,1], [\"Convolutional\", \"Dense\"], rotation=45)\n",
    "plt.yticks([1,2,3,4,5,6,7]);\n",
    "plt.title(\"Number of layers in prior works' architectures\", y=1.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.loc[:, ['Study', 'Decoding problem', 'External baseline']].to_markdown(showindex=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Study                                                                                                                              | Decoding problem                                                                                                                     | External baseline                                                               |\n",
    "|:-----------------------------------------------------------------------------------------------------------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------|:--------------------------------------------------------------------------------|\n",
    "| This manuscript, Schirrmeister et. al (2017)                                                                                       | Imagined and executed movement classes, within subject                                                                               | FBCSP + rLDA                                                                    |\n",
    "| Single-trial EEG classification of motor imagery using deep convolutional neural networks, citet{tang_single-trial_2017}           | Imagined movement classes, within-subject                                                                                            | FBCSP                                                                           |\n",
    "| EEGNet: A Compact Convolutional Network for EEG-based Brain-Computer Interfaces, {cite}`lawhern_eegnet:_2016`                      | Oddball response (RSVP), error response (ERN), movement classes (voluntarily started and imagined)                                   |                                                                                 |\n",
    "| Remembered or Forgotten? –- An EEG-Based Computational Prediction Approach, {cite}`sun_remembered_2016`                            | Memory performance, within-subject                                                                                                   |                                                                                 |\n",
    "| Multimodal Neural Network for Rapid Serial Visual Presentation Brain Computer Interface, {cite}`manor_multimodal_2016`             | Oddball response using RSVP and image (combined image-EEG decoding), within-subject                                                  |                                                                                 |\n",
    "| A novel deep learning approach for classification of EEG motor imagery signals, {cite}`tabar_novel_2017`                           | Imagined and executed movement classes, within-subject                                                                               | Weights (spatial + frequential)                                                 |\n",
    "| Predicting Seizures from Electroencephalography Recordings: A Knowledge Transfer Strategy, {cite}`liang_predicting_2016`           | Seizure prediction, within-subject                                                                                                   |                                                                                 |\n",
    "| EEG-based prediction of driver's cognitive performance by deep convolutional neural network, {cite}`hajinoroozi_eeg-based_2016`    | Driver performance, within- and cross-subject                                                                                        |                                                                                 |\n",
    "| Deep learning for epileptic intracranial EEG data, {cite}`antoniades_deep_2016`                                                    | Epileptic discharges, cross-subject                                                                                                  |                                                                                 |\n",
    "| Learning Robust Features using Deep Learning for Automatic Seizure Detection, {cite}`thodoroff_learning_2016`                      | Start of epileptic seizure, within- and cross-subject                                                                                | Hand crafted features + SVM                                                     |\n",
    "| Single-trial EEG RSVP classification using convolutional neural networks, {cite}`george_single-trial_2016`                         | Oddball response (RSVP), groupwise (ConvNet trained on all subjects)                                                                 |                                                                                 |\n",
    "| Wearable seizure detection using convolutional neural networks with transfer learning, {cite}`page_wearable_2016`                  | Seizure detection, cross-subject, within-subject, groupwise                                                                          | Multiple: spectral features, higher order statistics + linear-SVM, RBF-SVM, ... |\n",
    "| Learning Representations from EEG with Deep Recurrent-Convolutional Neural Networks, {cite}`bashivan_learning_2016`                | Cognitive load (number of characters to memorize), cross-subject                                                                     |                                                                                 |\n",
    "| Deep Feature Learning for EEG Recordings, {cite}`stober_learning_2016`                                                             | Type of music rhythm, groupwise (ensembles of leave-one-subject-out trained models, evaluated on separate test set of same subjects) |                                                                                 |\n",
    "| Convolutional Neural Network for Multi-Category Rapid Serial Visual Presentation BCI, {cite}`manor_convolutional_2015`             | Oddball response (RSVP), within-subject                                                                                              |                                                                                 |\n",
    "| Parallel Convolutional-Linear Neural Network for Motor Imagery Classification, {cite}`sakhavi_parallel_2015`                       | Imagined movement classes, within-subject                                                                                            |                                                                                 |\n",
    "| Using Convolutional Neural networks to Recognize Rhythm Stimuli form Electroencephalography Recordings, {cite}`stober_using_2014`  | Type of music rhythm, within-subject                                                                                                 |                                                                                 |\n",
    "| Convolutional deep belief networks for feature extraction of EEG signal, {cite}`ren_convolutional_2014`                            | Imagined movement classes, within-subject                                                                                            |                                                                                 |\n",
    "| Deep feature learning using target priors with applications in ECoG signal decoding for BCI, {cite}`wang_deep_2013`                | Finger flexion trajectory (regression), within-subject                                                                               |                                                                                 |\n",
    "| Convolutional neural networks for P300 detection with application to brain-computer interfaces, {cite}`cecotti_convolutional_2011` | Oddball / attention response using P300 speller, within-subject                                                                      | Multiple: Linear SVM, gradient boosting, E-SVM, S-SVM, mLVQ, LDA, ...           |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
