{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(prior-work)=\n",
    "# Prior Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition}  Deep Learning on EEG studies prior to 2017 only had limited comparisons to feature-based baselines \n",
    "* Few studies had an external baseline\n",
    "* Decoding problems were very varied\n",
    "* Remained unclear how deep learning approaches compare to well-tuned feature-based approaches\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Study                                                                                                                              | Decoding problem                                                                                                                     | External baseline                                                               |\n",
    "|:-----------------------------------------------------------------------------------------------------------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------|:--------------------------------------------------------------------------------|\n",
    "| Single-trial EEG classification of motor imagery using deep convolutional neural networks, {cite}`tang_single-trial_2017`           | Imagined movement classes, within-subject                                                                                            | FBCSP                                                                           |\n",
    "| EEGNet: A Compact Convolutional Network for EEG-based Brain-Computer Interfaces, {cite}`lawhern_eegnet:_2016`                      | Oddball response (RSVP), error response (ERN), movement classes (voluntarily started and imagined)                                   |                                                                                 |\n",
    "| Remembered or Forgotten? –- An EEG-Based Computational Prediction Approach, {cite}`sun_remembered_2016`                            | Memory performance, within-subject                                                                                                   |                                                                                 |\n",
    "| Multimodal Neural Network for Rapid Serial Visual Presentation Brain Computer Interface, {cite}`manor_multimodal_2016`             | Oddball response using RSVP and image (combined image-EEG decoding), within-subject                                                  |                                                                                 |\n",
    "| A novel deep learning approach for classification of EEG motor imagery signals, {cite}`tabar_novel_2017`                           | Imagined and executed movement classes, within-subject                                                                               | FBCSP, Twin SVM, DDFBS, Bi-spectrum, RQNN                                       |\n",
    "| Predicting Seizures from Electroencephalography Recordings: A Knowledge Transfer Strategy, {cite}`liang_predicting_2016`           | Seizure prediction, within-subject                                                                                                   |                                                                                 |\n",
    "| EEG-based prediction of driver's cognitive performance by deep convolutional neural network, {cite}`hajinoroozi_eeg-based_2016`    | Driver performance, within- and cross-subject                                                                                        |                                                                                 |\n",
    "| Deep learning for epileptic intracranial EEG data, {cite}`antoniades_deep_2016`                                                    | Epileptic discharges, cross-subject                                                                                                  |                                                                                 |\n",
    "| Learning Robust Features using Deep Learning for Automatic Seizure Detection, {cite}`thodoroff_learning_2016`                      | Start of epileptic seizure, within- and cross-subject                                                                                | Hand crafted features + SVM                                                     |\n",
    "| Single-trial EEG RSVP classification using convolutional neural networks, {cite}`george_single-trial_2016`                         | Oddball response (RSVP), groupwise (ConvNet trained on all subjects)                                                                 |                                                                                 |\n",
    "| Wearable seizure detection using convolutional neural networks with transfer learning, {cite}`page_wearable_2016`                  | Seizure detection, cross-subject, within-subject, groupwise                                                                          | Multiple: spectral features, higher order statistics + linear-SVM, RBF-SVM, ... |\n",
    "| Learning Representations from EEG with Deep Recurrent-Convolutional Neural Networks, {cite}`bashivan_learning_2016`                | Cognitive load (number of characters to memorize), cross-subject                                                                     |                                                                                 |\n",
    "| Deep Feature Learning for EEG Recordings, {cite}`stober_learning_2016`                                                             | Type of music rhythm, groupwise (ensembles of leave-one-subject-out trained models, evaluated on separate test set of same subjects) |                                                                                 |\n",
    "| Convolutional Neural Network for Multi-Category Rapid Serial Visual Presentation BCI, {cite}`manor_convolutional_2015`             | Oddball response (RSVP), within-subject                                                                                              |                                                                                 |\n",
    "| Parallel Convolutional-Linear Neural Network for Motor Imagery Classification, {cite}`sakhavi_parallel_2015`                       | Imagined movement classes, within-subject                                                                                            |                                                                                 |\n",
    "| Using Convolutional Neural networks to Recognize Rhythm Stimuli form Electroencephalography Recordings, {cite}`stober_using_2014`  | Type of music rhythm, within-subject                                                                                                 |                                                                                 |\n",
    "| Convolutional deep belief networks for feature extraction of EEG signal, {cite}`ren_convolutional_2014`                            | Imagined movement classes, within-subject                                                                                            |                                                                                 |\n",
    "| Deep feature learning using target priors with applications in ECoG signal decoding for BCI, {cite}`wang_deep_2013`                | Finger flexion trajectory (regression), within-subject                                                                               |                                                                                 |\n",
    "| Convolutional neural networks for P300 detection with application to brain-computer interfaces, {cite}`cecotti_convolutional_2011` | Oddball / attention response using P300 speller, within-subject                                                                      | Multiple: Linear SVM, gradient boosting, E-SVM, S-SVM, mLVQ, LDA, ...           |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "% rework table into jst numbers per task for overlapping task, remaining ones, mention separately\n",
    "% in our work, we therefore looked most closely at movement-related decoding as most common"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition}  Most investigated network architectures were fairly shallow (below 4 layers)\n",
    "* Unlike architectures in computer vision, most EEG DL architectures had only 1-3 convolutional layers\n",
    "* Unlike architectures in computer vision, many architectures used several dense layers\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input",
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import seaborn\n",
    "import numpy as np\n",
    "import re\n",
    "from myst_nb import glue\n",
    "seaborn.set_palette('colorblind')\n",
    "seaborn.set_style('darkgrid')\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'png'\n",
    "#matplotlib.rcParams['figure.figsize'] = (12.0, 1.0)\n",
    "matplotlib.rcParams['font.size'] = 14\n",
    "\n",
    "ls = np.array([' 2/2 ', ' 3/1 ', ' 2/2 ', ' 3/2 ', ' 1/1 ', ' 1/2 ', ' 1/3 ',\n",
    "       ' 1–2/2 ', ' 3/1 (+ LSTM as postprocessor) ', ' 4/3 ', ' 1-3/1-3 ',\n",
    "       ' 3–7/2 (+ LSTM or other temporal post-processing (see design choices)) ',\n",
    "       ' 2/1 ', ' 3/3 (Spatio-temporal regularization) ',\n",
    "       ' 2/2 (Final fully connected layer uses concatenated output by convolutionaland fully connected layers) ',\n",
    "       ' 1-2/1 ',\n",
    "       '2/0 (Convolutional deep belief network, separately trained RBF-SVM classifier) ',\n",
    "       ' 3/1 (Convolutional layers trained as convolutional stacked autoencoder with target prior) ',\n",
    "       ' 2/2 '])\n",
    "\n",
    "conv_ls = [l.split('/')[0] for l in ls]\n",
    "low_conv_ls = [int(re.split(r'[–-]', c)[0])for c in conv_ls]\n",
    "high_conv_ls = [int(re.split(r'[–-]', c)[-1])for c in conv_ls]\n",
    "dense_ls = [l.split('/')[1] for l in ls]\n",
    "low_dense_ls = [int(re.split(r'[–-]', c[:8])[0][:2])for c in dense_ls]\n",
    "high_dense_ls = [int(re.split(r'[–-]', c[:8])[-1][:2])for c in dense_ls]\n",
    "\n",
    "all_conv_ls = np.concatenate([np.arange(low_c, high_c+1) for low_c, high_c in zip(low_conv_ls, high_conv_ls)])\n",
    "all_dense_ls = np.concatenate([np.arange(low_c, high_c+1) for low_c, high_c in zip(low_dense_ls, high_dense_ls)])\n",
    "bincount_conv = np.bincount(all_conv_ls)\n",
    "bincount_dense = np.bincount(all_dense_ls)\n",
    "rng = np.random.RandomState(98349384)\n",
    "color = 'grey'\n",
    "fig = plt.figure(figsize=(8,4))\n",
    "for low_c, high_c in zip(low_conv_ls, high_conv_ls):\n",
    "    offset = rng.randn(1) * 0.1\n",
    "    tried_cs = np.arange(low_c, high_c+1)\n",
    "    plt.plot([offset,] * len(tried_cs), tried_cs, marker='o', alpha=0.5, color=color, ls=':')\n",
    "    \n",
    "for i_c, n_c in enumerate(bincount_conv):\n",
    "    plt.scatter(0.4, i_c, color=color, s=n_c*40)\n",
    "    plt.text(0.535, i_c, str(n_c)+ \"x\", ha='left', va='center')\n",
    "\n",
    "for low_c, high_c in zip(low_dense_ls, high_dense_ls):\n",
    "    offset = 1 + rng.randn(1) * 0.1\n",
    "    tried_cs = np.arange(low_c, high_c+1)\n",
    "    plt.plot([offset,] * len(tried_cs), tried_cs, marker='o', alpha=0.5, color=color, ls=':')\n",
    "    \n",
    "for i_c, n_c in enumerate(bincount_dense):\n",
    "    plt.scatter(1.4, i_c, color=color, s=n_c*40)\n",
    "    plt.text(1.535, i_c, str(n_c)+ \"x\", ha='left', va='center')\n",
    "\n",
    "plt.xlim(-0.5,2)\n",
    "plt.xlabel(\"Type of layer\")\n",
    "plt.ylabel(\"Number of layers\")\n",
    "plt.xticks([0,1], [\"Convolutional\", \"Dense\"], rotation=45)\n",
    "plt.yticks([1,2,3,4,5,6,7]);\n",
    "plt.title(\"Number of layers in prior works' architectures\", y=1.05)\n",
    "glue('layernum_fig', fig)\n",
    "plt.close(fig)\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{glue:figure} layernum_fig\n",
    "\n",
    "\n",
    "*Number of layers in prior work*. Small grey markers represent individual architectures. Dashed lines indicate different number of layers investigated in a single study (e.g., a single study investigated 3-7 convolutional layers). Larger grey markers indicate sum of occurences of that layer number over all studies (e.g., 9 architectures used 2 convolutional layers). Note most architectures use only 1-3 convolutional layers.\n",
    "```\n",
    "%:figclass: margin-caption"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition}  Prior work varied widely in which design choices and training strategies were compared\n",
    "* Six studies did not compare any design choices or training strategies\n",
    "* Most common was to try different kernel sizes\n",
    "* Only one study evaluated a wider range of hyperparameters for both design choices and training strategies\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Study                                                                                                                              | Design choices                                                                                                                                                                                  | Training strategies                                                                                                                      |\n",
    "|:-----------------------------------------------------------------------------------------------------------------------------------|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:-----------------------------------------------------------------------------------------------------------------------------------------|\n",
    "|{cite}`lawhern_eegnet:_2016`                      | Kernel sizes                                                                                                                                                                                    |                                                                                                                                          |\n",
    "|{cite}`sun_remembered_2016`                            |                                                                                                                                                                                                 | Different time windows                                                                                                                   |\n",
    "|{cite}`tabar_novel_2017`                           | Addition of six-layer stacked autoencoder on ConvNet features <br> Kernel sizes                                                                                                              |                                                                                                                                          |\n",
    "| {cite}`liang_predicting_2016`           |                                                                                                                                                                                                 | Different subdivisions of frequency range <br>Different lengths of time crops <br>Transfer learning with auxiliary non-epilepsy datasets |\n",
    "|{cite}`hajinoroozi_eeg-based_2016`    | Replacement of convolutional layers by restricted Boltzmann machines with slightly varied network architecture}                                                                                 |                                                                                                                                          |\n",
    "|{cite}`antoniades_deep_2016`                                                    | 1 or 2 convolutional layers                                                                                                                                                                     |                                                                                                                                          |\n",
    "|{cite}`page_wearable_2016`                  |                                                                                                                                                                                                 | Cross-subject supervised training, within-subject finetuning of fully connected layers                                                   |\n",
    "|{cite}`bashivan_learning_2016`                | Number of convolutional layers <br>Temporal processing of ConvNet output by max pooling, temporal convolution, LSTM or temporal convolution + LSTM                                              |                                                                                                                                          |\n",
    "|{cite}`stober_learning_2016`                                                             | Kernel sizes                                                                                                                                                                                    | Pretraining first layer as convolutional autoencoder with different constraints                                                          |\n",
    "|{cite}`sakhavi_parallel_2015`                       | Combination ConvNet and MLP (trained on different features) vs. only ConvNet vs. only MLP                                                                                                       |                                                                                                                                          |\n",
    "|{cite}`stober_using_2014`  | Best values from automatic hyperparameter optimization: frequency cutoff, one vs two layers, kernel sizes, number of channels, pooling width                                                    | Best values from automatic hyperparameter optimization: learning rate, learning rate decay, momentum, final momentum                     |\n",
    "|{cite}`wang_deep_2013`                | Partially supervised CSA                                                                                                                                                                        |                                                                                                                                          |\n",
    "|{cite}`cecotti_convolutional_2011` | Electrode subset (fixed or automatically determined) <br>Using only one spatial filter <br>Different ensembling strategies                                                                      |                                                                                                                                          |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input domain plot (first split off comma -> time or req, then split off by dash, first and last start is int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "```{bibliography} ./references.bib\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
