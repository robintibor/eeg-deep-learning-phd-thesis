
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Further Task-Related Decoding &#8212; Deep Learning for Brain-Signal Decoding from Electroencephalography (EEG)</title>
    
  <link href="_static/css/theme.css" rel="stylesheet" />
  <link href="_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.1c5a1a01449ed65a7b51.js">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script async="async" kind="hypothesis" src="https://hypothes.is/embed.js"></script>
    <script kind="utterances">

    var commentsRunWhenDOMLoaded = cb => {
    if (document.readyState != 'loading') {
        cb()
    } else if (document.addEventListener) {
        document.addEventListener('DOMContentLoaded', cb)
    } else {
        document.attachEvent('onreadystatechange', function() {
        if (document.readyState == 'complete') cb()
        })
    }
}

var addUtterances = () => {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src = "https://utteranc.es/client.js";
    script.async = "async";

    script.setAttribute("repo", "robintibor/eeg-deep-learning-phd-thesis");
    script.setAttribute("issue-term", "pathname");
    script.setAttribute("theme", "github-light");
    script.setAttribute("label", "💬 comment");
    script.setAttribute("crossorigin", "anonymous");

    sections = document.querySelectorAll("div.section");
    if (sections !== null) {
        section = sections[sections.length-1];
        section.appendChild(script);
    }
}
commentsRunWhenDOMLoaded(addUtterances);
</script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Decoding Pathology" href="Pathology.html" />
    <link rel="prev" title="Decoding Movement-Related Brain Activity" href="MovementDecoding.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="_static/Rainbow_brain,_Aug_2014.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Deep Learning for Brain-Signal Decoding from Electroencephalography (EEG)</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="Abstract.html">
   Deep Learning for Brain-Signal Decoding from Electroencephalography (EEG)
  </a>
 </li>
</ul>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="Introduction.html">
   Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="PriorWork.html">
   Prior Work
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="DeepArchitectures.html">
   Neural Network Architectures for EEG-Decoding
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="CroppedTraining.html">
   Cropped Training
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="PerturbationVisualization.html">
   Perturbation Visualization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="MovementDecoding.html">
   Decoding Movement-Related Brain Activity
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Further Task-Related Decoding
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Pathology.html">
   Decoding Pathology
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Invertible.html">
   Invertible Networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="FutureWork.html">
   Future Work
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="References.html">
   References
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/TaskDecoding.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/executablebooks/jupyter-book/master?urlpath=tree/TaskDecoding.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#decoding-different-mental-imageries">
   Decoding different mental imageries
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#decoding-error-related-signals">
   Decoding error-related signals
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#bci-robot">
   BCI Robot
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#intracranial">
   Intracranial
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#large-scale-evaluation">
   Large scale evaluation
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#interpretability-remove">
     Interpretability (remove?)
    </a>
   </li>
  </ul>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="further-task-related-decoding">
<span id="task-related"></span><h1>Further Task-Related Decoding<a class="headerlink" href="#further-task-related-decoding" title="Permalink to this headline">¶</a></h1>
<p>After our initial work designing and evaluating convolutional neural networks for movement decoding from EEG, we evaluated the resulting networks on a wide variety of other EEG decoding tasks.</p>
<ul class="simple">
<li><p>mention you helped with writing and setting up code for papers past xx</p></li>
</ul>
<div class="section" id="decoding-different-mental-imageries">
<h2>Decoding different mental imageries<a class="headerlink" href="#decoding-different-mental-imageries" title="Permalink to this headline">¶</a></h2>
<blockquote>
<div><p>The Mixed Imagery Dataset (MID) was obtained from 4 healthy subjects (3 female, all right-handed, age
26.75±5.9 (mean±std)) with a varying number of trials (S1: 675, S2: 2172, S3: 698, S4: 464) of imagined
movements (right hand and feet), mental rotation and mental word generation. All details were the same as
for the High Gamma Dataset, except: a 64-electrode subset of electrodes was used for recording, recordings
were not performed in the electromagnetically shielded cabin, thus possibly better approximating conditions
of real-world BCI usage, and trials varied in duration between 1 to 7 seconds. The dataset was analyzed
by cutting out time windows of 2 seconds with 1.5 second overlap from all trials longer than 2 seconds (S1:
6074 windows, S2: 21339, S3: 6197, S4: 4220), and both methods were evaluated using the accuracy of the
predictions for all the 2-second windows for the last two runs of roughly 130 trials (S1: 129, S2: 160, S3:
124, S4: 123).</p>
</div></blockquote>
<p>For the mixed imagery dataset, we find the deep ConvNet to perform slightly better and the shallow ConvNet to perform slightly worse than the FBCSP algorithm, as can be seen in <a class="reference internal" href="#mixed-imagery-dataset-results"><span class="std std-numref">Table 3</span></a>.</p>
<table class="colwidths-auto table" id="mixed-imagery-dataset-results">
<caption><span class="caption-number">Table 3 </span><span class="caption-text">Accuracies on the Mixed-Imagery dataset. ConvNet accuracies show the difference to the FBCSP accuracy.</span><a class="headerlink" href="#mixed-imagery-dataset-results" title="Permalink to this table">¶</a></caption>
<thead>
<tr class="row-odd"><th class="head"><p>FBCSP</p></th>
<th class="head"><p>Deep ConvNet</p></th>
<th class="head"><p>Shallow ConvNet</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>71.2</p></td>
<td><p>+1.0</p></td>
<td><p>-3.5</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="decoding-error-related-signals">
<h2>Decoding error-related signals<a class="headerlink" href="#decoding-error-related-signals" title="Permalink to this headline">¶</a></h2>
<p>In this dataset, subjects watched videos of a robot either successfully lifting ball from the ground or letting the ball fall while trying to lift it. The decoding task was to classify whether the person watched a successful or an unsuccessful video from the EEG during either the whole video duration (0-7s) or the part where the actual grasphing and lifting happened (4-7s).
Results in <a class="reference internal" href="#robot-ball-results"><span class="std std-numref">Table 4</span></a> show that the deep ConvNet outperforms regularized linear discriminant analysis (rLDA) as well as FBCSP.</p>
<table class="colwidths-auto table" id="robot-ball-results">
<caption><span class="caption-number">Table 4 </span><span class="caption-text">Accuracies for decoding watching of successful or unsuccessful robot ball-lifting.</span><a class="headerlink" href="#robot-ball-results" title="Permalink to this table">¶</a></caption>
<thead>
<tr class="row-odd"><th class="head"><p></p></th>
<th class="head"><p>0-7s</p></th>
<th class="head"><p>4-7s</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Deep ConvNet</p></td>
<td><p>78.31 ± 8.09</p></td>
<td><p>73.80 ± 7.52</p></td>
</tr>
<tr class="row-odd"><td><p>rLDA</p></td>
<td><p>68.29 ± 8.00</p></td>
<td><p>64.71 ± 7.36</p></td>
</tr>
<tr class="row-even"><td><p>FBCSP</p></td>
<td><p>55.71 ± 4.54</p></td>
<td><p>56.80 ± 3.92</p></td>
</tr>
</tbody>
</table>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Behncke J., Schirrmeister R. T., Burgard W., and Ball T., &quot;The role of robot design in decoding error-related information from EEG signals of a human observer&quot;. 6th International Congress on Neurotechnology, Electronics and Informatics 2018. doi.org/10.5220/0006934900610066

Behncke J., Schirrmeister R. T., Burgard W., and Ball T., &quot;The signature of robot action success in EEG signals of a human observer: Decoding and visualization using deep convolutional neural networks&quot;. IEEE The 6th International Winter Conference on Brain-Computer Interface 2018. doi.org/10.1109/IWW-BCI.2018.8311531

Völker M., Schirrmeister R. T., Fiederer L.D.J., Burgard W., and Ball T., &quot;Deep Transfer Learning for Error Decoding from Non-Invasive EEG&quot;. IEEE The 6th International Winter Conference on Brain-Computer Interface 2018. doi.org/10.1109/IWW-BCI.2018.8311491
</pre></div>
</div>
</div>
<div class="section" id="bci-robot">
<h2>BCI Robot<a class="headerlink" href="#bci-robot" title="Permalink to this headline">¶</a></h2>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Burget F.*, Fiederer L.D.J.*, Kuhner D.*, Völker M.*, Aldinger J., Schirrmeister R.T., Do C., Boedecker J., Nebel B., Ball T. and Burgard W., *equally contributing. &quot;Acting Thoughts: Towards a Mobile Robotic Service Assistant for Users with Limited Communication Skill&quot;. Proceedings of the 2017 IEEE European Conference on Mobile Robotics. https://arxiv.org/abs/1707.06633
</pre></div>
</div>
</div>
<div class="section" id="intracranial">
<h2>Intracranial<a class="headerlink" href="#intracranial" title="Permalink to this headline">¶</a></h2>
<p>Behncke J., Schirrmeister R. T., Völker M., Hammer J., Marusič P., Schulze-Bonhage A., Burgard W., and Ball T., “Cross-paradigm pretraining of convolutional networks improves intracranial EEG decoding”. IEEE International Conference on Systems, Man, and Cybernetics 2018 <a class="reference external" href="http://arxiv.org/abs/1806.09532">arxiv.org/abs/1806.09532</a></p>
<p>Wang, X., Gkogkidis, C. A., Schirrmeister, R. T., Heilmeyer, F. A., Gierthmuehlen, M., Kohler, F., Schuettler, M., Stieglitz, T., Ball, T., 2018.
Deep Learning for micro-Electrocorticographic (μECoG) Data. Conference paper for IEEE EMBS CONFERENCE ON BIOMEDICAL ENGINEERING AND SCIENCES (IECBES 2018), 16 Sep., accepted.
<a class="reference external" href="https://ieeexplore.ieee.org/document/8626607">https://ieeexplore.ieee.org/document/8626607</a></p>
<p>Völker M., Hammer J., Schirrmeister R.T., Behncke J., Fiederer L.D., Schulze-Bonhage A., Marusič P., Burgard W., and Ball T., “Intracranial Error Detection via Deep Learning”. IEEE International Conference on Systems, Man, and Cybernetics 2018 <a class="reference external" href="https://arxiv.org/abs/1805.01667">https://arxiv.org/abs/1805.01667</a></p>
</div>
<div class="section" id="large-scale-evaluation">
<h2>Large scale evaluation<a class="headerlink" href="#large-scale-evaluation" title="Permalink to this headline">¶</a></h2>
<p>Heilmeyer F.A., Schirrmeister R.T., Fiederer L.D.J., Völker M., Behncke J., Ball T., “A framework for large-scale evaluation of deep learning for EEG”. IEEE International Conference on Systems, Man, and Cybernetics 2018 <a class="reference external" href="https://arxiv.org/abs/1806.07741">https://arxiv.org/abs/1806.07741</a></p>
<div class="section" id="interpretability-remove">
<h3>Interpretability (remove?)<a class="headerlink" href="#interpretability-remove" title="Permalink to this headline">¶</a></h3>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Hartmann K.G., Schirrmeister R. T., and Ball T., &quot;Hierarchical internal representation of spectral features in deep convolutional networks trained for EEG decoding&quot;. IEEE The 6th International Winter Conference on Brain-Computer Interface 2018. doi.org/10.1109/IWW-BCI.2018.8311493
</pre></div>
</div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            



<div class='prev-next-bottom'>
    
    <div id="prev">
        <a class="left-prev" href="MovementDecoding.html" title="previous page">
            <i class="prevnext-label fas fa-angle-left"></i>
            <div class="prevnext-info">
                <p class="prevnext-label">previous</p>
                <p class="prevnext-title">Decoding Movement-Related Brain Activity</p>
            </div>
        </a>
    </div>
     <div id="next">
        <a class="right-next" href="Pathology.html" title="next page">
            <div class="prevnext-info">
                <p class="prevnext-label">next</p>
                <p class="prevnext-title">Decoding Pathology</p>
            </div>
            <i class="prevnext-label fas fa-angle-right"></i>
        </a>
     </div>

</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          By The Jupyter Book community<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>