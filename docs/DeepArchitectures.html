

<!DOCTYPE html>


<html lang="en" data-theme="light">

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Neural Network Architectures for EEG-Decoding &#8212; Deep Learning for Brain-Signal Decoding from Electroencephalography (EEG)</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "light";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script async="async" kind="hypothesis" src="https://hypothes.is/embed.js"></script>
    <script kind="utterances">

    var commentsRunWhenDOMLoaded = cb => {
    if (document.readyState != 'loading') {
        cb()
    } else if (document.addEventListener) {
        document.addEventListener('DOMContentLoaded', cb)
    } else {
        document.attachEvent('onreadystatechange', function() {
        if (document.readyState == 'complete') cb()
        })
    }
}

var addUtterances = () => {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src = "https://utteranc.es/client.js";
    script.async = "async";

    script.setAttribute("repo", "robintibor/eeg-deep-learning-phd-thesis");
    script.setAttribute("issue-term", "pathname");
    script.setAttribute("theme", "github-light");
    script.setAttribute("label", "💬 comment");
    script.setAttribute("crossorigin", "anonymous");

    sections = document.querySelectorAll("div.section");
    if (sections !== null) {
        section = sections[sections.length-1];
        section.appendChild(script);
    }
}
commentsRunWhenDOMLoaded(addUtterances);
</script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'DeepArchitectures';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Cropped Training" href="CroppedTraining.html" />
    <link rel="prev" title="Filter Bank Common Spatial Patterns and Filterbank Network" href="FBCSPAndFBCSPNet.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="light">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="Abstract.html">
  
  
  
  
    
    
    
    <img src="_static/braindecode-logo.svg" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="_static/braindecode-logo.svg" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="Introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="PriorWork.html">Prior Work</a></li>
<li class="toctree-l1"><a class="reference internal" href="FBCSPAndFBCSPNet.html">Filter Bank Common Spatial Patterns and Filterbank Network</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Neural Network Architectures for EEG-Decoding</a></li>
<li class="toctree-l1"><a class="reference internal" href="CroppedTraining.html">Cropped Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="PerturbationVisualization.html">Perturbation Visualization</a></li>
<li class="toctree-l1"><a class="reference internal" href="Invertible.html">Invertible Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="MovementDecoding.html">Decoding Movement-Related Brain Activity</a></li>
<li class="toctree-l1"><a class="reference internal" href="TaskDecoding.html">Generalization to Other Tasks</a></li>
<li class="toctree-l1"><a class="reference internal" href="Pathology.html">Decoding Pathology</a></li>
<li class="toctree-l1"><a class="reference internal" href="UnderstandingPathology.html">Understanding Pathology Decoding With Invertible Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="FutureWork.html">Future Work</a></li>
<li class="toctree-l1"><a class="reference internal" href="References.html">References</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/DeepArchitectures.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Neural Network Architectures for EEG-Decoding</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#shallow-network-architecture">Shallow Network Architecture</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#deep-network-architecture">Deep Network Architecture</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#residual-network">Residual Network</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <div class="tex2jax_ignore mathjax_ignore section" id="neural-network-architectures-for-eeg-decoding">
<span id="network-architectures"></span><h1>Neural Network Architectures for EEG-Decoding<a class="headerlink" href="#neural-network-architectures-for-eeg-decoding" title="Permalink to this heading">#</a></h1>
<div class="admonition-three-progressively-more-generic-architectures admonition">
<p class="admonition-title">Three progressively more generic architectures</p>
<ul class="simple">
<li><p>Shallow network learns temporal filters and later average-pools over large timeregions</p></li>
<li><p>Deep network uses smaller temporal filters and max-pooling over small timeregions</p></li>
<li><p>Residual network uses many layers with even smaller temporal filters</p></li>
</ul>
</div>
<p>We continued developing our neural network architectures with our EEG-specific development strategy of starting with networks that resemble feature-based algorithms. After the filterbank network from the master thesis, we adapted the so-called shallow network, initally also developed in the same master thesis <span id="id1">[<a class="reference internal" href="References.html#id4" title="Robin Tibor Schirrmeister. Convolutional neural networks for movement decoding from eeg signals. Master's thesis, Albert-Ludwigs-Universität Freiburg, 2015.">Schirrmeister, 2015</a>]</span>. The shallow network still resembles filter bank common spatial patterns, but less closely than the filterbank network. After validating that these initial network architectures perform as well as filter bank common spatial patterns, we progressed to developing and evaluating more generic architectures.</p>
<p>In this section, I describe the architectures presented in our first publication on EEG deep learning decoding <span id="id2">[<a class="reference internal" href="References.html#id36" title="Robin Tibor Schirrmeister, Jost Tobias Springenberg, Lukas Dominique Josef Fiederer, Martin Glasstetter, Katharina Eggensperger, Michael Tangermann, Frank Hutter, Wolfram Burgard, and Tonio Ball. Deep learning with convolutional neural networks for eeg decoding and visualization. Human Brain Mapping, aug 2017. URL: http://dx.doi.org/10.1002/hbm.23730, doi:10.1002/hbm.23730.">Schirrmeister <em>et al.</em>, 2017</a>]</span>. This part uses text and figures from <span id="id3">[<a class="reference internal" href="References.html#id36" title="Robin Tibor Schirrmeister, Jost Tobias Springenberg, Lukas Dominique Josef Fiederer, Martin Glasstetter, Katharina Eggensperger, Michael Tangermann, Frank Hutter, Wolfram Burgard, and Tonio Ball. Deep learning with convolutional neural networks for eeg decoding and visualization. Human Brain Mapping, aug 2017. URL: http://dx.doi.org/10.1002/hbm.23730, doi:10.1002/hbm.23730.">Schirrmeister <em>et al.</em>, 2017</a>]</span> adapted for readibility in this thesis.</p>
<div class="section" id="shallow-network-architecture">
<h2>Shallow Network Architecture<a class="headerlink" href="#shallow-network-architecture" title="Permalink to this heading">#</a></h2>
<div class="figure align-default" id="shallow-net-figure">
<a class="reference internal image-reference" href="_images/3D_Diagram_MatplotLib.ipynb.0.png"><img alt="_images/3D_Diagram_MatplotLib.ipynb.0.png" src="_images/3D_Diagram_MatplotLib.ipynb.0.png" style="width: 50%;" /></a>
<p class="caption"><span class="caption-number">Fig. 5 </span><span class="caption-text">Shallow network architecture, figure from <span id="id4">[<a class="reference internal" href="References.html#id36" title="Robin Tibor Schirrmeister, Jost Tobias Springenberg, Lukas Dominique Josef Fiederer, Martin Glasstetter, Katharina Eggensperger, Michael Tangermann, Frank Hutter, Wolfram Burgard, and Tonio Ball. Deep learning with convolutional neural networks for eeg decoding and visualization. Human Brain Mapping, aug 2017. URL: http://dx.doi.org/10.1002/hbm.23730, doi:10.1002/hbm.23730.">Schirrmeister <em>et al.</em>, 2017</a>]</span>.  EEG input (at the top) is progressively transformed toward the bottom, until the final classifier output. Black cuboids: inputs/feature maps; brown cuboids: convolution/pooling kernels. The corresponding sizes are indicated in black and brown, respectively. Note that the final dense layer operates only on a small remaining temporal dimension, making it similar to a regular convolutional layer.</span><a class="headerlink" href="#shallow-net-figure" title="Permalink to this image">#</a></p>
</div>
<p>We developed the shallow network architecture, a more flexible architecture than the filterbank network that also learns temporal filters on the input signal and on the later representation. Instead of bandpass-filtered signals, it is fed the raw signals as input.
The steps the architecture implements are as follows (also see <a class="reference internal" href="#shallow-net-figure"><span class="std std-numref">Fig. 5</span></a>):</p>
<ol class="arabic simple">
<li><p><strong>Temporal Filtering</strong> Learnable temporal filters are indepedently convolved with the signals of each EEG electrode. Afterwards, the channel dimension of the network representation contains <span class="math notranslate nohighlight">\(\mathrm{electrodes} \cdot \mathrm{temporal~ filters}\)</span> channels.</p></li>
<li><p><strong>Spatial Filtering</strong> Combining spatial filtering with mixing the outputs of the temporal filters, the network-channel dimension is linearly transformed by learned weights to a smaller dimensionality for further preprocessing.</p></li>
<li><p><strong>Log Average Power</strong> The resulting feature timeseries are then squared, average-pooled and log-transformed, which allows the network to more easily learn log-power-based features. Unlike the filterbank network, the average pooling does not collapse the feature timeseries into one value per trial. So after these processing steps, still some temporal information about the timecourse of the variance throughout the trial can be preserved.</p></li>
<li><p><strong>Classifier</strong> The final classification layer transforms these feature timecourses into class probabilities using a linear transformation and a softmax function.</p></li>
</ol>
</div>
<div class="section" id="deep-network-architecture">
<h2>Deep Network Architecture<a class="headerlink" href="#deep-network-architecture" title="Permalink to this heading">#</a></h2>
<div class="figure align-default" id="deep-net-figure">
<a class="reference internal image-reference" href="_images/3D_Diagram_MatplotLib.ipynb.1.png"><img alt="_images/3D_Diagram_MatplotLib.ipynb.1.png" src="_images/3D_Diagram_MatplotLib.ipynb.1.png" style="width: 75%;" /></a>
<p class="caption"><span class="caption-number">Fig. 6 </span><span class="caption-text">Deep network architecture, figure from <span id="id5">[<a class="reference internal" href="References.html#id36" title="Robin Tibor Schirrmeister, Jost Tobias Springenberg, Lukas Dominique Josef Fiederer, Martin Glasstetter, Katharina Eggensperger, Michael Tangermann, Frank Hutter, Wolfram Burgard, and Tonio Ball. Deep learning with convolutional neural networks for eeg decoding and visualization. Human Brain Mapping, aug 2017. URL: http://dx.doi.org/10.1002/hbm.23730, doi:10.1002/hbm.23730.">Schirrmeister <em>et al.</em>, 2017</a>]</span>. Conventions as in <a class="reference internal" href="#shallow-net-figure"><span class="std std-numref">Fig. 5</span></a>.</span><a class="headerlink" href="#deep-net-figure" title="Permalink to this image">#</a></p>
</div>
<p>The deep architecture is a more generic architecture, closer to network architectures used in computer vision, see  <a class="reference internal" href="#deep-net-figure"><span class="std std-numref">Fig. 6</span></a> for a schematic overview. The first two temporal convolution and spatial filtering layers are the same in the shallow network, which is followed by a ELU nonlinearity (ELUs, <span class="math notranslate nohighlight">\(f(x)=x\)</span> for <span class="math notranslate nohighlight">\(x &gt; 0\)</span> and <span class="math notranslate nohighlight">\(f(x) = e^x-1\)</span> for <span class="math notranslate nohighlight">\(x &lt;= 0\)</span> <span id="id6">[<a class="reference internal" href="References.html#id219" title="Djork-Arné Clevert, Thomas Unterthiner, and Sepp Hochreiter. Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs). In ArXiv e-prints, volume 1511, arXiv:1511.07289. 2016. URL: http://adsabs.harvard.edu/abs/2015arXiv151107289C (visited on 2016-12-21).">Clevert <em>et al.</em>, 2016</a>]</span>) and max pooling. The following three blocks simply consist of a convolution, a ELU nonlinearity and a max pooling. In the end, there is again a final linear classification layer with a softmax function. Due to its less specific and more generic computational steps, the deep architecture should be able to capture a large variety of features. Hence, the learned features may also be less biased towards the amplitude features commonly used in task-related EEG decoding.</p>
</div>
<div class="section" id="residual-network">
<h2>Residual Network<a class="headerlink" href="#residual-network" title="Permalink to this heading">#</a></h2>
<div class="figure align-default" id="residual-net-figure">
<img alt="_images/residual_block.png" src="_images/residual_block.png" />
<p class="caption"><span class="caption-number">Fig. 7 </span><span class="caption-text">Residual block, Figure from <span id="id7">[<a class="reference internal" href="References.html#id36" title="Robin Tibor Schirrmeister, Jost Tobias Springenberg, Lukas Dominique Josef Fiederer, Martin Glasstetter, Katharina Eggensperger, Michael Tangermann, Frank Hutter, Wolfram Burgard, and Tonio Ball. Deep learning with convolutional neural networks for eeg decoding and visualization. Human Brain Mapping, aug 2017. URL: http://dx.doi.org/10.1002/hbm.23730, doi:10.1002/hbm.23730.">Schirrmeister <em>et al.</em>, 2017</a>]</span>. “Residual block used in the ResNet architecture and as described in original paper (<span id="id8">[<a class="reference internal" href="References.html#id112" title="Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep Residual Learning for Image Recognition. arXiv:1512.03385 [cs], December 2015. arXiv: 1512.03385. URL: http://arxiv.org/abs/1512.03385 (visited on 2016-05-11).">He <em>et al.</em>, 2015</a>]</span>; see Fig. 2) with identity shortcut option A, except using ELU instead of ReLU nonlinearities.”</span><a class="headerlink" href="#residual-net-figure" title="Permalink to this image">#</a></p>
</div>
<table class="colwidths-auto table" id="residual-architectures-table">
<caption><span class="caption-number">Table 4 </span><span class="caption-text">Residual network architecture hyperparameters. Number of kernels, kernel and output size for all subparts of the network. Output size is always time x height x channels. Note that channels here refers to input channels of a network layer, not to EEG channels; EEG channels are in the height dimension. Output size is only shown if it changes from the previous block. Second convolution and all residual blocks used ELU nonlinearities. Note that in the end we had seven outputs, i.e., predictions for the four classes, in the time dimension (<strong>7</strong>x1x4 final output size). In practice, when using cropped training as explained in the following chapter, we even had 424 predictions, and used the mean of these to predict the trial.</span><a class="headerlink" href="#residual-architectures-table" title="Permalink to this table">#</a></caption>
<thead>
<tr class="row-odd"><th class="head"><p>Layer/Block</p></th>
<th class="head"><p>Number of Kernels</p></th>
<th class="head"><p>Kernel Size</p></th>
<th class="head"><p>Output Size</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Input</p></td>
<td><p></p></td>
<td><p></p></td>
<td><p>1000x44x1</p></td>
</tr>
<tr class="row-odd"><td><p>Convolution (linear)</p></td>
<td><p>48</p></td>
<td><p>3x1</p></td>
<td><p>1000x44x48</p></td>
</tr>
<tr class="row-even"><td><p>Convolution (ELU)</p></td>
<td><p>48</p></td>
<td><p>1x44</p></td>
<td><p>1000x1x48</p></td>
</tr>
<tr class="row-odd"><td><p>ResBlock (ELU)</p></td>
<td><p>48</p></td>
<td><p>3x1</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p>ResBlock (ELU)</p></td>
<td><p>48</p></td>
<td><p>3x1</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>ResBlock (ELU)</p></td>
<td><p>96</p></td>
<td><p>3x1 (Stride 2x1)</p></td>
<td><p>500x1x96</p></td>
</tr>
<tr class="row-even"><td><p>ResBlock (ELU)</p></td>
<td><p>96</p></td>
<td><p>3x1</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>ResBlock (ELU)</p></td>
<td><p>144</p></td>
<td><p>3x1 (Stride 2x1)</p></td>
<td><p>250x1x96</p></td>
</tr>
<tr class="row-even"><td><p>ResBlock (ELU)</p></td>
<td><p>144</p></td>
<td><p>3x1</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>ResBlock (ELU)</p></td>
<td><p>144</p></td>
<td><p>3x1 (Stride 2x1)</p></td>
<td><p>125x1x96</p></td>
</tr>
<tr class="row-even"><td><p>ResBlock (ELU)</p></td>
<td><p>144</p></td>
<td><p>3x1</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>ResBlock (ELU)</p></td>
<td><p>144</p></td>
<td><p>3x1 (Stride 2x1)</p></td>
<td><p>63x1x96</p></td>
</tr>
<tr class="row-even"><td><p>ResBlock (ELU)</p></td>
<td><p>144</p></td>
<td><p>3x1</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>ResBlock (ELU)</p></td>
<td><p>144</p></td>
<td><p>3x1 (Stride 2x1)</p></td>
<td><p>32x1x96</p></td>
</tr>
<tr class="row-even"><td><p>ResBlock (ELU)</p></td>
<td><p>144</p></td>
<td><p>3x1</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>ResBlock (ELU)</p></td>
<td><p>144</p></td>
<td><p>3x1 (Stride 2x1)</p></td>
<td><p>16x1x96</p></td>
</tr>
<tr class="row-even"><td><p>ResBlock (ELU)</p></td>
<td><p>144</p></td>
<td><p>3x1</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>Mean Pooling</p></td>
<td><p></p></td>
<td><p>10x1</p></td>
<td><p>7x1x144</p></td>
</tr>
<tr class="row-even"><td><p>Convolution + Softmax</p></td>
<td><p>4</p></td>
<td><p>1x1</p></td>
<td><p>7x1x4</p></td>
</tr>
</tbody>
</table>
<p>We also developed a residual network (ResNet <span id="id9">[<a class="reference internal" href="References.html#id112" title="Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep Residual Learning for Image Recognition. arXiv:1512.03385 [cs], December 2015. arXiv: 1512.03385. URL: http://arxiv.org/abs/1512.03385 (visited on 2016-05-11).">He <em>et al.</em>, 2015</a>]</span>) for EEG decoding. Residual networks add the input of a residual computational block back to its output, and empirically this allows to stably train much deeper networks. We use the same residual blocks as the original paper, described in Figure <a class="reference internal" href="#residual-net-figure"><span class="std std-numref">Fig. 7</span></a>. Our ResNet used ELU activation functions throughout the network (same as the deep ConvNet) and also starts with a splitted temporal and spatial convolution (same as the deep and shallow ConvNets), followed by 14 residual blocks, mean pooling and a final softmax dense classification layer.</p>
<p>In total, the ResNet has 31 convolutional layers, a depth where ConvNets without residual blocks started to show problems converging in the original ResNet paper <span id="id10">[<a class="reference internal" href="References.html#id112" title="Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep Residual Learning for Image Recognition. arXiv:1512.03385 [cs], December 2015. arXiv: 1512.03385. URL: http://arxiv.org/abs/1512.03385 (visited on 2016-05-11).">He <em>et al.</em>, 2015</a>]</span>. In layers where the number of channels is increased, we padded the incoming feature map with zeros to match the new channel dimensionality for the shortcut, as in option A of the original paper <span id="id11">[<a class="reference internal" href="References.html#id112" title="Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep Residual Learning for Image Recognition. arXiv:1512.03385 [cs], December 2015. arXiv: 1512.03385. URL: http://arxiv.org/abs/1512.03385 (visited on 2016-05-11).">He <em>et al.</em>, 2015</a>]</span>. The overall architecture is also shown in <a class="reference internal" href="#residual-architectures-table"><span class="std std-numref">Table 4</span></a>.</p>
<div class="tip admonition">
<p class="admonition-title">Three diverse architectures…</p>
<ul class="simple">
<li><p>to be evaluated on motor-related decoding and other tasks</p></li>
</ul>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="FBCSPAndFBCSPNet.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Filter Bank Common Spatial Patterns and Filterbank Network</p>
      </div>
    </a>
    <a class="right-next"
       href="CroppedTraining.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Cropped Training</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#shallow-network-architecture">Shallow Network Architecture</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#deep-network-architecture">Deep Network Architecture</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#residual-network">Residual Network</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By The Jupyter Book community
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>