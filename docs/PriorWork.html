
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Prior Work &#8212; Deep Learning for Brain-Signal Decoding from Electroencephalography (EEG)</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script async="async" kind="hypothesis" src="https://hypothes.is/embed.js"></script>
    <script kind="utterances">

    var commentsRunWhenDOMLoaded = cb => {
    if (document.readyState != 'loading') {
        cb()
    } else if (document.addEventListener) {
        document.addEventListener('DOMContentLoaded', cb)
    } else {
        document.attachEvent('onreadystatechange', function() {
        if (document.readyState == 'complete') cb()
        })
    }
}

var addUtterances = () => {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src = "https://utteranc.es/client.js";
    script.async = "async";

    script.setAttribute("repo", "robintibor/eeg-deep-learning-phd-thesis");
    script.setAttribute("issue-term", "pathname");
    script.setAttribute("theme", "github-light");
    script.setAttribute("label", "ðŸ’¬ comment");
    script.setAttribute("crossorigin", "anonymous");

    sections = document.querySelectorAll("div.section");
    if (sections !== null) {
        section = sections[sections.length-1];
        section.appendChild(script);
    }
}
commentsRunWhenDOMLoaded(addUtterances);
</script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Filterbank Common Spatial Patterns and Filterbank Network" href="FBCSPAndFBCSPNet.html" />
    <link rel="prev" title="Introduction" href="Introduction.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="_static/braindecode-logo.svg" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Deep Learning for Brain-Signal Decoding from Electroencephalography (EEG)</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="Abstract.html">
                    Deep Learning for Brain-Signal Decoding from Electroencephalography (EEG)
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="Introduction.html">
   Introduction
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Prior Work
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="FBCSPAndFBCSPNet.html">
   Filterbank Common Spatial Patterns and Filterbank Network
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="DeepArchitectures.html">
   Neural Network Architectures for EEG-Decoding
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="CroppedTraining.html">
   Cropped Training
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="PerturbationVisualization.html">
   Perturbation Visualization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="MovementDecoding.html">
   Decoding Movement-Related Brain Activity
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="TaskDecoding.html">
   Generalization to Other Tasks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Pathology.html">
   Decoding Pathology
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Invertible.html">
   Invertible Networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="FutureWork.html">
   Future Work
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="References.html">
   References
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/executablebooks/jupyter-book/master?urlpath=tree/PriorWork.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="_sources/PriorWork.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#decoding-problems-and-baselines">
   Decoding Problems and Baselines
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#input-domains-and-frequency-ranges">
   Input Domains and Frequency Ranges
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#network-architectures">
   Network Architectures
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#hyperparameter-evaluations">
   Hyperparameter Evaluations
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#visualizations">
   Visualizations
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Prior Work</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#decoding-problems-and-baselines">
   Decoding Problems and Baselines
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#input-domains-and-frequency-ranges">
   Input Domains and Frequency Ranges
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#network-architectures">
   Network Architectures
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#hyperparameter-evaluations">
   Hyperparameter Evaluations
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#visualizations">
   Visualizations
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="prior-work">
<span id="id1"></span><h1>Prior Work<a class="headerlink" href="#prior-work" title="Permalink to this headline">#</a></h1>
<div class="admonition-prior-to-our-work-research-on-deep-learning-based-eeg-decoding-was-limited admonition">
<p class="admonition-title">Prior to our work, research on deep-learning-based EEG decoding was limited</p>
<ul class="simple">
<li><p>Few studies compared to published well-tuned feature-based decoding results</p></li>
<li><p>Most EEG DL architectures had only 1-3 convolutional layers and included fully-connected layers</p></li>
<li><p>Most work only considered very restricted frequency ranges</p></li>
<li><p>Most studies only compared few design choices and training strategies</p></li>
</ul>
</div>
<div class="section" id="decoding-problems-and-baselines">
<h2>Decoding Problems and Baselines<a class="headerlink" href="#decoding-problems-and-baselines" title="Permalink to this headline">#</a></h2>
<table class="colwidths-auto table" id="prior-work-tasks-table">
<caption><span class="caption-number">Table 1 </span><span class="caption-text">Decoding problems in deep-learning EEG decoding studies prior to our work. Studies with external baseline compared their decoding results to an external baseline result by other authors.</span><a class="headerlink" href="#prior-work-tasks-table" title="Permalink to this table">#</a></caption>
<thead>
<tr class="row-odd"><th class="text-align:left head"><p>Decoding problem</p></th>
<th class="text-align:left head"><p>Number of studies</p></th>
<th class="text-align:left head"><p>With external baseline</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-align:left"><p>Imagined or Executed Movement</p></td>
<td class="text-align:left"><p>6</p></td>
<td class="text-align:left"><p>2</p></td>
</tr>
<tr class="row-odd"><td class="text-align:left"><p>Oddball/P300</p></td>
<td class="text-align:left"><p>5</p></td>
<td class="text-align:left"><p>1</p></td>
</tr>
<tr class="row-even"><td class="text-align:left"><p>Epilepsy-related</p></td>
<td class="text-align:left"><p>4</p></td>
<td class="text-align:left"><p>2</p></td>
</tr>
<tr class="row-odd"><td class="text-align:left"><p>Music Rhythm</p></td>
<td class="text-align:left"><p>2</p></td>
<td class="text-align:left"><p>0</p></td>
</tr>
<tr class="row-even"><td class="text-align:left"><p>Memory Performance/Cognitive Load</p></td>
<td class="text-align:left"><p>2</p></td>
<td class="text-align:left"><p>0</p></td>
</tr>
<tr class="row-odd"><td class="text-align:left"><p>Driver Performance</p></td>
<td class="text-align:left"><p>1</p></td>
<td class="text-align:left"><p>0</p></td>
</tr>
</tbody>
</table>
<p>Prior to 2017, when the first work presented in this thesis was published, there was only limited literature on EEG decoding with deep learning. From 19 studies we identified at the time, most were about movement-related decoding problems such as decoding which body part (hand, feet etc.) a person is imagining to move (see <a class="reference internal" href="#prior-work-tasks-table"><span class="std std-numref">Table 1</span></a>). Only 5 of the 19 studies compared their decoding results to an external baseline result, limiting the evaluation of the decoding results. To advance the understanding of EEG deep learning decoding, we therefore decided to first focus on widely researched movement-related decoding tasks with strong feature-based baselines.</p>
</div>
<div class="section" id="input-domains-and-frequency-ranges">
<h2>Input Domains and Frequency Ranges<a class="headerlink" href="#input-domains-and-frequency-ranges" title="Permalink to this headline">#</a></h2>
<div class="cell tag_hide-input tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">cm</span>
<span class="kn">import</span> <span class="nn">seaborn</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">from</span> <span class="nn">myst_nb</span> <span class="kn">import</span> <span class="n">glue</span>
<span class="n">seaborn</span><span class="o">.</span><span class="n">set_palette</span><span class="p">(</span><span class="s1">&#39;colorblind&#39;</span><span class="p">)</span>
<span class="n">seaborn</span><span class="o">.</span><span class="n">set_style</span><span class="p">(</span><span class="s1">&#39;darkgrid&#39;</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">re</span>

<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="o">%</span><span class="k">config</span> InlineBackend.figure_format = &#39;png&#39;
<span class="c1">#matplotlib.rcParams[&#39;figure.figsize&#39;] = (12.0, 1.0)</span>
<span class="n">matplotlib</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;font.size&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">14</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="s1">&#39;Time,  8â€“30 Hz &#39;</span><span class="p">,</span> <span class="s1">&#39;Time, 0.1â€“40 Hz &#39;</span><span class="p">,</span> <span class="s1">&#39;Time, 0.05â€“15 Hz &#39;</span><span class="p">,</span>
       <span class="s1">&#39;Time, 0.3â€“20 Hz &#39;</span><span class="p">,</span> <span class="s1">&#39;Frequency, 6â€“30 Hz &#39;</span><span class="p">,</span> <span class="s1">&#39; Frequency, 0â€“200 Hz &#39;</span><span class="p">,</span>
       <span class="s1">&#39;Time,  1â€“50 Hz &#39;</span><span class="p">,</span> <span class="s1">&#39; Time,  0â€“100 HZ &#39;</span><span class="p">,</span>
       <span class="s1">&#39;Frequency, mean amplitude for 0â€“7 Hz, 7â€“14 Hz, 14â€“49 Hz &#39;</span><span class="p">,</span>
       <span class="s1">&#39;Time, 0.5â€“50 Hz &#39;</span><span class="p">,</span> <span class="s1">&#39;Time,  0â€“128 Hz &#39;</span><span class="p">,</span>
       <span class="s1">&#39; Frequency, mean power for 4â€“7 Hz, 8â€“13 Hz, 13â€“30 Hz &#39;</span><span class="p">,</span>
       <span class="s1">&#39;Time, 0.5â€“30Hz &#39;</span><span class="p">,</span> <span class="s1">&#39;Time, 0.1â€“50 Hz &#39;</span><span class="p">,</span>
       <span class="s1">&#39;Frequency, 4â€“40 Hz, using FBCSP &#39;</span><span class="p">,</span>
       <span class="s1">&#39; Time and frequency evaluated, 0-200 Hz &#39;</span><span class="p">,</span> <span class="s1">&#39;Frequency, 8â€“30 Hz &#39;</span><span class="p">,</span>
       <span class="s1">&#39;Time, 0.15â€“200 Hz &#39;</span><span class="p">,</span> <span class="s1">&#39; Time, 0.1-20 Hz &#39;</span><span class="p">])</span>
<span class="n">domain_strings</span> <span class="o">=</span> <span class="p">[</span><span class="n">s</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;,&#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">a</span><span class="p">]</span>
<span class="n">start_fs</span> <span class="o">=</span> <span class="p">[</span><span class="nb">float</span><span class="p">(</span><span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;[a-z ]+&#39;</span><span class="p">,</span><span class="sa">r</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">re</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;[â€“-â€“-]&#39;</span><span class="p">,</span><span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">s</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;,&#39;</span><span class="p">)[</span><span class="mi">1</span><span class="p">:]))[</span><span class="mi">0</span><span class="p">]))</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">a</span><span class="p">]</span>
<span class="n">end_fs</span> <span class="o">=</span> <span class="p">[</span><span class="nb">float</span><span class="p">(</span><span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;[a-z HZFBCSP]+&#39;</span><span class="p">,</span><span class="sa">r</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">re</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;[â€“-â€“-]&#39;</span><span class="p">,</span><span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">s</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;,&#39;</span><span class="p">)[</span><span class="mi">1</span><span class="p">:]))[</span><span class="mi">1</span><span class="p">]))</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">a</span><span class="p">]</span>
<span class="n">domain_strings</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">domain_strings</span><span class="p">)</span>
<span class="n">start_fs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">start_fs</span><span class="p">)</span>
<span class="n">end_fs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">end_fs</span><span class="p">)</span>

<span class="n">freq_mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="s1">&#39;freq&#39;</span> <span class="ow">in</span> <span class="n">s</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">domain_strings</span><span class="p">])</span>
<span class="n">time_mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="s1">&#39;time&#39;</span> <span class="ow">in</span> <span class="n">s</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">domain_strings</span><span class="p">])</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="mi">98349384</span><span class="p">)</span>
<span class="n">color</span> <span class="o">=</span> <span class="n">seaborn</span><span class="o">.</span><span class="n">color_palette</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">i_sort</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">flatnonzero</span><span class="p">(</span><span class="n">time_mask</span><span class="p">)[</span><span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">end_fs</span><span class="p">[</span><span class="n">time_mask</span><span class="p">])]</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">d</span><span class="p">,</span><span class="n">s</span><span class="p">,</span><span class="n">e</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span>
        <span class="n">domain_strings</span><span class="p">[</span><span class="n">i_sort</span><span class="p">],</span> <span class="n">start_fs</span><span class="p">[</span><span class="n">i_sort</span><span class="p">],</span> <span class="n">end_fs</span><span class="p">[</span><span class="n">i_sort</span><span class="p">])):</span>
    <span class="n">offset</span> <span class="o">=</span> <span class="mf">0.6</span><span class="o">*</span><span class="n">i</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">i_sort</span><span class="p">)</span> <span class="o">-</span> <span class="mf">0.3</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">offset</span><span class="p">,</span><span class="n">offset</span><span class="p">]</span> <span class="p">,</span> <span class="p">[</span><span class="n">s</span><span class="p">,</span> <span class="n">e</span><span class="p">],</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s1">&#39;-&#39;</span><span class="p">)</span>
<span class="n">i_sort</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">flatnonzero</span><span class="p">(</span><span class="n">freq_mask</span><span class="p">)[</span><span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">end_fs</span><span class="p">[</span><span class="n">freq_mask</span><span class="p">])]</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">d</span><span class="p">,</span><span class="n">s</span><span class="p">,</span><span class="n">e</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span>
        <span class="n">domain_strings</span><span class="p">[</span><span class="n">i_sort</span><span class="p">],</span> <span class="n">start_fs</span><span class="p">[</span><span class="n">i_sort</span><span class="p">],</span> <span class="n">end_fs</span><span class="p">[</span><span class="n">i_sort</span><span class="p">])):</span>
    <span class="n">offset</span> <span class="o">=</span> <span class="mf">0.6</span><span class="o">*</span><span class="n">i</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">i_sort</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.7</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">offset</span><span class="p">,</span><span class="n">offset</span><span class="p">]</span> <span class="p">,</span> <span class="p">[</span><span class="n">s</span><span class="p">,</span> <span class="n">e</span><span class="p">],</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s1">&#39;-&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="mf">1.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Input domain&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Frequency [Hz]&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;Time&quot;</span><span class="p">,</span> <span class="s2">&quot;Frequency&quot;</span><span class="p">],</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">45</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Input domains and frequency ranges in prior work&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mf">1.05</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">25</span><span class="p">,</span><span class="mi">50</span><span class="p">,</span><span class="mi">75</span><span class="p">,</span><span class="mi">100</span><span class="p">,</span><span class="mi">150</span><span class="p">,</span><span class="mi">200</span><span class="p">])</span>
<span class="n">glue</span><span class="p">(</span><span class="s1">&#39;input_domain_fig&#39;</span><span class="p">,</span> <span class="n">fig</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">(</span><span class="n">fig</span><span class="p">)</span>
<span class="kc">None</span>
</pre></div>
</div>
</div>
</div>
<div class="figure align-default" id="id27">
<div class="cell_output docutils container">
<img alt="_images/PriorWork_6_0.png" src="_images/PriorWork_6_0.png" />
</div>
<p class="caption"><span class="caption-number">Fig. 1 </span><span class="caption-text"><em>Input domains and frequency ranges in prior work</em>. Grey lines represent frequency ranges of individual studies. Note that many studies only include frequencies below 50 Hz, some use very restricted ranges (alpha/beta band).</span><a class="headerlink" href="#id27" title="Permalink to this image">#</a></p>
</div>
<p>Deep networks can either decode directly from the time-domain EEG or process the data in the frequency domain, for example after a Fourier transformation. 12 of the prior studies used time-domain inputs, 6 used frequency-domain inputs and one used both. We decided to work directly in the time domain, as the deep networks should be capable to learn to extract any needed spectral information from the time-domain input.</p>
<p>Most prior studies that were working in the time domain only used frequencies below 50 Hz. We were interested in how well deep networks can also extract lesser-used higher-frequency components of the EEG signal. We used a sampling rate of 250 Hz, which means we were able to analyze frequencies up to the Nyquist frequency of 125 Hz. As a suitable dataset where high-frequency information may help decoding, we included our high-gamma dataset in our study, since it was recorded specifically to allow extraction of higher-frequency (&gt;50 Hz) information from scalp EEG.</p>
</div>
<div class="section" id="network-architectures">
<h2>Network Architectures<a class="headerlink" href="#network-architectures" title="Permalink to this headline">#</a></h2>
<div class="cell tag_hide-input tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ls</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="s1">&#39; 2/2 &#39;</span><span class="p">,</span> <span class="s1">&#39; 3/1 &#39;</span><span class="p">,</span> <span class="s1">&#39; 2/2 &#39;</span><span class="p">,</span> <span class="s1">&#39; 3/2 &#39;</span><span class="p">,</span> <span class="s1">&#39; 1/1 &#39;</span><span class="p">,</span> <span class="s1">&#39; 1/2 &#39;</span><span class="p">,</span> <span class="s1">&#39; 1/3 &#39;</span><span class="p">,</span>
       <span class="s1">&#39; 1â€“2/2 &#39;</span><span class="p">,</span> <span class="s1">&#39; 3/1 (+ LSTM as postprocessor) &#39;</span><span class="p">,</span> <span class="s1">&#39; 4/3 &#39;</span><span class="p">,</span> <span class="s1">&#39; 1-3/1-3 &#39;</span><span class="p">,</span>
       <span class="s1">&#39; 3â€“7/2 (+ LSTM or other temporal post-processing (see design choices)) &#39;</span><span class="p">,</span>
       <span class="s1">&#39; 2/1 &#39;</span><span class="p">,</span> <span class="s1">&#39; 3/3 (Spatio-temporal regularization) &#39;</span><span class="p">,</span>
       <span class="s1">&#39; 2/2 (Final fully connected layer uses concatenated output by convolutionaland fully connected layers) &#39;</span><span class="p">,</span>
       <span class="s1">&#39; 1-2/1 &#39;</span><span class="p">,</span>
       <span class="s1">&#39;2/0 (Convolutional deep belief network, separately trained RBF-SVM classifier) &#39;</span><span class="p">,</span>
       <span class="s1">&#39; 3/1 (Convolutional layers trained as convolutional stacked autoencoder with target prior) &#39;</span><span class="p">,</span>
       <span class="s1">&#39; 2/2 &#39;</span><span class="p">])</span>

<span class="n">conv_ls</span> <span class="o">=</span> <span class="p">[</span><span class="n">l</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;/&#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">ls</span><span class="p">]</span>
<span class="n">low_conv_ls</span> <span class="o">=</span> <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">re</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;[â€“-]&#39;</span><span class="p">,</span> <span class="n">c</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span><span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">conv_ls</span><span class="p">]</span>
<span class="n">high_conv_ls</span> <span class="o">=</span> <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">re</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;[â€“-]&#39;</span><span class="p">,</span> <span class="n">c</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">conv_ls</span><span class="p">]</span>
<span class="n">dense_ls</span> <span class="o">=</span> <span class="p">[</span><span class="n">l</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;/&#39;</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">ls</span><span class="p">]</span>
<span class="n">low_dense_ls</span> <span class="o">=</span> <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">re</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;[â€“-]&#39;</span><span class="p">,</span> <span class="n">c</span><span class="p">[:</span><span class="mi">8</span><span class="p">])[</span><span class="mi">0</span><span class="p">][:</span><span class="mi">2</span><span class="p">])</span><span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">dense_ls</span><span class="p">]</span>
<span class="n">high_dense_ls</span> <span class="o">=</span> <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">re</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;[â€“-]&#39;</span><span class="p">,</span> <span class="n">c</span><span class="p">[:</span><span class="mi">8</span><span class="p">])[</span><span class="o">-</span><span class="mi">1</span><span class="p">][:</span><span class="mi">2</span><span class="p">])</span><span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">dense_ls</span><span class="p">]</span>

<span class="n">all_conv_ls</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">low_c</span><span class="p">,</span> <span class="n">high_c</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">low_c</span><span class="p">,</span> <span class="n">high_c</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">low_conv_ls</span><span class="p">,</span> <span class="n">high_conv_ls</span><span class="p">)])</span>
<span class="n">all_dense_ls</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">low_c</span><span class="p">,</span> <span class="n">high_c</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">low_c</span><span class="p">,</span> <span class="n">high_c</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">low_dense_ls</span><span class="p">,</span> <span class="n">high_dense_ls</span><span class="p">)])</span>
<span class="n">bincount_conv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">bincount</span><span class="p">(</span><span class="n">all_conv_ls</span><span class="p">)</span>
<span class="n">bincount_dense</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">bincount</span><span class="p">(</span><span class="n">all_dense_ls</span><span class="p">)</span>
<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="mi">98349384</span><span class="p">)</span>
<span class="n">color</span> <span class="o">=</span> <span class="n">seaborn</span><span class="o">.</span><span class="n">color_palette</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="k">for</span> <span class="n">low_c</span><span class="p">,</span> <span class="n">high_c</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">low_conv_ls</span><span class="p">,</span> <span class="n">high_conv_ls</span><span class="p">):</span>
    <span class="n">offset</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.1</span>
    <span class="n">tried_cs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">low_c</span><span class="p">,</span> <span class="n">high_c</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">offset</span><span class="p">,]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">tried_cs</span><span class="p">),</span> <span class="n">tried_cs</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s1">&#39;:&#39;</span><span class="p">)</span>
    
<span class="k">for</span> <span class="n">i_c</span><span class="p">,</span> <span class="n">n_c</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">bincount_conv</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">i_c</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="n">n_c</span><span class="o">*</span><span class="mi">40</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">0.535</span><span class="p">,</span> <span class="n">i_c</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">n_c</span><span class="p">)</span><span class="o">+</span> <span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;left&#39;</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">)</span>

<span class="k">for</span> <span class="n">low_c</span><span class="p">,</span> <span class="n">high_c</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">low_dense_ls</span><span class="p">,</span> <span class="n">high_dense_ls</span><span class="p">):</span>
    <span class="n">offset</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">rng</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.1</span>
    <span class="n">tried_cs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">low_c</span><span class="p">,</span> <span class="n">high_c</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">offset</span><span class="p">,]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">tried_cs</span><span class="p">),</span> <span class="n">tried_cs</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s1">&#39;:&#39;</span><span class="p">)</span>
    
<span class="k">for</span> <span class="n">i_c</span><span class="p">,</span> <span class="n">n_c</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">bincount_dense</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="mf">1.4</span><span class="p">,</span> <span class="n">i_c</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="n">n_c</span><span class="o">*</span><span class="mi">40</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">1.535</span><span class="p">,</span> <span class="n">i_c</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">n_c</span><span class="p">)</span><span class="o">+</span> <span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;left&#39;</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Type of layer&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Number of layers&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;Convolutional&quot;</span><span class="p">,</span> <span class="s2">&quot;Dense&quot;</span><span class="p">],</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">45</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">7</span><span class="p">]);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Number of layers in prior works&#39; architectures&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mf">1.05</span><span class="p">)</span>
<span class="n">glue</span><span class="p">(</span><span class="s1">&#39;layernum_fig&#39;</span><span class="p">,</span> <span class="n">fig</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">(</span><span class="n">fig</span><span class="p">)</span>
<span class="kc">None</span>
</pre></div>
</div>
</div>
</div>
<div class="figure align-default" id="id28">
<div class="cell_output docutils container">
<img alt="_images/PriorWork_10_0.png" src="_images/PriorWork_10_0.png" />
</div>
<p class="caption"><span class="caption-number">Fig. 2 </span><span class="caption-text"><em>Number of layers in prior work</em>. Small grey markers represent individual architectures. Dashed lines indicate different number of layers investigated in a single study (e.g., a single study investigated 3-7 convolutional layers). Larger grey markers indicate sum of occurences of that layer number over all studies (e.g., 9 architectures used 2 convolutional layers). Note most architectures use only 1-3 convolutional layers.</span><a class="headerlink" href="#id28" title="Permalink to this image">#</a></p>
</div>
<p>The architectures used in prior work typically only included up to 3 layers, with only 2 studies considering more layers. As network architectures in other domains tend to be a lot deeper, we also evalauted architectures with a larger number of layers in our work. Several architectures from prior work also included fully-connected layers with larger number of parameters which had fallen out of favor in computer-vision deep-learning architectures due to their large compute and memory requirements with little accuracy benefit. Our architectures do not include traditional fully-connected layers with large number of parameters.</p>
</div>
<div class="section" id="hyperparameter-evaluations">
<h2>Hyperparameter Evaluations<a class="headerlink" href="#hyperparameter-evaluations" title="Permalink to this headline">#</a></h2>
<table class="colwidths-auto table" id="prior-work-design-choices-table">
<caption><span class="caption-number">Table 2 </span><span class="caption-text">Design choices and training strategies that prior deep-learning EEG decoding studies had studies.</span><a class="headerlink" href="#prior-work-design-choices-table" title="Permalink to this table">#</a></caption>
<thead>
<tr class="row-odd"><th class="text-align:left head"><p>Study</p></th>
<th class="text-align:left head"><p>Design choices</p></th>
<th class="text-align:left head"><p>Training strategies</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-align:left"><p><span id="id2">[<a class="reference internal" href="References.html#id150" title="Vernon J. Lawhern, Amelia J. Solon, Nicholas R. Waytowich, Stephen M. Gordon, Chou P. Hung, and Brent J. Lance. EEGNet: A Compact Convolutional Network for EEG-based Brain-Computer Interfaces. arXiv:1611.08024 [cs, q-bio, stat], November 2016. arXiv: 1611.08024. URL: http://arxiv.org/abs/1611.08024 (visited on 2016-12-20).">Lawhern <em>et al.</em>, 2016</a>]</span></p></td>
<td class="text-align:left"><p>Kernel sizes</p></td>
<td class="text-align:left"><p></p></td>
</tr>
<tr class="row-odd"><td class="text-align:left"><p><span id="id3">[<a class="reference internal" href="References.html#id222" title="Xuyun Sun, Cunle Qian, Zhongqin Chen, Zhaohui Wu, Benyan Luo, and Gang Pan. Remembered or Forgotten?â€”An EEG-Based Computational Prediction Approach. PLOS ONE, 11(12):e0167497, December 2016. URL: http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0167497 (visited on 2017-02-14), doi:10.1371/journal.pone.0167497.">Sun <em>et al.</em>, 2016</a>]</span></p></td>
<td class="text-align:left"><p></p></td>
<td class="text-align:left"><p>Different time windows</p></td>
</tr>
<tr class="row-even"><td class="text-align:left"><p><span id="id4">[<a class="reference internal" href="References.html#id215" title="Yousef Rezaei Tabar and Ugur Halici. A novel deep learning approach for classification of EEG motor imagery signals. Journal of Neural Engineering, 14(1):016003, 2017. URL: http://stacks.iop.org/1741-2552/14/i=1/a=016003 (visited on 2017-02-14), doi:10.1088/1741-2560/14/1/016003.">Tabar and Halici, 2017</a>]</span></p></td>
<td class="text-align:left"><p>Addition of six-layer stacked autoencoder on ConvNet features <br> Kernel sizes</p></td>
<td class="text-align:left"><p></p></td>
</tr>
<tr class="row-odd"><td class="text-align:left"><p><span id="id5">[<a class="reference internal" href="References.html#id172" title="J. Liang, R. Lu, C. Zhang, and F. Wang. Predicting Seizures from Electroencephalography Recordings: A Knowledge Transfer Strategy. In 2016 IEEE International Conference on Healthcare Informatics (ICHI), 184â€“191. October 2016. doi:10.1109/ICHI.2016.27.">Liang <em>et al.</em>, 2016</a>]</span></p></td>
<td class="text-align:left"><p></p></td>
<td class="text-align:left"><p>Different subdivisions of frequency range <br>Different lengths of time crops <br>Transfer learning with auxiliary non-epilepsy datasets</p></td>
</tr>
<tr class="row-even"><td class="text-align:left"><p><span id="id6">[<a class="reference internal" href="References.html#id180" title="Mehdi Hajinoroozi, Zijing Mao, Tzyy-Ping Jung, Chin-Teng Lin, and Yufei Huang. EEG-based prediction of driver's cognitive performance by deep convolutional neural network. Signal Processing: Image Communication, 47:549â€“555, September 2016. URL: http://www.sciencedirect.com/science/article/pii/S0923596516300832 (visited on 2016-12-20), doi:10.1016/j.image.2016.05.018.">Hajinoroozi <em>et al.</em>, 2016</a>]</span></p></td>
<td class="text-align:left"><p>Replacement of convolutional layers by restricted Boltzmann machines with slightly varied network architecture}</p></td>
<td class="text-align:left"><p></p></td>
</tr>
<tr class="row-odd"><td class="text-align:left"><p><span id="id7">[<a class="reference internal" href="References.html#id154" title="A. Antoniades, L. Spyrou, C. C. Took, and S. Sanei. Deep learning for epileptic intracranial EEG data. In 2016 IEEE 26th International Workshop on Machine Learning for Signal Processing (MLSP), 1â€“6. September 2016. doi:10.1109/MLSP.2016.7738824.">Antoniades <em>et al.</em>, 2016</a>]</span></p></td>
<td class="text-align:left"><p>1 or 2 convolutional layers</p></td>
<td class="text-align:left"><p></p></td>
</tr>
<tr class="row-even"><td class="text-align:left"><p><span id="id8">[<a class="reference internal" href="References.html#id204" title="A. Page, C. Shea, and T. Mohsenin. Wearable seizure detection using convolutional neural networks with transfer learning. In 2016 IEEE International Symposium on Circuits and Systems (ISCAS), 1086â€“1089. May 2016. doi:10.1109/ISCAS.2016.7527433.">Page <em>et al.</em>, 2016</a>]</span></p></td>
<td class="text-align:left"><p></p></td>
<td class="text-align:left"><p>Cross-subject supervised training, within-subject finetuning of fully connected layers</p></td>
</tr>
<tr class="row-odd"><td class="text-align:left"><p><span id="id9">[<a class="reference internal" href="References.html#id197" title="Pouya Bashivan, Irina Rish, Mohammed Yeasin, and Noel Codella. Learning Representations from EEG with Deep Recurrent-Convolutional Neural Networks. In arXiv:1511.06448 [cs]. 2016. arXiv: 1511.06448. URL: http://arxiv.org/abs/1511.06448 (visited on 2016-12-20).">Bashivan <em>et al.</em>, 2016</a>]</span></p></td>
<td class="text-align:left"><p>Number of convolutional layers <br>Temporal processing of ConvNet output by max pooling, temporal convolution, LSTM or temporal convolution + LSTM</p></td>
<td class="text-align:left"><p></p></td>
</tr>
<tr class="row-even"><td class="text-align:left"><p><span id="id10">[<a class="reference internal" href="References.html#id226" title="Sebastian Stober. Learning Discriminative Features from Electroencephalography Recordings by Encoding Similarity Constraints. In Bernstein Conference 2016. 2016. doi:10.12751/nncn.bc2016.0223.">Stober, 2016</a>]</span></p></td>
<td class="text-align:left"><p>Kernel sizes</p></td>
<td class="text-align:left"><p>Pretraining first layer as convolutional autoencoder with different constraints</p></td>
</tr>
<tr class="row-odd"><td class="text-align:left"><p><span id="id11">[<a class="reference internal" href="References.html#id117" title="S. Sakhavi, C. Guan, and S. Yan. Parallel convolutional-linear neural network for motor imagery classification. In Signal Processing Conference (EUSIPCO), 2015 23rd European, 2736â€“2740. August 2015. doi:10.1109/EUSIPCO.2015.7362882.">Sakhavi <em>et al.</em>, 2015</a>]</span></p></td>
<td class="text-align:left"><p>Combination ConvNet and MLP (trained on different features) vs. only ConvNet vs. only MLP</p></td>
<td class="text-align:left"><p></p></td>
</tr>
<tr class="row-even"><td class="text-align:left"><p><span id="id12">[<a class="reference internal" href="References.html#id184" title="Sebastian Stober, Daniel J. Cameron, and Jessica A. Grahn. Using Convolutional Neural Networks to Recognize Rhythm Stimuli from Electroencephalography Recordings. In Proceedings of the 27th International Conference on Neural Information Processing Systems, NIPS'14, 1449â€“1457. Cambridge, MA, USA, 2014. MIT Press. URL: http://dl.acm.org/citation.cfm?id=2968826.2968988 (visited on 2016-12-20).">Stober <em>et al.</em>, 2014</a>]</span></p></td>
<td class="text-align:left"><p>Best values from automatic hyperparameter optimization: frequency cutoff, one vs two layers, kernel sizes, number of channels, pooling width</p></td>
<td class="text-align:left"><p>Best values from automatic hyperparameter optimization: learning rate, learning rate decay, momentum, final momentum</p></td>
</tr>
<tr class="row-odd"><td class="text-align:left"><p><span id="id13">[<a class="reference internal" href="References.html#id209" title="Zuoguan Wang, Siwei Lyu, Gerwin Schalk, and Qiang Ji. Deep Feature Learning Using Target Priors with Applications in ECoG Signal Decoding for BCI. In Proceedings of the Twenty-Third International Joint Conference on Artificial Intelligence, IJCAI '13, 1785â€“1791. Beijing, China, 2013. AAAI Press. URL: http://dl.acm.org/citation.cfm?id=2540128.2540384 (visited on 2017-01-16).">Wang <em>et al.</em>, 2013</a>]</span></p></td>
<td class="text-align:left"><p>Partially supervised CSA</p></td>
<td class="text-align:left"><p></p></td>
</tr>
<tr class="row-even"><td class="text-align:left"><p><span id="id14">[<a class="reference internal" href="References.html#id212" title="Hubert Cecotti and Axel Graser. Convolutional Neural Networks for P300 Detection with Application to Brain-Computer Interfaces. IEEE Transactions on Pattern Analysis and Machine Intelligence, 33(3):433â€“445, March 2011. URL: http://dx.doi.org/10.1109/TPAMI.2010.125 (visited on 2016-12-20), doi:10.1109/TPAMI.2010.125.">Cecotti and Graser, 2011</a>]</span></p></td>
<td class="text-align:left"><p>Electrode subset (fixed or automatically determined) <br>Using only one spatial filter <br>Different ensembling strategies</p></td>
<td class="text-align:left"><p></p></td>
</tr>
</tbody>
</table>
<p>Prior work varied widely in which design choices and training strategies were compared. 6 of the studies did not compare any design choices or  training strategy hyperparamters. The other 13 studies evaluated different hyperparameters, with the most common one the kernel size (see <a class="reference internal" href="#prior-work-design-choices-table"><span class="std std-numref">Table 2</span></a>). Only one study evaluated a wider range of hyperparameters <span id="id15">[<a class="reference internal" href="References.html#id184" title="Sebastian Stober, Daniel J. Cameron, and Jessica A. Grahn. Using Convolutional Neural Networks to Recognize Rhythm Stimuli from Electroencephalography Recordings. In Proceedings of the 27th International Conference on Neural Information Processing Systems, NIPS'14, 1449â€“1457. Cambridge, MA, USA, 2014. MIT Press. URL: http://dl.acm.org/citation.cfm?id=2968826.2968988 (visited on 2016-12-20).">Stober <em>et al.</em>, 2014</a>]</span>. To fill this gap, we compared a wider range of design choices and training strategies and specifically evaluated in how far improvements of computer vision architecture design choices and training strategies also lead to improvements in EEG decoding.</p>
</div>
<div class="section" id="visualizations">
<h2>Visualizations<a class="headerlink" href="#visualizations" title="Permalink to this headline">#</a></h2>
<table class="colwidths-auto table" id="prior-work-visualizations-table">
<caption><span class="caption-number">Table 3 </span><span class="caption-text">Visualizations presented in prior work.</span><a class="headerlink" href="#prior-work-visualizations-table" title="Permalink to this table">#</a></caption>
<thead>
<tr class="row-odd"><th class="text-align:left head"><p>Study</p></th>
<th class="text-align:left head"><p>Visualization type(s)</p></th>
<th class="text-align:left head"><p>Visualization findings</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-align:left"><p><span id="id16">[<a class="reference internal" href="References.html#id222" title="Xuyun Sun, Cunle Qian, Zhongqin Chen, Zhaohui Wu, Benyan Luo, and Gang Pan. Remembered or Forgotten?â€”An EEG-Based Computational Prediction Approach. PLOS ONE, 11(12):e0167497, December 2016. URL: http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0167497 (visited on 2017-02-14), doi:10.1371/journal.pone.0167497.">Sun <em>et al.</em>, 2016</a>]</span></p></td>
<td class="text-align:left"><p>Weights (spatial)</p></td>
<td class="text-align:left"><p>Largest weights found over prefrontal and temporal cortex</p></td>
</tr>
<tr class="row-odd"><td class="text-align:left"><p><span id="id17">[<a class="reference internal" href="References.html#id196" title="Ran Manor, Liran Mishali, and Amir B. Geva. Multimodal Neural Network for Rapid Serial Visual Presentation Brain Computer Interface. Frontiers in Computational Neuroscience, December 2016. URL: http://www.ncbi.nlm.nih.gov/pmc/articles/PMC5168930/ (visited on 2017-02-03), doi:10.3389/fncom.2016.00130.">Manor <em>et al.</em>, 2016</a>]</span></p></td>
<td class="text-align:left"><p>Weights <br> Activations <br> Saliency maps by gradient</p></td>
<td class="text-align:left"><p>Weights showed typical P300 distribution <br>Activations were high at plausible times (300-500ms) <br>Saliency maps showed plausible spatio-temporal plots</p></td>
</tr>
<tr class="row-even"><td class="text-align:left"><p><span id="id18">[<a class="reference internal" href="References.html#id215" title="Yousef Rezaei Tabar and Ugur Halici. A novel deep learning approach for classification of EEG motor imagery signals. Journal of Neural Engineering, 14(1):016003, 2017. URL: http://stacks.iop.org/1741-2552/14/i=1/a=016003 (visited on 2017-02-14), doi:10.1088/1741-2560/14/1/016003.">Tabar and Halici, 2017</a>]</span></p></td>
<td class="text-align:left"><p>Weights (spatial + frequential)</p></td>
<td class="text-align:left"><p>Some weights represented difference of values of two electrodes on different sides of head</p></td>
</tr>
<tr class="row-odd"><td class="text-align:left"><p><span id="id19">[<a class="reference internal" href="References.html#id172" title="J. Liang, R. Lu, C. Zhang, and F. Wang. Predicting Seizures from Electroencephalography Recordings: A Knowledge Transfer Strategy. In 2016 IEEE International Conference on Healthcare Informatics (ICHI), 184â€“191. October 2016. doi:10.1109/ICHI.2016.27.">Liang <em>et al.</em>, 2016</a>]</span></p></td>
<td class="text-align:left"><p>Weights <br> Clustering of weights</p></td>
<td class="text-align:left"><p>Clusters of weights showed typical frequency band subdivision (delta, theta, alpha, beta, gamma)</p></td>
</tr>
<tr class="row-even"><td class="text-align:left"><p><span id="id20">[<a class="reference internal" href="References.html#id154" title="A. Antoniades, L. Spyrou, C. C. Took, and S. Sanei. Deep learning for epileptic intracranial EEG data. In 2016 IEEE 26th International Workshop on Machine Learning for Signal Processing (MLSP), 1â€“6. September 2016. doi:10.1109/MLSP.2016.7738824.">Antoniades <em>et al.</em>, 2016</a>]</span></p></td>
<td class="text-align:left"><p>Weights <br>Correlation weights and interictal epileptic discharges (IED) <br>Activations</p></td>
<td class="text-align:left"><p>Weights increasingly correlated with IED waveforms with increasing number of training iterations <br>Second layer captured more complex and well-defined epileptic shapes than first layer <br>IEDs led to highly synchronized activations for neighbouring electrodes</p></td>
</tr>
<tr class="row-odd"><td class="text-align:left"><p><span id="id21">[<a class="reference internal" href="References.html#id182" title="Pierre Thodoroff, Joelle Pineau, and Andrew Lim. Learning Robust Features using Deep Learning for Automatic Seizure Detection. In JMLR Workshop and Conference Proceedings, volume 56. 2016. URL: http://www.jmlr.org/proceedings/papers/v56/Thodoroff16.pdf (visited on 2017-02-14).">Thodoroff <em>et al.</em>, 2016</a>]</span></p></td>
<td class="text-align:left"><p>Input occlusion and effect on prediction accuracy</p></td>
<td class="text-align:left"><p>Allowed to locate areas critical for seizure</p></td>
</tr>
<tr class="row-even"><td class="text-align:left"><p><span id="id22">[<a class="reference internal" href="References.html#id200" title="Jared Shamwell, Hyungtae Lee, Heesung Kwon, Amar R. Marathe, Vernon Lawhern, and William Nothwang. Single-trial EEG RSVP classification using convolutional neural networks. In Thomas George, Achyut K. Dutta, and M. Saif Islam, editors, SPIE Defense+ Security, volume 9836. International Society for Optics and Photonics, May 2016. URL: http://proceedings.spiedigitallibrary.org/proceeding.aspx?doi=10.1117/12.2224172 (visited on 2017-02-14), doi:10.1117/12.2224172.">Shamwell <em>et al.</em>, 2016</a>]</span></p></td>
<td class="text-align:left"><p>Weights (spatial)</p></td>
<td class="text-align:left"><p>Some filter weights had expected topographic distributions for P300 <br>Others filters had large weights on areas not traditionally associated with P300</p></td>
</tr>
<tr class="row-odd"><td class="text-align:left"><p><span id="id23">[<a class="reference internal" href="References.html#id197" title="Pouya Bashivan, Irina Rish, Mohammed Yeasin, and Noel Codella. Learning Representations from EEG with Deep Recurrent-Convolutional Neural Networks. In arXiv:1511.06448 [cs]. 2016. arXiv: 1511.06448. URL: http://arxiv.org/abs/1511.06448 (visited on 2016-12-20).">Bashivan <em>et al.</em>, 2016</a>]</span></p></td>
<td class="text-align:left"><p>Inputs that maximally activate given filter <br>Activations of these inputs <br>â€Deconvolutionâ€ for these inputs</p></td>
<td class="text-align:left"><p>Different filters were sensitive to different frequency bands <br>Later layers had more spatially localized activations <br>Learned features had noticeable links to well-known electrophysiological markers of cognitive load <br></p></td>
</tr>
<tr class="row-even"><td class="text-align:left"><p><span id="id24">[<a class="reference internal" href="References.html#id226" title="Sebastian Stober. Learning Discriminative Features from Electroencephalography Recordings by Encoding Similarity Constraints. In Bernstein Conference 2016. 2016. doi:10.12751/nncn.bc2016.0223.">Stober, 2016</a>]</span></p></td>
<td class="text-align:left"><p>Weights (spatial+3 timesteps, pretrained as autoencoder)</p></td>
<td class="text-align:left"><p>Different constraints led to different weights, one type of constraints could enforce weights that are similar across subjects; other type of constraints led to weights that have similar spatial topographies under different architectural configurations and preprocessings</p></td>
</tr>
<tr class="row-odd"><td class="text-align:left"><p><span id="id25">[<a class="reference internal" href="References.html#id147" title="Ran Manor and Amir B. Geva. Convolutional Neural Network for Multi-Category Rapid Serial Visual Presentation BCI. Frontiers in Computational Neuroscience, 9:146, 2015. doi:10.3389/fncom.2015.00146.">Manor and Geva, 2015</a>]</span></p></td>
<td class="text-align:left"><p>Weights <br> Mean and single-trial activations</p></td>
<td class="text-align:left"><p>Spatiotemporal regularization led to softer peaks in weights <br>Spatial weights showed typical P300 distribution <br>Activations mostly had peaks at typical times (300-400ms)</p></td>
</tr>
<tr class="row-even"><td class="text-align:left"><p><span id="id26">[<a class="reference internal" href="References.html#id212" title="Hubert Cecotti and Axel Graser. Convolutional Neural Networks for P300 Detection with Application to Brain-Computer Interfaces. IEEE Transactions on Pattern Analysis and Machine Intelligence, 33(3):433â€“445, March 2011. URL: http://dx.doi.org/10.1109/TPAMI.2010.125 (visited on 2016-12-20), doi:10.1109/TPAMI.2010.125.">Cecotti and Graser, 2011</a>]</span></p></td>
<td class="text-align:left"><p>Weights</p></td>
<td class="text-align:left"><p>Spatial filters were similar for different architectures <br>Spatial filters were different (more focal, more diffuse) for different subjects</p></td>
</tr>
</tbody>
</table>
<p>Visualizations can help understand what information the networks are extracting from the EEG signal. 11 of the prior 19 studies presented any visualizations. These studies mostly focussed on analyzing weights and activations, see <a class="reference internal" href="#prior-work-visualizations-table"><span class="std std-numref">Table 3</span></a>. In our work, we focused on investigating how far the networks extract features known to work well for movement-related decoding, see <a class="reference internal" href="PerturbationVisualization.html#perturbation-visualization"><span class="std std-ref">Perturbation Visualization</span></a>.</p>
<div class="tip admonition">
<p class="admonition-title">We aimed to thoroughly evaluate deep-learning-based EEG decoding byâ€¦</p>
<ul class="simple">
<li><p>using well-researched EEG movement-related decoding tasks with strong baselines</p></li>
<li><p>using a dataset suitable to analyze extraction of higher-frequency information</p></li>
<li><p>trying shallower EEG-specific as well as deeper more generic architectures</p></li>
<li><p>evaluating many design choices and two training strategies</p></li>
<li><p>investigating in how far networks learn to extract well-known EEG features</p></li>
</ul>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="Introduction.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Introduction</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="FBCSPAndFBCSPNet.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Filterbank Common Spatial Patterns and Filterbank Network</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By The Jupyter Book community<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>