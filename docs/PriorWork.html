

<!DOCTYPE html>


<html lang="en" data-theme="light">

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Prior Work &#8212; Deep Learning for Brain-Signal Decoding from Electroencephalography (EEG)</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "light";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="_static/.ipynb_checkpoints/custom-checkpoint.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script async="async" kind="hypothesis" src="https://hypothes.is/embed.js"></script>
    <script kind="utterances">

    var commentsRunWhenDOMLoaded = cb => {
    if (document.readyState != 'loading') {
        cb()
    } else if (document.addEventListener) {
        document.addEventListener('DOMContentLoaded', cb)
    } else {
        document.attachEvent('onreadystatechange', function() {
        if (document.readyState == 'complete') cb()
        })
    }
}

var addUtterances = () => {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src = "https://utteranc.es/client.js";
    script.async = "async";

    script.setAttribute("repo", "robintibor/eeg-deep-learning-phd-thesis");
    script.setAttribute("issue-term", "pathname");
    script.setAttribute("theme", "github-light");
    script.setAttribute("label", "💬 comment");
    script.setAttribute("crossorigin", "anonymous");

    sections = document.querySelectorAll("div.section");
    if (sections !== null) {
        section = sections[sections.length-1];
        section.appendChild(script);
    }
}
commentsRunWhenDOMLoaded(addUtterances);
</script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'PriorWork';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Filter Bank Common Spatial Patterns and Filterbank Network" href="FBCSPAndFBCSPNet.html" />
    <link rel="prev" title="Introduction" href="Introduction.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="light">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="Abstract.html">
  
  
  
  
    
    
    
    <img src="_static/braindecode-logo.svg" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="_static/braindecode-logo.svg" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="Introduction.html">Introduction</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Prior Work</a></li>
<li class="toctree-l1"><a class="reference internal" href="FBCSPAndFBCSPNet.html">Filter Bank Common Spatial Patterns and Filterbank Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="DeepArchitectures.html">Neural Network Architectures for EEG-Decoding</a></li>
<li class="toctree-l1"><a class="reference internal" href="CroppedTraining.html">Cropped Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="PerturbationVisualization.html">Perturbation Visualization</a></li>
<li class="toctree-l1"><a class="reference internal" href="Invertible.html">Invertible Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="MovementDecoding.html">Decoding Movement-Related Brain Activity</a></li>
<li class="toctree-l1"><a class="reference internal" href="TaskDecoding.html">Generalization to Other Tasks</a></li>
<li class="toctree-l1"><a class="reference internal" href="Pathology.html">Decoding Pathology</a></li>
<li class="toctree-l1"><a class="reference internal" href="UnderstandingPathology.html">Understanding Pathology Decoding With Invertible Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="FutureWork.html">Future Work</a></li>
<li class="toctree-l1"><a class="reference internal" href="References.html">References</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/PriorWork.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Prior Work</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#decoding-problems-and-baselines">Decoding Problems and Baselines</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#input-domains-and-frequency-ranges">Input Domains and Frequency Ranges</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#network-architectures">Network Architectures</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hyperparameter-evaluations">Hyperparameter Evaluations</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#visualizations">Visualizations</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <div class="tex2jax_ignore mathjax_ignore section" id="prior-work">
<span id="id1"></span><h1>Prior Work<a class="headerlink" href="#prior-work" title="Permalink to this heading">#</a></h1>
<div class="admonition-prior-to-our-work-research-on-deep-learning-based-eeg-decoding-was-limited admonition">
<p class="admonition-title">Prior to our work, research on deep-learning-based EEG decoding was limited</p>
<ul class="simple">
<li><p>Few studies compared to published well-tuned feature-based decoding results</p></li>
<li><p>Most EEG DL architectures had only 1-3 convolutional layers and included fully-connected layers</p></li>
<li><p>Most work only considered very restricted frequency ranges</p></li>
<li><p>Most studies only compared few design choices and training strategies</p></li>
</ul>
</div>
<p>Prior to 2017, when the first work presented in this thesis was published, there was only limited literature on EEG decoding with deep learning. In this chapter, I outline what decoding problems, input representations, network architectures, hyperparameter choices and visualizations were evaluated in prior work. This is based on the literature research that we presented in <span id="id2">Schirrmeister <em>et al.</em> [<a class="reference internal" href="References.html#id36" title="Robin Tibor Schirrmeister, Jost Tobias Springenberg, Lukas Dominique Josef Fiederer, Martin Glasstetter, Katharina Eggensperger, Michael Tangermann, Frank Hutter, Wolfram Burgard, and Tonio Ball. Deep learning with convolutional neural networks for eeg decoding and visualization. Human Brain Mapping, aug 2017. URL: http://dx.doi.org/10.1002/hbm.23730, doi:10.1002/hbm.23730.">2017</a>]</span>.</p>
<div class="section" id="decoding-problems-and-baselines">
<h2>Decoding Problems and Baselines<a class="headerlink" href="#decoding-problems-and-baselines" title="Permalink to this heading">#</a></h2>
<table class="colwidths-auto table" id="prior-work-tasks-table">
<caption><span class="caption-number">Table 1 </span><span class="caption-text">Decoding problems in deep-learning EEG decoding studies prior to our work. Studies with published baseline compared their decoding results to an external baseline result published by other authors.</span><a class="headerlink" href="#prior-work-tasks-table" title="Permalink to this table">#</a></caption>
<thead>
<tr class="row-odd"><th class="text-left head"><p>Decoding problem</p></th>
<th class="text-left head"><p>Number of studies</p></th>
<th class="text-left head"><p>With published baseline</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p>Imagined or Executed Movement</p></td>
<td class="text-left"><p>6</p></td>
<td class="text-left"><p>2</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>Oddball/P300</p></td>
<td class="text-left"><p>5</p></td>
<td class="text-left"><p>1</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>Epilepsy-related</p></td>
<td class="text-left"><p>4</p></td>
<td class="text-left"><p>2</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>Music Rhythm</p></td>
<td class="text-left"><p>2</p></td>
<td class="text-left"><p>0</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>Memory Performance/Cognitive Load</p></td>
<td class="text-left"><p>2</p></td>
<td class="text-left"><p>0</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>Driver Performance</p></td>
<td class="text-left"><p>1</p></td>
<td class="text-left"><p>0</p></td>
</tr>
</tbody>
</table>
<p>The most widely studied decoding problems were movement-related decoding problems such as decoding which body part (hand, feet etc.) a person is moving or imagining to move (see <a class="reference internal" href="#prior-work-tasks-table"><span class="std std-numref">Table 1</span></a>). From the 19 studies we identified at the time, only 5 compared their decoding results to an external published baseline result, limiting how much one can learn about the deep-learning decoding performance. To advance the understanding of decoding EEG using deep learning, we therefore decided to first focus on those widely researched movement-related decoding tasks and include a comparison to a strong feature-based baseline (see <a class="reference internal" href="FBCSPAndFBCSPNet.html#fbscp-and-filterbank-net"><span class="std std-ref">Filter Bank Common Spatial Patterns and Filterbank Network</span></a>).</p>
</div>
<div class="section" id="input-domains-and-frequency-ranges">
<h2>Input Domains and Frequency Ranges<a class="headerlink" href="#input-domains-and-frequency-ranges" title="Permalink to this heading">#</a></h2>
<div class="cell tag_hide-input tag_remove-output docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">cm</span>
<span class="kn">import</span> <span class="nn">seaborn</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">from</span> <span class="nn">myst_nb</span> <span class="kn">import</span> <span class="n">glue</span>
<span class="n">seaborn</span><span class="o">.</span><span class="n">set_palette</span><span class="p">(</span><span class="s1">&#39;colorblind&#39;</span><span class="p">)</span>
<span class="n">seaborn</span><span class="o">.</span><span class="n">set_style</span><span class="p">(</span><span class="s1">&#39;darkgrid&#39;</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">re</span>

<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="o">%</span><span class="k">config</span> InlineBackend.figure_format = &#39;png&#39;
<span class="c1">#matplotlib.rcParams[&#39;figure.figsize&#39;] = (12.0, 1.0)</span>
<span class="n">matplotlib</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;font.size&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">14</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="s1">&#39;Time,  8–30 Hz &#39;</span><span class="p">,</span> <span class="s1">&#39;Time, 0.1–40 Hz &#39;</span><span class="p">,</span> <span class="s1">&#39;Time, 0.05–15 Hz &#39;</span><span class="p">,</span>
       <span class="s1">&#39;Time, 0.3–20 Hz &#39;</span><span class="p">,</span> <span class="s1">&#39;Frequency, 6–30 Hz &#39;</span><span class="p">,</span> <span class="s1">&#39; Frequency, 0–200 Hz &#39;</span><span class="p">,</span>
       <span class="s1">&#39;Time,  1–50 Hz &#39;</span><span class="p">,</span> <span class="s1">&#39; Time,  0–100 HZ &#39;</span><span class="p">,</span>
       <span class="s1">&#39;Frequency, mean amplitude for 0–7 Hz, 7–14 Hz, 14–49 Hz &#39;</span><span class="p">,</span>
       <span class="s1">&#39;Time, 0.5–50 Hz &#39;</span><span class="p">,</span> <span class="s1">&#39;Time,  0–128 Hz &#39;</span><span class="p">,</span>
       <span class="s1">&#39; Frequency, mean power for 4–7 Hz, 8–13 Hz, 13–30 Hz &#39;</span><span class="p">,</span>
       <span class="s1">&#39;Time, 0.5–30Hz &#39;</span><span class="p">,</span> <span class="s1">&#39;Time, 0.1–50 Hz &#39;</span><span class="p">,</span>
       <span class="s1">&#39;Frequency, 4–40 Hz, using FBCSP &#39;</span><span class="p">,</span>
       <span class="s1">&#39; Time and frequency evaluated, 0-200 Hz &#39;</span><span class="p">,</span> <span class="s1">&#39;Frequency, 8–30 Hz &#39;</span><span class="p">,</span>
       <span class="s1">&#39;Time, 0.15–200 Hz &#39;</span><span class="p">,</span> <span class="s1">&#39; Time, 0.1-20 Hz &#39;</span><span class="p">])</span>
<span class="n">domain_strings</span> <span class="o">=</span> <span class="p">[</span><span class="n">s</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;,&#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">a</span><span class="p">]</span>
<span class="n">start_fs</span> <span class="o">=</span> <span class="p">[</span><span class="nb">float</span><span class="p">(</span><span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;[a-z ]+&#39;</span><span class="p">,</span><span class="sa">r</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">re</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;[–-–-]&#39;</span><span class="p">,</span><span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">s</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;,&#39;</span><span class="p">)[</span><span class="mi">1</span><span class="p">:]))[</span><span class="mi">0</span><span class="p">]))</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">a</span><span class="p">]</span>
<span class="n">end_fs</span> <span class="o">=</span> <span class="p">[</span><span class="nb">float</span><span class="p">(</span><span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;[a-z HZFBCSP]+&#39;</span><span class="p">,</span><span class="sa">r</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">re</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;[–-–-]&#39;</span><span class="p">,</span><span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">s</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;,&#39;</span><span class="p">)[</span><span class="mi">1</span><span class="p">:]))[</span><span class="mi">1</span><span class="p">]))</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">a</span><span class="p">]</span>
<span class="n">domain_strings</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">domain_strings</span><span class="p">)</span>
<span class="n">start_fs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">start_fs</span><span class="p">)</span>
<span class="n">end_fs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">end_fs</span><span class="p">)</span>

<span class="n">freq_mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="s1">&#39;freq&#39;</span> <span class="ow">in</span> <span class="n">s</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">domain_strings</span><span class="p">])</span>
<span class="n">time_mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="s1">&#39;time&#39;</span> <span class="ow">in</span> <span class="n">s</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">domain_strings</span><span class="p">])</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="mi">98349384</span><span class="p">)</span>
<span class="n">color</span> <span class="o">=</span> <span class="n">seaborn</span><span class="o">.</span><span class="n">color_palette</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">i_sort</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">flatnonzero</span><span class="p">(</span><span class="n">time_mask</span><span class="p">)[</span><span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">end_fs</span><span class="p">[</span><span class="n">time_mask</span><span class="p">])]</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">d</span><span class="p">,</span><span class="n">s</span><span class="p">,</span><span class="n">e</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span>
        <span class="n">domain_strings</span><span class="p">[</span><span class="n">i_sort</span><span class="p">],</span> <span class="n">start_fs</span><span class="p">[</span><span class="n">i_sort</span><span class="p">],</span> <span class="n">end_fs</span><span class="p">[</span><span class="n">i_sort</span><span class="p">])):</span>
    <span class="n">offset</span> <span class="o">=</span> <span class="mf">0.6</span><span class="o">*</span><span class="n">i</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">i_sort</span><span class="p">)</span> <span class="o">-</span> <span class="mf">0.3</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">offset</span><span class="p">,</span><span class="n">offset</span><span class="p">]</span> <span class="p">,</span> <span class="p">[</span><span class="n">s</span><span class="p">,</span> <span class="n">e</span><span class="p">],</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s1">&#39;-&#39;</span><span class="p">)</span>
<span class="n">i_sort</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">flatnonzero</span><span class="p">(</span><span class="n">freq_mask</span><span class="p">)[</span><span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">end_fs</span><span class="p">[</span><span class="n">freq_mask</span><span class="p">])]</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">d</span><span class="p">,</span><span class="n">s</span><span class="p">,</span><span class="n">e</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span>
        <span class="n">domain_strings</span><span class="p">[</span><span class="n">i_sort</span><span class="p">],</span> <span class="n">start_fs</span><span class="p">[</span><span class="n">i_sort</span><span class="p">],</span> <span class="n">end_fs</span><span class="p">[</span><span class="n">i_sort</span><span class="p">])):</span>
    <span class="n">offset</span> <span class="o">=</span> <span class="mf">0.6</span><span class="o">*</span><span class="n">i</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">i_sort</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.7</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">offset</span><span class="p">,</span><span class="n">offset</span><span class="p">]</span> <span class="p">,</span> <span class="p">[</span><span class="n">s</span><span class="p">,</span> <span class="n">e</span><span class="p">],</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s1">&#39;-&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="mf">1.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Input domain&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Frequency [Hz]&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;Time&quot;</span><span class="p">,</span> <span class="s2">&quot;Frequency&quot;</span><span class="p">],</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">45</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Input domains and frequency ranges in prior work&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mf">1.05</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">25</span><span class="p">,</span><span class="mi">50</span><span class="p">,</span><span class="mi">75</span><span class="p">,</span><span class="mi">100</span><span class="p">,</span><span class="mi">150</span><span class="p">,</span><span class="mi">200</span><span class="p">])</span>
<span class="n">glue</span><span class="p">(</span><span class="s1">&#39;input_domain_fig&#39;</span><span class="p">,</span> <span class="n">fig</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">(</span><span class="n">fig</span><span class="p">)</span>
<span class="kc">None</span>
</pre></div>
</div>
</div>
</details>
</div>
<div class="figure align-default" id="id29">
<img alt="_images/12b9c75de2ac9fe0306de0abcbc038b8f7372c501526c6e11e7c798b26cfbe44.png" src="_images/12b9c75de2ac9fe0306de0abcbc038b8f7372c501526c6e11e7c798b26cfbe44.png" />
<p class="caption"><span class="caption-number">Fig. 1 </span><span class="caption-text"><em>Input domains and frequency ranges in prior work</em>. Grey lines represent frequency ranges of individual studies. Note that many studies only include frequencies below 50 Hz, some use very restricted ranges (alpha/beta band).</span><a class="headerlink" href="#id29" title="Permalink to this image">#</a></p>
</div>
<p>Deep networks can either decode directly from the time-domain EEG or process the data in the frequency domain, for example after a Fourier transformation. 12 of the prior studies used time-domain inputs, 6 used frequency-domain inputs and one used both. We decided to work directly in the time domain, as the deep networks should in principle be able to learn how to extract any needed spectral information from the time-domain input.</p>
<p>Most prior studies that were working in the time domain only used frequencies below 50 Hz. We were interested in how well deep networks can also extract lesser-used higher-frequency components of the EEG signal. For that, we used a sampling rate of 250 Hz, which means we were able to analyze frequencies up to the Nyquist frequency of 125 Hz. As a suitable dataset where high-frequency information may help decoding, we included our high-gamma dataset in our study, since it was recorded specifically to allow extraction of higher-frequency (&gt;50 Hz) information from scalp EEG <span id="id3">[<a class="reference internal" href="References.html#id36" title="Robin Tibor Schirrmeister, Jost Tobias Springenberg, Lukas Dominique Josef Fiederer, Martin Glasstetter, Katharina Eggensperger, Michael Tangermann, Frank Hutter, Wolfram Burgard, and Tonio Ball. Deep learning with convolutional neural networks for eeg decoding and visualization. Human Brain Mapping, aug 2017. URL: http://dx.doi.org/10.1002/hbm.23730, doi:10.1002/hbm.23730.">Schirrmeister <em>et al.</em>, 2017</a>]</span>.</p>
</div>
<div class="section" id="network-architectures">
<h2>Network Architectures<a class="headerlink" href="#network-architectures" title="Permalink to this heading">#</a></h2>
<div class="cell tag_hide-input tag_remove-output docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ls</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="s1">&#39; 2/2 &#39;</span><span class="p">,</span> <span class="s1">&#39; 3/1 &#39;</span><span class="p">,</span> <span class="s1">&#39; 2/2 &#39;</span><span class="p">,</span> <span class="s1">&#39; 3/2 &#39;</span><span class="p">,</span> <span class="s1">&#39; 1/1 &#39;</span><span class="p">,</span> <span class="s1">&#39; 1/2 &#39;</span><span class="p">,</span> <span class="s1">&#39; 1/3 &#39;</span><span class="p">,</span>
       <span class="s1">&#39; 1–2/2 &#39;</span><span class="p">,</span> <span class="s1">&#39; 3/1 (+ LSTM as postprocessor) &#39;</span><span class="p">,</span> <span class="s1">&#39; 4/3 &#39;</span><span class="p">,</span> <span class="s1">&#39; 1-3/1-3 &#39;</span><span class="p">,</span>
       <span class="s1">&#39; 3–7/2 (+ LSTM or other temporal post-processing (see design choices)) &#39;</span><span class="p">,</span>
       <span class="s1">&#39; 2/1 &#39;</span><span class="p">,</span> <span class="s1">&#39; 3/3 (Spatio-temporal regularization) &#39;</span><span class="p">,</span>
       <span class="s1">&#39; 2/2 (Final fully connected layer uses concatenated output by convolutionaland fully connected layers) &#39;</span><span class="p">,</span>
       <span class="s1">&#39; 1-2/1 &#39;</span><span class="p">,</span>
       <span class="s1">&#39;2/0 (Convolutional deep belief network, separately trained RBF-SVM classifier) &#39;</span><span class="p">,</span>
       <span class="s1">&#39; 3/1 (Convolutional layers trained as convolutional stacked autoencoder with target prior) &#39;</span><span class="p">,</span>
       <span class="s1">&#39; 2/2 &#39;</span><span class="p">])</span>

<span class="n">conv_ls</span> <span class="o">=</span> <span class="p">[</span><span class="n">l</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;/&#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">ls</span><span class="p">]</span>
<span class="n">low_conv_ls</span> <span class="o">=</span> <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">re</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;[–-]&#39;</span><span class="p">,</span> <span class="n">c</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span><span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">conv_ls</span><span class="p">]</span>
<span class="n">high_conv_ls</span> <span class="o">=</span> <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">re</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;[–-]&#39;</span><span class="p">,</span> <span class="n">c</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">conv_ls</span><span class="p">]</span>
<span class="n">dense_ls</span> <span class="o">=</span> <span class="p">[</span><span class="n">l</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;/&#39;</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">ls</span><span class="p">]</span>
<span class="n">low_dense_ls</span> <span class="o">=</span> <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">re</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;[–-]&#39;</span><span class="p">,</span> <span class="n">c</span><span class="p">[:</span><span class="mi">8</span><span class="p">])[</span><span class="mi">0</span><span class="p">][:</span><span class="mi">2</span><span class="p">])</span><span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">dense_ls</span><span class="p">]</span>
<span class="n">high_dense_ls</span> <span class="o">=</span> <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">re</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;[–-]&#39;</span><span class="p">,</span> <span class="n">c</span><span class="p">[:</span><span class="mi">8</span><span class="p">])[</span><span class="o">-</span><span class="mi">1</span><span class="p">][:</span><span class="mi">2</span><span class="p">])</span><span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">dense_ls</span><span class="p">]</span>

<span class="n">all_conv_ls</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">low_c</span><span class="p">,</span> <span class="n">high_c</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">low_c</span><span class="p">,</span> <span class="n">high_c</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">low_conv_ls</span><span class="p">,</span> <span class="n">high_conv_ls</span><span class="p">)])</span>
<span class="n">all_dense_ls</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">low_c</span><span class="p">,</span> <span class="n">high_c</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">low_c</span><span class="p">,</span> <span class="n">high_c</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">low_dense_ls</span><span class="p">,</span> <span class="n">high_dense_ls</span><span class="p">)])</span>
<span class="n">bincount_conv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">bincount</span><span class="p">(</span><span class="n">all_conv_ls</span><span class="p">)</span>
<span class="n">bincount_dense</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">bincount</span><span class="p">(</span><span class="n">all_dense_ls</span><span class="p">)</span>
<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="mi">98349384</span><span class="p">)</span>
<span class="n">color</span> <span class="o">=</span> <span class="n">seaborn</span><span class="o">.</span><span class="n">color_palette</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="k">for</span> <span class="n">low_c</span><span class="p">,</span> <span class="n">high_c</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">low_conv_ls</span><span class="p">,</span> <span class="n">high_conv_ls</span><span class="p">):</span>
    <span class="n">offset</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.1</span>
    <span class="n">tried_cs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">low_c</span><span class="p">,</span> <span class="n">high_c</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">offset</span><span class="p">,]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">tried_cs</span><span class="p">),</span> <span class="n">tried_cs</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s1">&#39;:&#39;</span><span class="p">)</span>
    
<span class="k">for</span> <span class="n">i_c</span><span class="p">,</span> <span class="n">n_c</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">bincount_conv</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">i_c</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="n">n_c</span><span class="o">*</span><span class="mi">40</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">0.535</span><span class="p">,</span> <span class="n">i_c</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">n_c</span><span class="p">)</span><span class="o">+</span> <span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;left&#39;</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">)</span>

<span class="k">for</span> <span class="n">low_c</span><span class="p">,</span> <span class="n">high_c</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">low_dense_ls</span><span class="p">,</span> <span class="n">high_dense_ls</span><span class="p">):</span>
    <span class="n">offset</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">rng</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.1</span>
    <span class="n">tried_cs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">low_c</span><span class="p">,</span> <span class="n">high_c</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">offset</span><span class="p">,]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">tried_cs</span><span class="p">),</span> <span class="n">tried_cs</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s1">&#39;:&#39;</span><span class="p">)</span>
    
<span class="k">for</span> <span class="n">i_c</span><span class="p">,</span> <span class="n">n_c</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">bincount_dense</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="mf">1.4</span><span class="p">,</span> <span class="n">i_c</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="n">n_c</span><span class="o">*</span><span class="mi">40</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">1.535</span><span class="p">,</span> <span class="n">i_c</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">n_c</span><span class="p">)</span><span class="o">+</span> <span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;left&#39;</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Type of layer&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Number of layers&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;Convolutional&quot;</span><span class="p">,</span> <span class="s2">&quot;Dense&quot;</span><span class="p">],</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">45</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">7</span><span class="p">]);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Number of layers in prior works&#39; architectures&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mf">1.05</span><span class="p">)</span>
<span class="n">glue</span><span class="p">(</span><span class="s1">&#39;layernum_fig&#39;</span><span class="p">,</span> <span class="n">fig</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">(</span><span class="n">fig</span><span class="p">)</span>
<span class="kc">None</span>
</pre></div>
</div>
</div>
</details>
</div>
<div class="figure align-default" id="id30">
<img alt="_images/7392f18c25bd31ecf70f575926c0cd4b901396bfe82eebc08ed594903a0475ce.png" src="_images/7392f18c25bd31ecf70f575926c0cd4b901396bfe82eebc08ed594903a0475ce.png" />
<p class="caption"><span class="caption-number">Fig. 2 </span><span class="caption-text"><em>Number of layers in prior work</em>. Small grey markers represent individual architectures. Dashed lines indicate different number of layers investigated in a single study (e.g., a single study investigated 3-7 convolutional layers). Larger grey markers indicate sum of occurences of that layer number over all studies (e.g., 9 architectures used 2 convolutional layers). Note most architectures use only 1-3 convolutional layers.</span><a class="headerlink" href="#id30" title="Permalink to this image">#</a></p>
</div>
<p>The architectures used in prior work typically only included up to 3 layers, with only 2 studies considering more layers. As network architectures in other domains tend to be a lot deeper, we also evaluated architectures with a larger number of layers in our work. Several architectures from prior work also included fully-connected layers with larger number of parameters which had fallen out of favor in computer-vision deep-learning architectures due to their large compute and memory requirements with little accuracy benefit. Our architectures do not include traditional fully-connected layers with a large number of parameters.</p>
</div>
<div class="section" id="hyperparameter-evaluations">
<h2>Hyperparameter Evaluations<a class="headerlink" href="#hyperparameter-evaluations" title="Permalink to this heading">#</a></h2>
<table class="colwidths-auto table" id="prior-work-design-choices-table">
<caption><span class="caption-number">Table 2 </span><span class="caption-text">Design choices and training strategies that prior deep-learning EEG decoding studies had studies.</span><a class="headerlink" href="#prior-work-design-choices-table" title="Permalink to this table">#</a></caption>
<thead>
<tr class="row-odd"><th class="text-left head"><p>Study</p></th>
<th class="text-left head"><p>Design choices</p></th>
<th class="text-left head"><p>Training strategies</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p><span id="id4">[<a class="reference internal" href="References.html#id152" title="Vernon J. Lawhern, Amelia J. Solon, Nicholas R. Waytowich, Stephen M. Gordon, Chou P. Hung, and Brent J. Lance. EEGNet: A Compact Convolutional Network for EEG-based Brain-Computer Interfaces. arXiv:1611.08024 [cs, q-bio, stat], November 2016. arXiv: 1611.08024. URL: http://arxiv.org/abs/1611.08024 (visited on 2016-12-20).">Lawhern <em>et al.</em>, 2016</a>]</span></p></td>
<td class="text-left"><p>Kernel sizes</p></td>
<td class="text-left"><p></p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><span id="id5">[<a class="reference internal" href="References.html#id224" title="Xuyun Sun, Cunle Qian, Zhongqin Chen, Zhaohui Wu, Benyan Luo, and Gang Pan. Remembered or Forgotten?—An EEG-Based Computational Prediction Approach. PLOS ONE, 11(12):e0167497, December 2016. URL: http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0167497 (visited on 2017-02-14), doi:10.1371/journal.pone.0167497.">Sun <em>et al.</em>, 2016</a>]</span></p></td>
<td class="text-left"><p></p></td>
<td class="text-left"><p>Different time windows</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><span id="id6">[<a class="reference internal" href="References.html#id217" title="Yousef Rezaei Tabar and Ugur Halici. A novel deep learning approach for classification of EEG motor imagery signals. Journal of Neural Engineering, 14(1):016003, 2017. URL: http://stacks.iop.org/1741-2552/14/i=1/a=016003 (visited on 2017-02-14), doi:10.1088/1741-2560/14/1/016003.">Tabar and Halici, 2017</a>]</span></p></td>
<td class="text-left"><p>Addition of six-layer stacked autoencoder on ConvNet features <br> Kernel sizes</p></td>
<td class="text-left"><p></p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><span id="id7">[<a class="reference internal" href="References.html#id174" title="J. Liang, R. Lu, C. Zhang, and F. Wang. Predicting Seizures from Electroencephalography Recordings: A Knowledge Transfer Strategy. In 2016 IEEE International Conference on Healthcare Informatics (ICHI), 184–191. October 2016. doi:10.1109/ICHI.2016.27.">Liang <em>et al.</em>, 2016</a>]</span></p></td>
<td class="text-left"><p></p></td>
<td class="text-left"><p>Different subdivisions of frequency range <br>Different lengths of time crops <br>Transfer learning with auxiliary non-epilepsy datasets</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><span id="id8">[<a class="reference internal" href="References.html#id182" title="Mehdi Hajinoroozi, Zijing Mao, Tzyy-Ping Jung, Chin-Teng Lin, and Yufei Huang. EEG-based prediction of driver's cognitive performance by deep convolutional neural network. Signal Processing: Image Communication, 47:549–555, September 2016. URL: http://www.sciencedirect.com/science/article/pii/S0923596516300832 (visited on 2016-12-20), doi:10.1016/j.image.2016.05.018.">Hajinoroozi <em>et al.</em>, 2016</a>]</span></p></td>
<td class="text-left"><p>Replacement of convolutional layers by restricted Boltzmann machines with slightly varied network architecture}</p></td>
<td class="text-left"><p></p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><span id="id9">[<a class="reference internal" href="References.html#id156" title="A. Antoniades, L. Spyrou, C. C. Took, and S. Sanei. Deep learning for epileptic intracranial EEG data. In 2016 IEEE 26th International Workshop on Machine Learning for Signal Processing (MLSP), 1–6. September 2016. doi:10.1109/MLSP.2016.7738824.">Antoniades <em>et al.</em>, 2016</a>]</span></p></td>
<td class="text-left"><p>1 or 2 convolutional layers</p></td>
<td class="text-left"><p></p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><span id="id10">[<a class="reference internal" href="References.html#id206" title="A. Page, C. Shea, and T. Mohsenin. Wearable seizure detection using convolutional neural networks with transfer learning. In 2016 IEEE International Symposium on Circuits and Systems (ISCAS), 1086–1089. May 2016. doi:10.1109/ISCAS.2016.7527433.">Page <em>et al.</em>, 2016</a>]</span></p></td>
<td class="text-left"><p></p></td>
<td class="text-left"><p>Cross-subject supervised training, within-subject finetuning of fully connected layers</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><span id="id11">[<a class="reference internal" href="References.html#id199" title="Pouya Bashivan, Irina Rish, Mohammed Yeasin, and Noel Codella. Learning Representations from EEG with Deep Recurrent-Convolutional Neural Networks. In arXiv:1511.06448 [cs]. 2016. arXiv: 1511.06448. URL: http://arxiv.org/abs/1511.06448 (visited on 2016-12-20).">Bashivan <em>et al.</em>, 2016</a>]</span></p></td>
<td class="text-left"><p>Number of convolutional layers <br>Temporal processing of ConvNet output by max pooling, temporal convolution, LSTM or temporal convolution + LSTM</p></td>
<td class="text-left"><p></p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><span id="id12">[<a class="reference internal" href="References.html#id228" title="Sebastian Stober. Learning Discriminative Features from Electroencephalography Recordings by Encoding Similarity Constraints. In Bernstein Conference 2016. 2016. doi:10.12751/nncn.bc2016.0223.">Stober, 2016</a>]</span></p></td>
<td class="text-left"><p>Kernel sizes</p></td>
<td class="text-left"><p>Pretraining first layer as convolutional autoencoder with different constraints</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><span id="id13">[<a class="reference internal" href="References.html#id119" title="S. Sakhavi, C. Guan, and S. Yan. Parallel convolutional-linear neural network for motor imagery classification. In Signal Processing Conference (EUSIPCO), 2015 23rd European, 2736–2740. August 2015. doi:10.1109/EUSIPCO.2015.7362882.">Sakhavi <em>et al.</em>, 2015</a>]</span></p></td>
<td class="text-left"><p>Combination ConvNet and MLP (trained on different features) vs. only ConvNet vs. only MLP</p></td>
<td class="text-left"><p></p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><span id="id14">[<a class="reference internal" href="References.html#id186" title="Sebastian Stober, Daniel J. Cameron, and Jessica A. Grahn. Using Convolutional Neural Networks to Recognize Rhythm Stimuli from Electroencephalography Recordings. In Proceedings of the 27th International Conference on Neural Information Processing Systems, NIPS'14, 1449–1457. Cambridge, MA, USA, 2014. MIT Press. URL: http://dl.acm.org/citation.cfm?id=2968826.2968988 (visited on 2016-12-20).">Stober <em>et al.</em>, 2014</a>]</span></p></td>
<td class="text-left"><p>Best values from automatic hyperparameter optimization: frequency cutoff, one vs two layers, kernel sizes, number of channels, pooling width</p></td>
<td class="text-left"><p>Best values from automatic hyperparameter optimization: learning rate, learning rate decay, momentum, final momentum</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><span id="id15">[<a class="reference internal" href="References.html#id211" title="Zuoguan Wang, Siwei Lyu, Gerwin Schalk, and Qiang Ji. Deep Feature Learning Using Target Priors with Applications in ECoG Signal Decoding for BCI. In Proceedings of the Twenty-Third International Joint Conference on Artificial Intelligence, IJCAI '13, 1785–1791. Beijing, China, 2013. AAAI Press. URL: http://dl.acm.org/citation.cfm?id=2540128.2540384 (visited on 2017-01-16).">Wang <em>et al.</em>, 2013</a>]</span></p></td>
<td class="text-left"><p>Partially supervised CSA</p></td>
<td class="text-left"><p></p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><span id="id16">[<a class="reference internal" href="References.html#id214" title="Hubert Cecotti and Axel Graser. Convolutional Neural Networks for P300 Detection with Application to Brain-Computer Interfaces. IEEE Transactions on Pattern Analysis and Machine Intelligence, 33(3):433–445, March 2011. URL: http://dx.doi.org/10.1109/TPAMI.2010.125 (visited on 2016-12-20), doi:10.1109/TPAMI.2010.125.">Cecotti and Graser, 2011</a>]</span></p></td>
<td class="text-left"><p>Electrode subset (fixed or automatically determined) <br>Using only one spatial filter <br>Different ensembling strategies</p></td>
<td class="text-left"><p></p></td>
</tr>
</tbody>
</table>
<p>Prior work varied widely in which design choices and training strategies were compared. 6 of the studies did not compare any design choices or  training strategy hyperparameters. The other 13 studies evaluated different hyperparameters, with the most common one the kernel size (see <a class="reference internal" href="#prior-work-design-choices-table"><span class="std std-numref">Table 2</span></a>). Only one study evaluated a wider range of hyperparameters <span id="id17">[<a class="reference internal" href="References.html#id186" title="Sebastian Stober, Daniel J. Cameron, and Jessica A. Grahn. Using Convolutional Neural Networks to Recognize Rhythm Stimuli from Electroencephalography Recordings. In Proceedings of the 27th International Conference on Neural Information Processing Systems, NIPS'14, 1449–1457. Cambridge, MA, USA, 2014. MIT Press. URL: http://dl.acm.org/citation.cfm?id=2968826.2968988 (visited on 2016-12-20).">Stober <em>et al.</em>, 2014</a>]</span>. To fill this gap, we compared a wider range of design choices and training strategies and specifically evaluated in how far improvements of computer vision architecture design choices and training strategies also lead to improvements in EEG decoding.</p>
</div>
<div class="section" id="visualizations">
<h2>Visualizations<a class="headerlink" href="#visualizations" title="Permalink to this heading">#</a></h2>
<table class="colwidths-auto table" id="prior-work-visualizations-table">
<caption><span class="caption-number">Table 3 </span><span class="caption-text">Visualizations presented in prior work.</span><a class="headerlink" href="#prior-work-visualizations-table" title="Permalink to this table">#</a></caption>
<thead>
<tr class="row-odd"><th class="text-left head"><p>Study</p></th>
<th class="text-left head"><p>Visualization type(s)</p></th>
<th class="text-left head"><p>Visualization findings</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p><span id="id18">[<a class="reference internal" href="References.html#id224" title="Xuyun Sun, Cunle Qian, Zhongqin Chen, Zhaohui Wu, Benyan Luo, and Gang Pan. Remembered or Forgotten?—An EEG-Based Computational Prediction Approach. PLOS ONE, 11(12):e0167497, December 2016. URL: http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0167497 (visited on 2017-02-14), doi:10.1371/journal.pone.0167497.">Sun <em>et al.</em>, 2016</a>]</span></p></td>
<td class="text-left"><p>Weights (spatial)</p></td>
<td class="text-left"><p>Largest weights found over prefrontal and temporal cortex</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><span id="id19">[<a class="reference internal" href="References.html#id198" title="Ran Manor, Liran Mishali, and Amir B. Geva. Multimodal Neural Network for Rapid Serial Visual Presentation Brain Computer Interface. Frontiers in Computational Neuroscience, December 2016. URL: http://www.ncbi.nlm.nih.gov/pmc/articles/PMC5168930/ (visited on 2017-02-03), doi:10.3389/fncom.2016.00130.">Manor <em>et al.</em>, 2016</a>]</span></p></td>
<td class="text-left"><p>Weights <br> Activations <br> Saliency maps by gradient</p></td>
<td class="text-left"><p>Weights showed typical P300 distribution <br>Activations were high at plausible times (300-500ms) <br>Saliency maps showed plausible spatio-temporal plots</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><span id="id20">[<a class="reference internal" href="References.html#id217" title="Yousef Rezaei Tabar and Ugur Halici. A novel deep learning approach for classification of EEG motor imagery signals. Journal of Neural Engineering, 14(1):016003, 2017. URL: http://stacks.iop.org/1741-2552/14/i=1/a=016003 (visited on 2017-02-14), doi:10.1088/1741-2560/14/1/016003.">Tabar and Halici, 2017</a>]</span></p></td>
<td class="text-left"><p>Weights (spatial + frequential)</p></td>
<td class="text-left"><p>Some weights represented difference of values of two electrodes on different sides of head</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><span id="id21">[<a class="reference internal" href="References.html#id174" title="J. Liang, R. Lu, C. Zhang, and F. Wang. Predicting Seizures from Electroencephalography Recordings: A Knowledge Transfer Strategy. In 2016 IEEE International Conference on Healthcare Informatics (ICHI), 184–191. October 2016. doi:10.1109/ICHI.2016.27.">Liang <em>et al.</em>, 2016</a>]</span></p></td>
<td class="text-left"><p>Weights <br> Clustering of weights</p></td>
<td class="text-left"><p>Clusters of weights showed typical frequency band subdivision (delta, theta, alpha, beta, gamma)</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><span id="id22">[<a class="reference internal" href="References.html#id156" title="A. Antoniades, L. Spyrou, C. C. Took, and S. Sanei. Deep learning for epileptic intracranial EEG data. In 2016 IEEE 26th International Workshop on Machine Learning for Signal Processing (MLSP), 1–6. September 2016. doi:10.1109/MLSP.2016.7738824.">Antoniades <em>et al.</em>, 2016</a>]</span></p></td>
<td class="text-left"><p>Weights <br>Correlation weights and interictal epileptic discharges (IED) <br>Activations</p></td>
<td class="text-left"><p>Weights increasingly correlated with IED waveforms with increasing number of training iterations <br>Second layer captured more complex and well-defined epileptic shapes than first layer <br>IEDs led to highly synchronized activations for neighbouring electrodes</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><span id="id23">[<a class="reference internal" href="References.html#id184" title="Pierre Thodoroff, Joelle Pineau, and Andrew Lim. Learning Robust Features using Deep Learning for Automatic Seizure Detection. In JMLR Workshop and Conference Proceedings, volume 56. 2016. URL: http://www.jmlr.org/proceedings/papers/v56/Thodoroff16.pdf (visited on 2017-02-14).">Thodoroff <em>et al.</em>, 2016</a>]</span></p></td>
<td class="text-left"><p>Input occlusion and effect on prediction accuracy</p></td>
<td class="text-left"><p>Allowed to locate areas critical for seizure</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><span id="id24">[<a class="reference internal" href="References.html#id202" title="Jared Shamwell, Hyungtae Lee, Heesung Kwon, Amar R. Marathe, Vernon Lawhern, and William Nothwang. Single-trial EEG RSVP classification using convolutional neural networks. In Thomas George, Achyut K. Dutta, and M. Saif Islam, editors, SPIE Defense+ Security, volume 9836. International Society for Optics and Photonics, May 2016. URL: http://proceedings.spiedigitallibrary.org/proceeding.aspx?doi=10.1117/12.2224172 (visited on 2017-02-14), doi:10.1117/12.2224172.">Shamwell <em>et al.</em>, 2016</a>]</span></p></td>
<td class="text-left"><p>Weights (spatial)</p></td>
<td class="text-left"><p>Some filter weights had expected topographic distributions for P300 <br>Others filters had large weights on areas not traditionally associated with P300</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><span id="id25">[<a class="reference internal" href="References.html#id199" title="Pouya Bashivan, Irina Rish, Mohammed Yeasin, and Noel Codella. Learning Representations from EEG with Deep Recurrent-Convolutional Neural Networks. In arXiv:1511.06448 [cs]. 2016. arXiv: 1511.06448. URL: http://arxiv.org/abs/1511.06448 (visited on 2016-12-20).">Bashivan <em>et al.</em>, 2016</a>]</span></p></td>
<td class="text-left"><p>Inputs that maximally activate given filter <br>Activations of these inputs <br>”Deconvolution” for these inputs</p></td>
<td class="text-left"><p>Different filters were sensitive to different frequency bands <br>Later layers had more spatially localized activations <br>Learned features had noticeable links to well-known electrophysiological markers of cognitive load <br></p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><span id="id26">[<a class="reference internal" href="References.html#id228" title="Sebastian Stober. Learning Discriminative Features from Electroencephalography Recordings by Encoding Similarity Constraints. In Bernstein Conference 2016. 2016. doi:10.12751/nncn.bc2016.0223.">Stober, 2016</a>]</span></p></td>
<td class="text-left"><p>Weights (spatial+3 timesteps, pretrained as autoencoder)</p></td>
<td class="text-left"><p>Different constraints led to different weights, one type of constraints could enforce weights that are similar across subjects; other type of constraints led to weights that have similar spatial topographies under different architectural configurations and preprocessings</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><span id="id27">[<a class="reference internal" href="References.html#id149" title="Ran Manor and Amir B. Geva. Convolutional Neural Network for Multi-Category Rapid Serial Visual Presentation BCI. Frontiers in Computational Neuroscience, 9:146, 2015. doi:10.3389/fncom.2015.00146.">Manor and Geva, 2015</a>]</span></p></td>
<td class="text-left"><p>Weights <br> Mean and single-trial activations</p></td>
<td class="text-left"><p>Spatiotemporal regularization led to softer peaks in weights <br>Spatial weights showed typical P300 distribution <br>Activations mostly had peaks at typical times (300-400ms)</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><span id="id28">[<a class="reference internal" href="References.html#id214" title="Hubert Cecotti and Axel Graser. Convolutional Neural Networks for P300 Detection with Application to Brain-Computer Interfaces. IEEE Transactions on Pattern Analysis and Machine Intelligence, 33(3):433–445, March 2011. URL: http://dx.doi.org/10.1109/TPAMI.2010.125 (visited on 2016-12-20), doi:10.1109/TPAMI.2010.125.">Cecotti and Graser, 2011</a>]</span></p></td>
<td class="text-left"><p>Weights</p></td>
<td class="text-left"><p>Spatial filters were similar for different architectures <br>Spatial filters were different (more focal, more diffuse) for different subjects</p></td>
</tr>
</tbody>
</table>
<p>Visualizations can help understand what information the networks are extracting from the EEG signal. 11 of the prior 19 studies presented any visualizations. These studies mostly focused on analyzing weights and activations, see <a class="reference internal" href="#prior-work-visualizations-table"><span class="std std-numref">Table 3</span></a>. In our work, we first focused on investigating how far the networks extract spectral features known to work well for movement-related decoding, see <a class="reference internal" href="PerturbationVisualization.html#perturbation-visualization"><span class="std std-ref">Perturbation Visualization</span></a>. Later, we also developed more sophisticated visualization methods and applied them both to movement-related decoding as well as to pathology decoding, see <a class="reference internal" href="Invertible.html#invertible-networks"><span class="std std-ref">Invertible Networks</span></a>.</p>
<div class="tip admonition">
<p class="admonition-title">Open Questions</p>
<ul class="simple">
<li><p>How do ConvNets perform on well-researched EEG movement-related decoding tasks against strong feature-based baselines?</p></li>
<li><p>How do shallower and deeper architectures compare?</p></li>
<li><p>How do design choices and training strategies affect the decoding performance?</p></li>
<li><p>What features do the deep networks learn to extract from the EEG signals?</p></li>
<li><p>Do they learn to use higher-frequency (&gt;50 Hz) information?</p></li>
</ul>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="Introduction.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Introduction</p>
      </div>
    </a>
    <a class="right-next"
       href="FBCSPAndFBCSPNet.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Filter Bank Common Spatial Patterns and Filterbank Network</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#decoding-problems-and-baselines">Decoding Problems and Baselines</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#input-domains-and-frequency-ranges">Input Domains and Frequency Ranges</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#network-architectures">Network Architectures</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hyperparameter-evaluations">Hyperparameter Evaluations</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#visualizations">Visualizations</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By The Jupyter Book community
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>