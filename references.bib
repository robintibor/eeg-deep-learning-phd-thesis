


@article{albert_automatic_2016,
	series = {Knowledge-{Based} and {Intelligent} {Information} \& {Engineering} {Systems}: {Proceedings} of the 20th {International} {Conference} {KES}-2016},
	title = {Automatic {EEG} {Processing} for the {Early} {Diagnosis} of {Traumatic} {Brain} {Injury}},
	volume = {96},
	issn = {1877-0509},
	url = {http://www.sciencedirect.com/science/article/pii/S1877050916320646},
	doi = {10.1016/j.procs.2016.08.253},
	abstract = {Traumatic Brain Injury (TBI) is recognized as an important cause of death and disabilities after an accident. The availability a tool for the early diagnosis of brain dysfunctions could greatly improve the quality of life of people affected by TBI and even prevent deaths. The contribution of the paper is a process including several methods for the automatic processing of electroencephalography (EEG) data, in order to provide a fast and reliable diagnosis of TBI. Integrated in a portable decision support system called EmerEEG, the TBI diagnosis is obtained using discriminant analysis based on quantitative EEG (qEEG) features extracted from data recordings after the automatic removal of artifacts. The proposed algorithm computes the TBI diagnosis on the basis of a model extracted from clinically-labelled EEG records. The system evaluations have confirmed the speed and reliability of the processing algorithms as well as the system's ability to deliver accurate diagnosis. The developed algorithms have achieved 79.1\% accuracy in removing artifacts, and 87.85\% accuracy in TBI diagnosis. Therefore, the developed system enables a short response time in emergency situations and provides a tool the emergency services could base their decision upon, thus preventing possibly miss-diagnosed injuries.},
	urldate = {2017-08-25},
	journal = {Procedia Computer Science},
	author = {Albert, Bruno and Zhang, Jingjing and Noyvirt, Alexandre and Setchi, Rossitza and Sjaaheim, Haldor and Velikova, Svetla and Strisland, Frode},
	month = jan,
	year = {2016},
	keywords = {Artifact removal, Diagnosis, electroencephalography (EEG), Portable Medical System, Traumatic Brain Injury (TBI)},
	pages = {703--712}
}

@inproceedings{cai_pervasive_2016,
	title = {Pervasive {EEG} diagnosis of depression using {Deep} {Belief} {Network} with three-electrodes {EEG} collector},
	doi = {10.1109/BIBM.2016.7822696},
	abstract = {According to the World Health Organization, it is predicted that in 2020, depression will become the second largest illness threatening the health of mankind. In order to alleviate the worldwide damage caused by depression, a portable and accurate diagnosing technique is the most essential. This research uses three-electrode pervasive EEG collector to collect EEG data from Fp1, Fp2, and Fpz as locations of scalp electrodes, since these locations are closely related to emotions, and uncovered by hair. Special designed experiment has been conducted and totally 178 subjects' EEG data have been collected. Then the research uses KNN (k-Nearest Neighbor), SVM (Support Vector Machine), ANN (Artificial Neuro Network) and DBN (Deep Belief Network) to analyze the data. The results show DBN performed better than traditional methods using shallow algorithms. Moreover, the results suggested the absolute power of beta wave is a valid characteristic, which could be used for detection of depression. The accuracy reached 78.24\% using the combination of DBN and the absolute power of beta wave. This research proves the feasibility of smaller-size pervasive system for depression diagnosis.},
	booktitle = {2016 {IEEE} {International} {Conference} on {Bioinformatics} and {Biomedicine} ({BIBM})},
	author = {Cai, Hanshu and Sha, Xiaocong and Han, Xue and Wei, Shixin and Hu, Bin},
	month = dec,
	year = {2016},
	keywords = {accurate diagnosing technique, ANN, artificial neural networks, belief networks, bioelectric potentials, Biomedical electrodes, DBN, deep belief network, depression detection, depression diagnosis, EEG, EEG data, Electrodes, electroencephalography, emotion, hair, illness, Integrated circuits, k-nearest neighbor, medical signal detection, neural nets, pervasive EEG depression diagnosis, pervasive system, portable diagnosing technique, psychology, scalp electrode location, Support vector machine, Support vector machines, SVM, three-electrode pervasive EEG collector},
	pages = {1239--1246}
}

@article{hosseinifard_classifying_2013,
	title = {Classifying depression patients and normal subjects using machine learning techniques and nonlinear features from {EEG} signal},
	volume = {109},
	issn = {1872-7565},
	doi = {10.1016/j.cmpb.2012.10.008},
	abstract = {Diagnosing depression in the early curable stages is very important and may even save the life of a patient. In this paper, we study nonlinear analysis of EEG signal for discriminating depression patients and normal controls. Forty-five unmedicated depressed patients and 45 normal subjects were participated in this study. Power of four EEG bands and four nonlinear features including detrended fluctuation analysis (DFA), higuchi fractal, correlation dimension and lyapunov exponent were extracted from EEG signal. For discriminating the two groups, k-nearest neighbor, linear discriminant analysis and logistic regression as the classifiers are then used. Highest classification accuracy of 83.3\% is obtained by correlation dimension and LR classifier among other nonlinear features. For further improvement, all nonlinear features are combined and applied to classifiers. A classification accuracy of 90\% is achieved by all nonlinear features and LR classifier. In all experiments, genetic algorithm is employed to select the most important features. The proposed technique is compared and contrasted with the other reported methods and it is demonstrated that by combining nonlinear features, the performance is enhanced. This study shows that nonlinear analysis of EEG can be a useful method for discriminating depressed patients and normal subjects. It is suggested that this analysis may be a complementary tool to help psychiatrists for diagnosing depressed patients.},
	language = {eng},
	number = {3},
	journal = {Computer Methods and Programs in Biomedicine},
	author = {Hosseinifard, Behshad and Moradi, Mohammad Hassan and Rostami, Reza},
	month = mar,
	year = {2013},
	pmid = {23122719},
	keywords = {Adult, Algorithms, Artificial Intelligence, Brain Mapping, Computer Simulation, Depression, Discriminant analysis, electroencephalography, Female, Fractals, Humans, Least-Squares Analysis, Logistic Models, Male, Middle Aged, Models, Statistical, Reproducibility of Results, Signal Processing, Computer-Assisted, Software},
	pages = {339--345}
}

@article{lehmann_application_2007,
	title = {Application and comparison of classification algorithms for recognition of {Alzheimer}'s disease in electrical brain activity ({EEG})},
	volume = {161},
	issn = {0165-0270},
	url = {http://www.sciencedirect.com/science/article/pii/S0165027006005425},
	doi = {10.1016/j.jneumeth.2006.10.023},
	abstract = {The early detection of subjects with probable Alzheimer's disease (AD) is crucial for effective appliance of treatment strategies. Here we explored the ability of a multitude of linear and non-linear classification algorithms to discriminate between the electroencephalograms (EEGs) of patients with varying degree of AD and their age-matched control subjects. Absolute and relative spectral power, distribution of spectral power, and measures of spatial synchronization were calculated from recordings of resting eyes-closed continuous EEGs of 45 healthy controls, 116 patients with mild AD and 81 patients with moderate AD, recruited in two different centers (Stockholm, New York). The applied classification algorithms were: principal component linear discriminant analysis (PC LDA), partial least squares LDA (PLS LDA), principal component logistic regression (PC LR), partial least squares logistic regression (PLS LR), bagging, random forest, support vector machines (SVM) and feed-forward neural network. Based on 10-fold cross-validation runs it could be demonstrated that even tough modern computer-intensive classification algorithms such as random forests, SVM and neural networks show a slight superiority, more classical classification algorithms performed nearly equally well. Using random forests classification a considerable sensitivity of up to 85\% and a specificity of 78\%, respectively for the test of even only mild AD patients has been reached, whereas for the comparison of moderate AD vs. controls, using SVM and neural networks, values of 89\% and 88\% for sensitivity and specificity were achieved. Such a remarkable performance proves the value of these classification algorithms for clinical diagnostics.},
	number = {2},
	urldate = {2017-08-25},
	journal = {Journal of Neuroscience Methods},
	author = {Lehmann, Christoph and Koenig, Thomas and Jelic, Vesna and Prichep, Leslie and John, Roy E. and Wahlund, Lars-Olof and Dodge, Yadolah and Dierks, Thomas},
	month = apr,
	year = {2007},
	keywords = {Alzheimer's disease, Classification, EEG, Multivariate statistics},
	pages = {342--350}
}

@article{giri_ischemic_2016,
	title = {Ischemic {Stroke} {Identification} {Based} on {EEG} and {EOG} using 1D {Convolutional} {Neural} {Network} and {Batch} {Normalization}},
	url = {http://arxiv.org/abs/1610.01757},
	abstract = {In 2015, stroke was the number one cause of death in Indonesia. The majority type of stroke is ischemic. The standard tool for diagnosing stroke is CT-Scan. For developing countries like Indonesia, the availability of CT-Scan is very limited and still relatively expensive. Because of the availability, another device that potential to diagnose stroke in Indonesia is EEG. Ischemic stroke occurs because of obstruction that can make the cerebral blood flow (CBF) on a person with stroke has become lower than CBF on a normal person (control) so that the EEG signal have a deceleration. On this study, we perform the ability of 1D Convolutional Neural Network (1DCNN) to construct classification model that can distinguish the EEG and EOG stroke data from EEG and EOG control data. To accelerate training process our model we use Batch Normalization. Involving 62 person data object and from leave one out the scenario with five times repetition of measurement we obtain the average of accuracy 0.86 (F-Score 0.861) only at 200 epoch. This result is better than all over shallow and popular classifiers as the comparator (the best result of accuracy 0.69 and F-Score 0.72 ). The feature used in our study were only 24 handcrafted feature with simple feature extraction process.},
	urldate = {2017-08-25},
	journal = {arXiv:1610.01757 [cs]},
	author = {Giri, Endang Purnama and Fanany, Mohamad Ivan and Arymurthy, Aniati Murni},
	month = oct,
	year = {2016},
	note = {arXiv: 1610.01757},
	keywords = {Computer Science - Learning, Computer Science - Neural and Evolutionary Computing},
	annote = {Comment: 13 pages. To be published in ICACSIS 2016}
}


@article{miotto_deep_2017,
	title = {Deep learning for healthcare: review, opportunities and challenges},
	issn = {1477-4054},
	shorttitle = {Deep learning for healthcare},
	doi = {10.1093/bib/bbx044},
	abstract = {Gaining knowledge and actionable insights from complex, high-dimensional and heterogeneous biomedical data remains a key challenge in transforming health care. Various types of data have been emerging in modern biomedical research, including electronic health records, imaging, -omics, sensor data and text, which are complex, heterogeneous, poorly annotated and generally unstructured. Traditional data mining and statistical learning approaches typically need to first perform feature engineering to obtain effective and more robust features from those data, and then build prediction or clustering models on top of them. There are lots of challenges on both steps in a scenario of complicated data and lacking of sufficient domain knowledge. The latest advances in deep learning technologies provide new effective paradigms to obtain end-to-end learning models from complex data. In this article, we review the recent literature on applying deep learning technologies to advance the health care domain. Based on the analyzed work, we suggest that deep learning approaches could be the vehicle for translating big biomedical data into improved human health. However, we also note limitations and needs for improved methods development and applications, especially in terms of ease-of-understanding for domain experts and citizen scientists. We discuss such challenges and suggest developing holistic and meaningful interpretable architectures to bridge deep learning models and human interpretability.},
	language = {eng},
	journal = {Briefings in Bioinformatics},
	author = {Miotto, Riccardo and Wang, Fei and Wang, Shuang and Jiang, Xiaoqian and Dudley, Joel T.},
	month = may,
	year = {2017},
	pmid = {28481991},
	keywords = {Biomedical informatics, deep learning, electronic health records, genomics, health care, translational bioinformatics}
}

@article{esteva_dermatologist-level_2017,
	title = {Dermatologist-level classification of skin cancer with deep neural networks},
	volume = {542},
	copyright = {© 2017 Macmillan Publishers Limited, part of Springer Nature. All rights reserved.},
	issn = {0028-0836},
	url = {http://www.nature.com/nature/journal/v542/n7639/full/nature21056.html?foxtrotcallback=true},
	doi = {10.1038/nature21056},
	abstract = {Skin cancer, the most common human malignancy, is primarily diagnosed visually, beginning with an initial clinical screening and followed potentially by dermoscopic analysis, a biopsy and histopathological examination. Automated classification of skin lesions using images is a challenging task owing to the fine-grained variability in the appearance of skin lesions. Deep convolutional neural networks (CNNs) show potential for general and highly variable tasks across many fine-grained object categories. Here we demonstrate classification of skin lesions using a single CNN, trained end-to-end from images directly, using only pixels and disease labels as inputs. We train a CNN using a dataset of 129,450 clinical images—two orders of magnitude larger than previous datasets—consisting of 2,032 different diseases. We test its performance against 21 board-certified dermatologists on biopsy-proven clinical images with two critical binary classification use cases: keratinocyte carcinomas versus benign seborrheic keratoses; and malignant melanomas versus benign nevi. The first case represents the identification of the most common cancers, the second represents the identification of the deadliest skin cancer. The CNN achieves performance on par with all tested experts across both tasks, demonstrating an artificial intelligence capable of classifying skin cancer with a level of competence comparable to dermatologists. Outfitted with deep neural networks, mobile devices can potentially extend the reach of dermatologists outside of the clinic. It is projected that 6.3 billion smartphone subscriptions will exist by the year 2021 (ref. 13) and can therefore potentially provide low-cost universal access to vital diagnostic care.},
	language = {en},
	number = {7639},
	urldate = {2017-08-26},
	journal = {Nature},
	author = {Esteva, Andre and Kuprel, Brett and Novoa, Roberto A. and Ko, Justin and Swetter, Susan M. and Blau, Helen M. and Thrun, Sebastian},
	month = feb,
	year = {2017},
	keywords = {Diagnosis, machine learning, Skin cancer},
	pages = {115--118},
	file = {Full Text PDF:/home/robintibor/firefox-portable/profilordner/zotero/storage/UE7PTB96/Esteva et al. - 2017 - Dermatologist-level classification of skin cancer .pdf:application/pdf;Snapshot:/home/robintibor/firefox-portable/profilordner/zotero/storage/HDZ7NV7X/nature21056.html:text/html}
}

@inproceedings{maninis_deep_2016,
	title = {Deep {Retinal} {Image} {Understanding}},
	booktitle = {Medical {Image} {Computing} and {Computer}-{Assisted} {Intervention} ({MICCAI})},
	author = {Maninis, K. K. and Pont-Tuset, J. and Arbeláez, P. and Gool, L. Van},
	year = {2016}
}


@inproceedings{hutter_sequential_2011,
	title = {Sequential {Model}-{Based} {Optimization} for {General} {Algorithm} {Configuration}},
	booktitle = {Proceedings of the conference on {Learning} and {Intelligent} {OptimizatioN} ({LION} 5)},
	author = {Hutter, F. and Hoos, H. H. and Leyton-Brown, K.},
	month = jan,
	year = {2011},
	pages = {507--523}
}

@article{montavon_methods_2017,
	title = {Methods for {Interpreting} and {Understanding} {Deep} {Neural} {Networks}},
	volume = {abs/1706.07979},
	url = {http://arxiv.org/abs/1706.07979},
	journal = {CoRR},
	author = {Montavon, Grégoire and Samek, Wojciech and Müller, Klaus-Robert},
	year = {2017}
}

@article{kindermans_patternnet_2017,
	title = {{PatternNet} and {PatternLRP} - {Improving} the interpretability of neural networks},
	volume = {abs/1705.05598},
	url = {http://arxiv.org/abs/1705.05598},
	journal = {CoRR},
	author = {Kindermans, Pieter-Jan and Schütt, Kristof T. and Alber, Maximilian and Müller, Klaus-Robert and Dähne, Sven},
	year = {2017}
}

@article{zoph_learning_2017,
	title = {Learning {Transferable} {Architectures} for {Scalable} {Image} {Recognition}},
	url = {http://arxiv.org/abs/1707.07012},
	abstract = {Developing state-of-the-art image classification models often requires significant architecture engineering and tuning. In this paper, we attempt to reduce the amount of architecture engineering by using Neural Architecture Search to learn an architectural building block on a small dataset that can be transferred to a large dataset. This approach is similar to learning the structure of a recurrent cell within a recurrent network. In our experiments, we search for the best convolutional cell on the CIFAR-10 dataset and then apply this learned cell to the ImageNet dataset by stacking together more of this cell. Although the cell is not learned directly on ImageNet, an architecture constructed from the best learned cell achieves state-of-the-art accuracy of 82.3\% top-1 and 96.0\% top-5 on ImageNet, which is 0.8\% better in top-1 accuracy than the best human-invented architectures while having 9 billion fewer FLOPS. This cell can also be scaled down two orders of magnitude: a smaller network constructed from the best cell also achieves 74\% top-1 accuracy, which is 3.1\% better than the equivalently-sized, state-of-the-art models for mobile platforms.},
	urldate = {2017-08-26},
	journal = {arXiv:1707.07012 [cs]},
	author = {Zoph, Barret and Vasudevan, Vijay and Shlens, Jonathon and Le, Quoc V.},
	month = jul,
	year = {2017},
	note = {arXiv: 1707.07012},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv\:1707.07012 PDF:/home/robintibor/firefox-portable/profilordner/zotero/storage/Q6W6TZ9B/Zoph et al. - 2017 - Learning Transferable Architectures for Scalable I.pdf:application/pdf;arXiv.org Snapshot:/home/robintibor/firefox-portable/profilordner/zotero/storage/USMXKMKT/1707.html:text/html}
}

@article{zoph_neural_2016,
	title = {Neural {Architecture} {Search} with {Reinforcement} {Learning}},
	url = {http://arxiv.org/abs/1611.01578},
	abstract = {Neural networks are powerful and flexible models that work well for many difficult learning tasks in image, speech and natural language understanding. Despite their success, neural networks are still hard to design. In this paper, we use a recurrent network to generate the model descriptions of neural networks and train this RNN with reinforcement learning to maximize the expected accuracy of the generated architectures on a validation set. On the CIFAR-10 dataset, our method, starting from scratch, can design a novel network architecture that rivals the best human-invented architecture in terms of test set accuracy. Our CIFAR-10 model achieves a test error rate of 3.65, which is 0.09 percent better and 1.05x faster than the previous state-of-the-art model that used a similar architectural scheme. On the Penn Treebank dataset, our model can compose a novel recurrent cell that outperforms the widely-used LSTM cell, and other state-of-the-art baselines. Our cell achieves a test set perplexity of 62.4 on the Penn Treebank, which is 3.6 perplexity better than the previous state-of-the-art model. The cell can also be transferred to the character language modeling task on PTB and achieves a state-of-the-art perplexity of 1.214.},
	urldate = {2017-08-26},
	journal = {arXiv:1611.01578 [cs]},
	author = {Zoph, Barret and Le, Quoc V.},
	month = nov,
	year = {2016},
	note = {arXiv: 1611.01578},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Learning, Computer Science - Neural and Evolutionary Computing},
	file = {arXiv\:1611.01578 PDF:/home/robintibor/firefox-portable/profilordner/zotero/storage/CZVGINKB/Zoph and Le - 2016 - Neural Architecture Search with Reinforcement Lear.pdf:application/pdf;arXiv.org Snapshot:/home/robintibor/firefox-portable/profilordner/zotero/storage/PQX6DMR4/1611.html:text/html}
}

@article{miikkulainen_evolving_2017,
	title = {Evolving {Deep} {Neural} {Networks}},
	url = {http://arxiv.org/abs/1703.00548},
	abstract = {The success of deep learning depends on finding an architecture to fit the task. As deep learning has scaled up to more challenging tasks, the architectures have become difficult to design by hand. This paper proposes an automated method, CoDeepNEAT, for optimizing deep learning architectures through evolution. By extending existing neuroevolution methods to topology, components, and hyperparameters, this method achieves results comparable to best human designs in standard benchmarks in object recognition and language modeling. It also supports building a real-world application of automated image captioning on a magazine website. Given the anticipated increases in available computing power, evolution of deep networks is promising approach to constructing deep learning applications in the future.},
	urldate = {2017-08-26},
	journal = {arXiv:1703.00548 [cs]},
	author = {Miikkulainen, Risto and Liang, Jason and Meyerson, Elliot and Rawal, Aditya and Fink, Dan and Francon, Olivier and Raju, Bala and Shahrzad, Hormoz and Navruzyan, Arshak and Duffy, Nigel and Hodjat, Babak},
	month = mar,
	year = {2017},
	note = {arXiv: 1703.00548},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Neural and Evolutionary Computing},
	file = {arXiv\:1703.00548 PDF:/home/robintibor/firefox-portable/profilordner/zotero/storage/CTH2ZZPM/Miikkulainen et al. - 2017 - Evolving Deep Neural Networks.pdf:application/pdf;arXiv.org Snapshot:/home/robintibor/firefox-portable/profilordner/zotero/storage/R7ABKSPI/1703.html:text/html}
}

@article{real_large-scale_2017,
	title = {Large-{Scale} {Evolution} of {Image} {Classifiers}},
	url = {http://arxiv.org/abs/1703.01041},
	abstract = {Neural networks have proven effective at solving difficult problems but designing their architectures can be challenging, even for image classification problems alone. Our goal is to minimize human participation, so we employ evolutionary algorithms to discover such networks automatically. Despite significant computational requirements, we show that it is now possible to evolve models with accuracies within the range of those published in the last year. Specifically, we employ simple evolutionary techniques at unprecedented scales to discover models for the CIFAR-10 and CIFAR-100 datasets, starting from trivial initial conditions and reaching accuracies of 94.6\% (95.6\% for ensemble) and 77.0\%, respectively. To do this, we use novel and intuitive mutation operators that navigate large search spaces; we stress that no human participation is required once evolution starts and that the output is a fully-trained model. Throughout this work, we place special emphasis on the repeatability of results, the variability in the outcomes and the computational requirements.},
	urldate = {2017-08-26},
	journal = {arXiv:1703.01041 [cs]},
	author = {Real, Esteban and Moore, Sherry and Selle, Andrew and Saxena, Saurabh and Suematsu, Yutaka Leon and Tan, Jie and Le, Quoc and Kurakin, Alex},
	month = mar,
	year = {2017},
	note = {arXiv: 1703.01041},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Distributed, Parallel, and Cluster Computing, Computer Science - Neural and Evolutionary Computing, I.2.6, I.5.1, I.5.2},
	annote = {Comment: Accepted for publication at ICML 2017 (34th International Conference on Machine Learning)},
	file = {arXiv\:1703.01041 PDF:/home/robintibor/firefox-portable/profilordner/zotero/storage/HQVE52MI/Real et al. - 2017 - Large-Scale Evolution of Image Classifiers.pdf:application/pdf;arXiv.org Snapshot:/home/robintibor/firefox-portable/profilordner/zotero/storage/BIWIJKGP/1703.html:text/html}
}

@inproceedings{mendoza_towards_2016,
	title = {Towards {Automatically}-{Tuned} {Neural} {Networks}},
	booktitle = {{ICML} 2016 {AutoML} {Workshop}},
	author = {Mendoza, H. and Klein, A. and Feurer, M. and Springenberg, J. and Hutter, F.},
	month = jun,
	year = {2016}
}

@article{mirza_conditional_2014,
	title = {Conditional generative adversarial nets},
	journal = {arXiv preprint arXiv:1411.1784},
	author = {Mirza, Mehdi and Osindero, Simon},
	year = {2014}
}

@article{radford_unsupervised_2015,
	title = {Unsupervised representation learning with deep convolutional generative adversarial networks},
	journal = {arXiv preprint arXiv:1511.06434},
	author = {Radford, Alec and Metz, Luke and Chintala, Soumith},
	year = {2015}
}

@article{springenberg_unsupervised_2015,
	title = {Unsupervised and semi-supervised learning with categorical generative adversarial networks},
	journal = {arXiv preprint arXiv:1511.06390},
	author = {Springenberg, Jost Tobias},
	year = {2015}
}

@mastersthesis{abnormalLopez,
  author       = {Lopez de Diego, S.}, 
  title        = {Automated interpretation of abnormal adult electroencephalography},
  school       = {Temple University},
  year         = 2017,
}

@INPROCEEDINGS{schirrmeisterdeeppathology,
author={Schirrmeister, R. and Gemein, L. and Eggensperger, K. and Hutter, F. and Ball, T.},
booktitle={2017 IEEE Signal Processing in Medicine and Biology Symposium (SPMB)},   title={Deep learning with convolutional neural networks for decoding and visualization of EEG pathology},
year={2017},
volume={},
number={},
pages={1-7},
doi={10.1109/SPMB.2017.8257015}}


@ARTICLE{obeid_temple_2016,
AUTHOR={Obeid, Iyad and Picone, Joseph},   
TITLE={The Temple University Hospital EEG Data Corpus},
JOURNAL={Frontiers in Neuroscience},   
VOLUME={10},    
YEAR={2016},
URL={https://www.frontiersin.org/articles/10.3389/fnins.2016.00196},
DOI={10.3389/fnins.2016.00196},
ISSN={1662-453X}   
}

@article{Rau:2015uk,
author = {V. Rau},
journal = {Bachelor's Thesis, University of Freiburg, DOI},
title = {EEG Correlates of Inner Speech},
year = {2015},
unidentified = {/UNIFR/15003},
}



@article {schirrmeisterdeephbm2017,
author = {Schirrmeister, Robin Tibor and Springenberg, Jost Tobias and Fiederer,
  Lukas Dominique Josef and Glasstetter, Martin and Eggensperger, Katharina and Tangermann, Michael and
  Hutter, Frank and Burgard, Wolfram and Ball, Tonio},
title = {Deep learning with convolutional neural networks for EEG decoding and visualization},
journal = {Human Brain Mapping},
issn = {1097-0193},
url = {http://dx.doi.org/10.1002/hbm.23730},
doi = {10.1002/hbm.23730},
month = {aug},
year = {2017},
keywords = {electroencephalography, EEG analysis, machine learning, end-to-end learning, brain–machine interface,
  brain–computer interface, model interpretability, brain mapping},
}

@inproceedings{heilmeyer2018large,
  title={A large-scale evaluation framework for EEG deep learning architectures},
  author={Heilmeyer, Felix A and Schirrmeister, Robin T and Fiederer, Lukas DJ and Volker, Martin and Behncke, Joos and Ball, Tonio},
  booktitle={2018 IEEE International Conference on Systems, Man, and Cybernetics (SMC)},
  pages={1039--1045},
  year={2018},
  organization={IEEE}
}


@INPROCEEDINGS{wangsheep,

  author={Wang, X. and Gkogkidis, C. A. and Schirrmeister, R. T. and Heilmeyer, F. A. and Gierthmuehlen, M. and Kohler, F. and Schuettler, M. and Stieglitz, T. and Ball, T.},

  booktitle={2018 IEEE-EMBS Conference on Biomedical Engineering and Sciences (IECBES)}, 

  title={Deep Learning for micro-Electrocorticographic (µECoG) Data}, 

  year={2018},

  volume={},

  number={},

  pages={63-68},

  doi={10.1109/IECBES.2018.8626607}}


@inproceedings{behncke2018cross,
  title={Cross-paradigm pretraining of convolutional networks improves intracranial EEG decoding},
  author={Behncke, Joos and Schirrmeister, Robin Tibor and Volker, Martin and Hammer, Jiri and Marusic, Petr and Schulze-Bonhage, Andreas and Burgard, Wolfram and Ball, Tonio},
  booktitle={2018 IEEE International Conference on Systems, Man, and Cybernetics (SMC)},
  pages={1046--1053},
  year={2018},
  organization={IEEE}
}



@inproceedings{volker2018intracranial,
  title={Intracranial error detection via deep learning},
  author={Volker, Martin and Hammer, Jiri and Schirrmeister, Robin T and Behncke, Joos and Fiederer, Lukas DJ and Schulze-Bonhage, Andreas and Marusic, Petr and Burgard, Wolfram and Ball, Tonio},
  booktitle={2018 IEEE International Conference on Systems, Man, and Cybernetics (SMC)},
  pages={568--575},
  year={2018},
  organization={IEEE}
}



@inproceedings{behncke2018signature,
  title={The signature of robot action success in EEG signals of a human observer: Decoding and visualization using deep convolutional neural networks},
  author={Behncke, Joos and Schirrmeister, Robin T and Burgard, Wolfram and Ball, Tonio},
  booktitle={2018 6th international conference on brain-computer interface (BCI)},
  pages={1--6},
  year={2018},
  organization={IEEE}
}

@inproceedings{volker2018deep,
  title={Deep transfer learning for error decoding from non-invasive EEG},
  author={V{\"o}lker, Martin and Schirrmeister, Robin T and Fiederer, Lukas DJ and Burgard, Wolfram and Ball, Tonio},
  booktitle={2018 6th International Conference on Brain-Computer Interface (BCI)},
  pages={1--6},
  year={2018},
  organization={IEEE}
}

@inproceedings{burget2017acting,
  title={Acting thoughts: Towards a mobile robotic service assistant for users with limited communication skills},
  author={Burget, Felix and Fiederer, Lukas Dominique Josef and Kuhner, Daniel and V{\"o}lker, Martin and Aldinger, Johannes and Schirrmeister, Robin Tibor and Do, Chau and Boedecker, Joschka and Nebel, Bernhard and Ball, Tonio and others},
  booktitle={2017 European Conference on Mobile Robots (ECMR)},
  pages={1--6},
  year={2017},
  organization={IEEE}
}





@article{pfurtscheller_mu_2006,
	title = {Mu rhythm (de)synchronization and {EEG} single-trial classification of different motor imagery tasks},
	volume = {31},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811905025140},
	doi = {10.1016/j.neuroimage.2005.12.003},
	abstract = {We studied the reactivity of EEG rhythms (mu rhythms) in association with the imagination of right hand, left hand, foot, and tongue movement with 60 EEG electrodes in nine able-bodied subjects. During hand motor imagery, the hand mu rhythm blocked or desynchronized in all subjects, whereas an enhancement of the hand area mu rhythm was observed during foot or tongue motor imagery in the majority of the subjects. The frequency of the most reactive components was 11.7 Hz ± 0.4 (mean ± SD). While the desynchronized components were broad banded and centered at 10.9 Hz ± 0.9, the synchronized components were narrow banded and displayed higher frequencies at 12.0 Hz ± 1.0. The discrimination between the four motor imagery tasks based on classification of single EEG trials improved when, in addition to event-related desynchronization (ERD), event-related synchronization (ERS) patterns were induced in at least one or two tasks. This implies that such EEG phenomena may be utilized in a multi-class brain–computer interface (BCI) operated simply by motor imagery.},
	number = {1},
	urldate = {2015-06-26},
	journal = {NeuroImage},
	author = {Pfurtscheller, G. and Brunner, C. and Schlögl, A. and Lopes da Silva, F. H.},
	month = may,
	year = {2006},
	pages = {153--159},
	file = {ScienceDirect Full Text PDF:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/KP7FJVKA/Pfurtscheller et al. - 2006 - Mu rhythm (de)synchronization and EEG single-trial.pdf:application/pdf;ScienceDirect Snapshot:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/Z7GI8GQR/S1053811905025140.html:text/html}
}


@article{pascanu_difficulty_2012,
	title = {On the difficulty of training {Recurrent} {Neural} {Networks}},
	url = {http://arxiv.org/abs/1211.5063},
	abstract = {There are two widely known issues with properly training Recurrent Neural Networks, the vanishing and the exploding gradient problems detailed in Bengio et al. (1994). In this paper we attempt to improve the understanding of the underlying issues by exploring these problems from an analytical, a geometric and a dynamical systems perspective. Our analysis is used to justify a simple yet effective solution. We propose a gradient norm clipping strategy to deal with exploding gradients and a soft constraint for the vanishing gradients problem. We validate empirically our hypothesis and proposed solutions in the experimental section.},
	urldate = {2015-08-18},
	journal = {arXiv:1211.5063 [cs]},
	author = {Pascanu, Razvan and Mikolov, Tomas and Bengio, Yoshua},
	month = nov,
	year = {2012},
	note = {arXiv: 1211.5063},
	keywords = {Computer Science - Learning},
	annote = {Comment: Improved description of the exploding gradient problem and description and analysis of the vanishing gradient problem},
	file = {arXiv\:1211.5063 PDF:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/FWSAHG8M/Pascanu et al. - 2012 - On the difficulty of training Recurrent Neural Net.pdf:application/pdf;arXiv.org Snapshot:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/VIRFSMCG/1211.html:text/html}
}

@book{ferri_comparative_1994,
	title = {Comparative {Study} of {Techniques} for {Large}-{Scale} {Feature} {Selection}},
	url = {http://www2.cse.msu.edu/~rossarun/courses/sp15/cse802/papers/FerriFeatureSelection_PR1994.pdf},
	abstract = {this paper is to investigate the applicability of these techniques to high dimensional problems of Feature Selection. The aim is to establish whether the properties inferred for these techniques from medium scale experiments involving up to a few tens of dimensions extend to dimensionalities of one order of magnitude higher. Further, relative merits of these techniques vis-a-vis such high dimensional problems are explored and the possibility of exploiting the best aspects of these methods to create a composite feature selection procedure with superior properties is considered},
	author = {Ferri, F. J. and Pudil, P. and Hatef, M. and Kittler, J.},
	year = {1994},
	file = {Citeseer - Snapshot:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/4UGCTMCV/summary.html:text/html}
}

@article{kudo_comparison_2000,
	title = {Comparison of algorithms that select features for pattern classifiers},
	volume = {33},
	issn = {0031-3203},
	url = {http://www.sciencedirect.com/science/article/pii/S0031320399000412},
	doi = {10.1016/S0031-3203(99)00041-2},
	abstract = {A comparative study of algorithms for large-scale feature selection (where the number of features is over 50) is carried out. In the study, the goodness of a feature subset is measured by leave-one-out correct-classification rate of a nearest-neighbor (1-NN) classifier and many practical problems are used. A unified way is given to compare algorithms having dissimilar objectives. Based on the results of many experiments, we give guidelines for the use of feature selection algorithms. Especially, it is shown that sequential floating search methods are suitable for small- and medium-scale problems and genetic algorithms are suitable for large-scale problems.},
	number = {1},
	urldate = {2015-08-20},
	journal = {Pattern Recognition},
	author = {Kudo, Mineichi and Sklansky, Jack},
	month = jan,
	year = {2000},
	keywords = {Feature selection, Genetic algorithms, k-nearest-neighbor method, Leave-one-out method, Monotonicity},
	pages = {25--41},
	file = {ScienceDirect Full Text PDF:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/ITAE3B26/Kudo and Sklansky - 2000 - Comparison of algorithms that select features for .pdf:application/pdf;ScienceDirect Snapshot:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/JJMHGP3K/S0031320399000412.html:text/html}
}

@book{duda_pattern_2012,
	edition = {2},
	title = {Pattern classification},
	url = {https://books.google.com/books?hl=de&lr=&id=Br33IRC3PkQC&oi=fnd&pg=PR3&dq=Pattern+Classification+Richard+O.+Duda,+Peter+E.+Hart,+David+G.+Stork&ots=2wAOHzd9Kt&sig=y3ZAYtHneVHEY3P0buNWhlh6U7U},
	urldate = {2015-08-19},
	publisher = {John Wiley \& Sons},
	author = {Duda, Richard O. and Hart, Peter E. and Stork, David G.},
	year = {2012},
	file = {[PDF] von cern.ch:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/RS8EAC55/Duda et al. - 2012 - Pattern classification.pdf:application/pdf;Snapshot:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/DZXBWM2Q/books.html:text/html}
}

@book{smith_spectral_2011,
	title = {Spectral {Audio} {Signal} {Processing}},
	url = {https://ccrma.stanford.edu/~jos/sasp/Blackman_Harris_Window_Family.html},
	publisher = {https://ccrma.stanford.edu/{\textasciitilde}jos/sasp/},
	author = {Smith, Julius O.},
	year = {2011},
	note = {online book, 2011 edition}
}

@article{collinger_high-performance_2013,
	title = {High-performance neuroprosthetic control by an individual with tetraplegia},
	volume = {381},
	issn = {0140-6736},
	url = {http://www.sciencedirect.com/science/article/pii/S0140673612618169},
	doi = {10.1016/S0140-6736(12)61816-9},
	abstract = {SummaryBackground
Paralysis or amputation of an arm results in the loss of the ability to orient the hand and grasp, manipulate, and carry objects, functions that are essential for activities of daily living. Brain–machine interfaces could provide a solution to restoring many of these lost functions. We therefore tested whether an individual with tetraplegia could rapidly achieve neurological control of a high-performance prosthetic limb using this type of an interface.
Methods
We implanted two 96-channel intracortical microelectrodes in the motor cortex of a 52-year-old individual with tetraplegia. Brain–machine-interface training was done for 13 weeks with the goal of controlling an anthropomorphic prosthetic limb with seven degrees of freedom (three-dimensional translation, three-dimensional orientation, one-dimensional grasping). The participant's ability to control the prosthetic limb was assessed with clinical measures of upper limb function. This study is registered with ClinicalTrials.gov, NCT01364480.
Findings
The participant was able to move the prosthetic limb freely in the three-dimensional workspace on the second day of training. After 13 weeks, robust seven-dimensional movements were performed routinely. Mean success rate on target-based reaching tasks was 91·6\% (SD 4·4) versus median chance level 6·2\% (95\% CI 2·0–15·3). Improvements were seen in completion time (decreased from a mean of 148 s [SD 60] to 112 s [6]) and path efficiency (increased from 0·30 [0·04] to 0·38 [0·02]). The participant was also able to use the prosthetic limb to do skilful and coordinated reach and grasp movements that resulted in clinically significant gains in tests of upper limb function. No adverse events were reported.
Interpretation
With continued development of neuroprosthetic limbs, individuals with long-term paralysis could recover the natural and intuitive command signals for hand placement, orientation, and reaching, allowing them to perform activities of daily living.
Funding
Defense Advanced Research Projects Agency, National Institutes of Health, Department of Veterans Affairs, and UPMC Rehabilitation Institute.},
	number = {9866},
	urldate = {2015-08-21},
	journal = {The Lancet},
	author = {Collinger, Jennifer L and Wodlinger, Brian and Downey, John E and Wang, Wei and Tyler-Kabara, Elizabeth C and Weber, Douglas J and McMorland, Angus JC and Velliste, Meel and Boninger, Michael L and Schwartz, Andrew B},
	month = feb,
	year = {2013},
	pages = {557--564},
	file = {ScienceDirect Full Text PDF:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/3UX6NXCI/Collinger et al. - 2013 - High-performance neuroprosthetic control by an ind.pdf:application/pdf;ScienceDirect Snapshot:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/WA6TZA3E/S0140673612618169.html:text/html}
}

@article{ledoit_well-conditioned_2004,
	title = {A well-conditioned estimator for large-dimensional covariance matrices},
	volume = {88},
	issn = {0047-259X},
	url = {http://www.sciencedirect.com/science/article/pii/S0047259X03000964},
	doi = {10.1016/S0047-259X(03)00096-4},
	abstract = {Many applied problems require a covariance matrix estimator that is not only invertible, but also well-conditioned (that is, inverting it does not amplify estimation error). For large-dimensional covariance matrices, the usual estimator—the sample covariance matrix—is typically not well-conditioned and may not even be invertible. This paper introduces an estimator that is both well-conditioned and more accurate than the sample covariance matrix asymptotically. This estimator is distribution-free and has a simple explicit formula that is easy to compute and interpret. It is the asymptotically optimal convex linear combination of the sample covariance matrix with the identity matrix. Optimality is meant with respect to a quadratic loss function, asymptotically as the number of observations and the number of variables go to infinity together. Extensive Monte Carlo confirm that the asymptotic results tend to hold well in finite sample.},
	number = {2},
	urldate = {2015-08-19},
	journal = {Journal of Multivariate Analysis},
	author = {Ledoit, Olivier and Wolf, Michael},
	month = feb,
	year = {2004},
	keywords = {Condition number, Covariance matrix estimation, Empirical Bayes, General asymptotics, Shrinkage},
	pages = {365--411},
	file = {ScienceDirect Full Text PDF:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/CCVVANK5/Ledoit and Wolf - 2004 - A well-conditioned estimator for large-dimensional.pdf:application/pdf;ScienceDirect Snapshot:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/XGGZFJRJ/S0047259X03000964.html:text/html}
}

@article{srivastava_dropout:_2014,
	title = {Dropout: {A} simple way to prevent neural networks from overfitting},
	volume = {15},
	shorttitle = {Dropout},
	url = {http://dl.acm.org/citation.cfm?id=2670313},
	number = {1},
	urldate = {2015-08-12},
	journal = {The Journal of Machine Learning Research},
	author = {Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
	year = {2014},
	pages = {1929--1958},
	file = {[PDF] von jmlr.org:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/HFA53MH3/Srivastava et al. - 2014 - Dropout A simple way to prevent neural networks f.pdf:application/pdf;Snapshot:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/PQWTSDUV/citation.html:text/html}
}

@inproceedings{dieleman_end--end_2014,
	title = {End-to-end learning for music audio},
	url = {http://ieeexplore.ieee.org/xpls/icp.jsp?arnumber=6854950},
	doi = {10.1109/ICASSP.2014.6854950},
	abstract = {Content-based music information retrieval tasks have traditionally been solved using engineered features and shallow processing architectures. In recent years, there has been increasing interest in using feature learning and deep architectures instead, thus reducing the required engineering effort and the need for prior knowledge. However, this new approach typically still relies on mid-level representations of music audio, e.g. spectrograms, instead of raw audio signals. In this paper, we investigate whether it is possible to apply feature learning directly to raw audio signals. We train convolutional neural networks using both approaches and compare their performance on an automatic tagging task. Although they do not outperform a spectrogram-based approach, the networks are able to autonomously discover frequency decompositions from raw audio, as well as phase-and translation-invariant feature representations.},
	booktitle = {2014 {IEEE} {International} {Conference} on {Acoustics}, {Speech} and {Signal} {Processing} ({ICASSP})},
	author = {Dieleman, S. and Schrauwen, B.},
	month = may,
	year = {2014},
	keywords = {automatic tagging, automatic tagging task, Computer architecture, content-based music information retrieval tasks, content-based retrieval, convolution, convolutional neural networks, convolutional neural networks training, end-to-end learning, feature learning, frequency decompositions, learning (artificial intelligence), music, music audio, Music information retrieval, Neural networks, phase-and translation-invariant feature representations, raw audio, Spectrogram, spectrogram-based approach, Speech},
	pages = {6964--6968},
	file = {IEEE Xplore Abstract Record:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/NBVWE7HA/icp.html:text/html}
}

@article{goodfellow_pylearn2:_2013,
	title = {Pylearn2: a machine learning research library},
	url = {http://arxiv.org/abs/1308.4214},
	abstract = {Pylearn2 is a machine learning research library. This does not just mean that it is a collection of machine learning algorithms that share a common API; it means that it has been designed for flexibility and extensibility in order to facilitate research projects that involve new or unusual use cases. In this paper we give a brief history of the library, an overview of its basic philosophy, a summary of the library's architecture, and a description of how the Pylearn2 community functions socially.},
	journal = {arXiv preprint arXiv:1308.4214},
	author = {Goodfellow, Ian J. and Warde-Farley, David and Lamblin, Pascal and Dumoulin, Vincent and Mirza, Mehdi and Pascanu, Razvan and Bergstra, James and Bastien, Frédéric and Bengio, Yoshua},
	year = {2013}
}

@article{galar_overview_2011,
	title = {An overview of ensemble methods for binary classifiers in multi-class problems: {Experimental} study on one-vs-one and one-vs-all schemes},
	volume = {44},
	issn = {0031-3203},
	shorttitle = {An overview of ensemble methods for binary classifiers in multi-class problems},
	url = {http://www.sciencedirect.com/science/article/pii/S0031320311000458},
	doi = {10.1016/j.patcog.2011.01.017},
	abstract = {Classification problems involving multiple classes can be addressed in different ways. One of the most popular techniques consists in dividing the original data set into two-class subsets, learning a different binary model for each new subset. These techniques are known as binarization strategies.

In this work, we are interested in ensemble methods by binarization techniques; in particular, we focus on the well-known one-vs-one and one-vs-all decomposition strategies, paying special attention to the final step of the ensembles, the combination of the outputs of the binary classifiers. Our aim is to develop an empirical analysis of different aggregations to combine these outputs. To do so, we develop a double study: first, we use different base classifiers in order to observe the suitability and potential of each combination within each classifier. Then, we compare the performance of these ensemble techniques with the classifiers' themselves. Hence, we also analyse the improvement with respect to the classifiers that handle multiple classes inherently.

We carry out the experimental study with several well-known algorithms of the literature such as Support Vector Machines, Decision Trees, Instance Based Learning or Rule Based Systems. We will show, supported by several statistical analyses, the goodness of the binarization techniques with respect to the base classifiers and finally we will point out the most robust techniques within this framework.},
	number = {8},
	urldate = {2015-08-20},
	journal = {Pattern Recognition},
	author = {Galar, Mikel and Fernández, Alberto and Barrenechea, Edurne and Bustince, Humberto and Herrera, Francisco},
	month = aug,
	year = {2011},
	keywords = {Decomposition strategies, Ensembles, Multi-classification, One-vs-all, One-vs-one, Pairwise learning},
	pages = {1761--1776},
	file = {ScienceDirect Full Text PDF:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/44EV2QDZ/Galar et al. - 2011 - An overview of ensemble methods for binary classif.pdf:application/pdf;ScienceDirect Snapshot:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/BS7Z3QZB/S0031320311000458.html:text/html}
}

@article{hochberg_reach_2012,
	title = {Reach and grasp by people with tetraplegia using a neurally controlled robotic arm},
	volume = {485},
	copyright = {© 2012 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	issn = {0028-0836},
	url = {http://www.nature.com/nature/journal/v485/n7398/abs/nature11076.html},
	doi = {10.1038/nature11076},
	abstract = {Paralysis following spinal cord injury, brainstem stroke, amyotrophic lateral sclerosis and other disorders can disconnect the brain from the body, eliminating the ability to perform volitional movements. A neural interface system could restore mobility and independence for people with paralysis by translating neuronal activity directly into control signals for assistive devices. We have previously shown that people with long-standing tetraplegia can use a neural interface system to move and click a computer cursor and to control physical devices. Able-bodied monkeys have used a neural interface system to control a robotic arm, but it is unknown whether people with profound upper extremity paralysis or limb loss could use cortical neuronal ensemble signals to direct useful arm actions. Here we demonstrate the ability of two people with long-standing tetraplegia to use neural interface system-based control of a robotic arm to perform three-dimensional reach and grasp movements. Participants controlled the arm and hand over a broad space without explicit training, using signals decoded from a small, local population of motor cortex (MI) neurons recorded from a 96-channel microelectrode array. One of the study participants, implanted with the sensor 5 years earlier, also used a robotic arm to drink coffee from a bottle. Although robotic reach and grasp actions were not as fast or accurate as those of an able-bodied person, our results demonstrate the feasibility for people with tetraplegia, years after injury to the central nervous system, to recreate useful multidimensional control of complex devices directly from a small sample of neural signals.},
	language = {en},
	number = {7398},
	urldate = {2015-08-21},
	journal = {Nature},
	author = {Hochberg, Leigh R. and Bacher, Daniel and Jarosiewicz, Beata and Masse, Nicolas Y. and Simeral, John D. and Vogel, Joern and Haddadin, Sami and Liu, Jie and Cash, Sydney S. and van der Smagt, Patrick and Donoghue, John P.},
	month = may,
	year = {2012},
	keywords = {Applied physics, Engineering, Medical research, Neuroscience, Technology},
	pages = {372--375},
	file = {Full Text PDF:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/N869KPWF/Hochberg et al. - 2012 - Reach and grasp by people with tetraplegia using a.pdf:application/pdf;Snapshot:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/H6ESAXG2/nature11076.html:text/html}
}

@article{anderson_targeting_2004,
	title = {Targeting recovery: priorities of the spinal cord-injured population},
	volume = {21},
	shorttitle = {Targeting recovery},
	url = {http://online.liebertpub.com/doi/pdf/10.1089/neu.2004.21.1371},
	number = {10},
	urldate = {2014-02-09},
	journal = {Journal of neurotrauma},
	author = {Anderson, Kim D.},
	year = {2004},
	pages = {1371--1383},
	file = {[PDF] von christopherreeve.org:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/2FDATS66/Anderson - 2004 - Targeting recovery priorities of the spinal cord-.pdf:application/pdf;Snapshot:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/R6QV4H9N/cookieAbsent.html:text/html}
}

@article{weichwald_causal_2015,
	title = {Causal interpretation rules for encoding and decoding models in neuroimaging},
	volume = {110},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/pii/S105381191500052X},
	doi = {10.1016/j.neuroimage.2015.01.036},
	abstract = {Causal terminology is often introduced in the interpretation of encoding and decoding models trained on neuroimaging data. In this article, we investigate which causal statements are warranted and which ones are not supported by empirical evidence. We argue that the distinction between encoding and decoding models is not sufficient for this purpose: relevant features in encoding and decoding models carry a different meaning in stimulus- and in response-based experimental paradigms.We show that only encoding models in the stimulus-based setting support unambiguous causal interpretations. By combining encoding and decoding models trained on the same data, however, we obtain insights into causal relations beyond those that are implied by each individual model type. We illustrate the empirical relevance of our theoretical findings on EEG data recorded during a visuo-motor learning task.},
	urldate = {2015-07-31},
	journal = {NeuroImage},
	author = {Weichwald, Sebastian and Meyer, Timm and Özdenizci, Ozan and Schölkopf, Bernhard and Ball, Tonio and Grosse-Wentrup, Moritz},
	month = apr,
	year = {2015},
	keywords = {Causal inference, Decoding models, Encoding models, Interpretation, Pattern recognition},
	pages = {48--59},
	file = {ScienceDirect Full Text PDF:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/D7ZM63DN/Weichwald et al. - 2015 - Causal interpretation rules for encoding and decod.pdf:application/pdf;ScienceDirect Snapshot:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/SPEZ6WMM/S105381191500052X.html:text/html}
}

@article{ball_movement_2008,
	title = {Movement related activity in the high gamma range of the human {EEG}},
	volume = {41},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811908001717},
	doi = {10.1016/j.neuroimage.2008.02.032},
	abstract = {Electrocorticographic (ECoG) recordings obtained using intracranially implanted electrodes in epilepsy patients indicate that high gamma band (HGB) activity of sensorimotor cortex is focally increased during voluntary movement. These movement related HGB modulations may play an important role in sensorimotor cortex function. It is however currently not clear to what extent this type of neural activity can be detected using non-invasive electroencephalography (EEG) and how similar HGB responses in healthy human subjects are to those observed in epilepsy patients. Using the same arm reaching task, we have investigated spectral power changes both in intracranial ECoG recordings in epilepsy patients and in non-invasive EEG recordings optimized for detecting HGB activity in healthy subjects. Our results show a common HGB response pattern both in ECoG and EEG recorded above the sensorimotor cortex contralateral to the side of arm movement. In both cases, HGB activity increased around movement onset in the 60–90 Hz range and became most pronounced at reaching movement end. Additionally, we found EEG HGB activity above the frontal midline possibly generated by the anterior supplementary motor area (SMA), a region that was however not covered by the intracranial electrodes used in the present study. In summary, our findings show that HGB activity from human sensorimotor cortex can be non-invasively detected in healthy subjects using EEG, opening a new perspective for investigating the role of high gamma range neuronal activity both in function and dysfunction of the human cortical sensorimotor network.},
	number = {2},
	urldate = {2015-07-15},
	journal = {NeuroImage},
	author = {Ball, Tonio and Demandt, Evariste and Mutschler, Isabella and Neitzel, Eva and Mehring, Carsten and Vogt, Klaus and Aertsen, Ad and Schulze-Bonhage, Andreas},
	month = jun,
	year = {2008},
	pages = {302--310},
	file = {ScienceDirect Full Text PDF:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/NI4VHQTQ/Ball et al. - 2008 - Movement related activity in the high gamma range .pdf:application/pdf;ScienceDirect Snapshot:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/999KFHAJ/S1053811908001717.html:text/html}
}

@article{li_using_2006,
	title = {Using discriminant analysis for multi-class classification: an experimental investigation},
	volume = {10},
	issn = {0219-1377, 0219-3116},
	shorttitle = {Using discriminant analysis for multi-class classification},
	url = {http://link.springer.com/article/10.1007/s10115-006-0013-y},
	doi = {10.1007/s10115-006-0013-y},
	abstract = {Many supervised machine learning tasks can be cast as multi-class classification problems. Support vector machines (SVMs) excel at binary classification problems, but the elegant theory behind large-margin hyperplane cannot be easily extended to their multi-class counterparts. On the other hand, it was shown that the decision hyperplanes for binary classification obtained by SVMs are equivalent to the solutions obtained by Fisher's linear discriminant on the set of support vectors. Discriminant analysis approaches are well known to learn discriminative feature transformations in the statistical pattern recognition literature and can be easily extend to multi-class cases. The use of discriminant analysis, however, has not been fully experimented in the data mining literature. In this paper, we explore the use of discriminant analysis for multi-class classification problems. We evaluate the performance of discriminant analysis on a large collection of benchmark datasets and investigate its usage in text categorization. Our experiments suggest that discriminant analysis provides a fast, efficient yet accurate alternative for general multi-class classification problems.},
	language = {en},
	number = {4},
	urldate = {2015-08-19},
	journal = {Knowledge and Information Systems},
	author = {Li, Tao and Zhu, Shenghuo and Ogihara, Mitsunori},
	month = mar,
	year = {2006},
	keywords = {Business Information Systems, Discriminant analysis, Information Systems and Communication Service, Multi-class classification},
	pages = {453--472},
	file = {Full Text PDF:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/D83WHCP7/Li et al. - 2006 - Using discriminant analysis for multi-class classi.pdf:application/pdf;Snapshot:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/FQAA8EM5/10.html:text/html}
}

@article{simonyan_deep_2013,
	title = {Deep {Inside} {Convolutional} {Networks}: {Visualising} {Image} {Classification} {Models} and {Saliency} {Maps}},
	shorttitle = {Deep {Inside} {Convolutional} {Networks}},
	url = {http://arxiv.org/abs/1312.6034},
	abstract = {This paper addresses the visualisation of image classification models, learnt using deep Convolutional Networks (ConvNets). We consider two visualisation techniques, based on computing the gradient of the class score with respect to the input image. The first one generates an image, which maximises the class score [Erhan et al., 2009], thus visualising the notion of the class, captured by a ConvNet. The second technique computes a class saliency map, specific to a given image and class. We show that such maps can be employed for weakly supervised object segmentation using classification ConvNets. Finally, we establish the connection between the gradient-based ConvNet visualisation methods and deconvolutional networks [Zeiler et al., 2013].},
	urldate = {2015-08-23},
	journal = {arXiv:1312.6034 [cs]},
	author = {Simonyan, Karen and Vedaldi, Andrea and Zisserman, Andrew},
	month = dec,
	year = {2013},
	note = {arXiv: 1312.6034},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv\:1312.6034 PDF:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/GRWTQH5S/Simonyan et al. - 2013 - Deep Inside Convolutional Networks Visualising Im.pdf:application/pdf;arXiv.org Snapshot:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/G3PKNWQB/1312.html:text/html}
}

@inproceedings{dahl_improving_2013,
	title = {Improving deep neural networks for {LVCSR} using rectified linear units and dropout},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6639346},
	doi = {10.1109/ICASSP.2013.6639346},
	abstract = {Recently, pre-trained deep neural networks (DNNs) have outperformed traditional acoustic models based on Gaussian mixture models (GMMs) on a variety of large vocabulary speech recognition benchmarks. Deep neural nets have also achieved excellent results on various computer vision tasks using a random “dropout” procedure that drastically improves generalization error by randomly omitting a fraction of the hidden units in all layers. Since dropout helps avoid over-fitting, it has also been successful on a small-scale phone recognition task using larger neural nets. However, training deep neural net acoustic models for large vocabulary speech recognition takes a very long time and dropout is likely to only increase training time. Neural networks with rectified linear unit (ReLU) non-linearities have been highly successful for computer vision tasks and proved faster to train than standard sigmoid units, sometimes also improving discriminative performance. In this work, we show on a 50-hour English Broadcast News task that modified deep neural networks using ReLUs trained with dropout during frame level training provide an 4.2\% relative improvement over a DNN trained with sigmoid units, and a 14.4\% relative improvement over a strong GMM/HMM system. We were able to obtain our results with minimal human hyper-parameter tuning using publicly available Bayesian optimization code.},
	booktitle = {2013 {IEEE} {International} {Conference} on {Acoustics}, {Speech} and {Signal} {Processing} ({ICASSP})},
	author = {Dahl, G.E. and Sainath, T.N. and Hinton, G.E.},
	month = may,
	year = {2013},
	keywords = {acoustic modeling, acoustic models, Acoustics, acoustic signal processing, Bayesian optimization, Bayesian optimization code, Bayes methods, broadcast news, computer vision tasks, deep learning, deep neural networks, DNN, dropout, English broadcast news task, frame level training, Gaussian mixture models, Gaussian processes, generalization error, GMM/HMM system, hidden Markov models, hyper-parameter tuning, LVCSR, neural nets, Neural networks, optimisation, Optimization, random dropout procedure, rectified linear unit, rectified linear units, ReLU nonlinearities, sigmoid units, small-scale phone recognition task, Speech recognition, Training, vocabulary speech recognition benchmarks},
	pages = {8609--8613},
	file = {IEEE Xplore Abstract Record:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/X5MX3RS4/abs_all.html:text/html;IEEE Xplore Full Text PDF:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/C4N7WW48/Dahl et al. - 2013 - Improving deep neural networks for LVCSR using rec.pdf:application/pdf}
}

@article{kohavi_wrappers_1997,
	series = {Relevance},
	title = {Wrappers for feature subset selection},
	volume = {97},
	issn = {0004-3702},
	url = {http://www.sciencedirect.com/science/article/pii/S000437029700043X},
	doi = {10.1016/S0004-3702(97)00043-X},
	abstract = {In the feature subset selection problem, a learning algorithm is faced with the problem of selecting a relevant subset of features upon which to focus its attention, while ignoring the rest. To achieve the best possible performance with a particular learning algorithm on a particular training set, a feature subset selection method should consider how the algorithm and the training set interact. We explore the relation between optimal feature subset selection and relevance. Our wrapper method searches for an optimal feature subset tailored to a particular algorithm and a domain. We study the strengths and weaknesses of the wrapper approach and show a series of improved designs. We compare the wrapper approach to induction without feature subset selection and to Relief, a filter approach to feature subset selection. Significant improvement in accuracy is achieved for some datasets for the two families of induction algorithms used: decision trees and Naive-Bayes.},
	number = {1–2},
	urldate = {2015-08-19},
	journal = {Artificial Intelligence},
	author = {Kohavi, Ron and John, George H.},
	month = dec,
	year = {1997},
	keywords = {Classification, Feature selection, Filter, Wrapper},
	pages = {273--324},
	file = {ScienceDirect Full Text PDF:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/ITBWZJJH/Kohavi and John - 1997 - Wrappers for feature subset selection.pdf:application/pdf;ScienceDirect Snapshot:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/ZJ9VHM5K/S000437029700043X.html:text/html}
}

@article{blankertz_optimizing_2008,
	title = {Optimizing {Spatial} filters for {Robust} {EEG} {Single}-{Trial} {Analysis}},
	volume = {25},
	issn = {1053-5888},
	url = {http://ieeexplore.ieee.org/xpls/icp.jsp?arnumber=4408441},
	doi = {10.1109/MSP.2008.4408441},
	abstract = {Due to the volume conduction multichannel electroencephalogram (EEG) recordings give a rather blurred image of brain activity. Therefore spatial filters are extremely useful in single-trial analysis in order to improve the signal-to-noise ratio. There are powerful methods from machine learning and signal processing that permit the optimization of spatio-temporal filters for each subject in a data dependent fashion beyond the fixed filters based on the sensor geometry, e.g., Laplacians. Here we elucidate the theoretical background of the common spatial pattern (CSP) algorithm, a popular method in brain-computer interface (BCD research. Apart from reviewing several variants of the basic algorithm, we reveal tricks of the trade for achieving a powerful CSP performance, briefly elaborate on theoretical aspects of CSP, and demonstrate the application of CSP-type preprocessing in our studies of the Berlin BCI (BBCI) project.},
	number = {1},
	journal = {IEEE Signal Processing Magazine},
	author = {Blankertz, B. and Tomioka, R. and Lemm, S. and Kawanabe, M. and Muller, K.-R.},
	year = {2008},
	keywords = {Berlin BCI project, Brain, brain activity, brain-computer interface, common spatial pattern algorithm, electroencephalogram, electroencephalography, Geometry, learning (artificial intelligence), machine learning, medical signal processing, neurophysiology, Optimization methods, robust EEG analysis, Robustness, Signal analysis, signal processing, Signal processing algorithms, Signal to noise ratio, signal-to-noise ratio, single-trial analysis, spatial filters, spatiotemporal filters, user interfaces, volume conduction multichannel EEG},
	pages = {41--56},
	file = {IEEE Xplore Abstract Record:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/PRN2NKRC/icp.html:text/html}
}

@article{haufe_interpretation_2014,
	title = {On the interpretation of weight vectors of linear models in multivariate neuroimaging},
	volume = {87},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811913010914},
	doi = {10.1016/j.neuroimage.2013.10.067},
	abstract = {The increase in spatiotemporal resolution of neuroimaging devices is accompanied by a trend towards more powerful multivariate analysis methods. Often it is desired to interpret the outcome of these methods with respect to the cognitive processes under study. Here we discuss which methods allow for such interpretations, and provide guidelines for choosing an appropriate analysis for a given experimental goal: For a surgeon who needs to decide where to remove brain tissue it is most important to determine the origin of cognitive functions and associated neural processes. In contrast, when communicating with paralyzed or comatose patients via brain–computer interfaces, it is most important to accurately extract the neural processes specific to a certain mental state. These equally important but complementary objectives require different analysis methods. Determining the origin of neural processes in time or space from the parameters of a data-driven model requires what we call a forward model of the data; such a model explains how the measured data was generated from the neural sources. Examples are general linear models (GLMs). Methods for the extraction of neural information from data can be considered as backward models, as they attempt to reverse the data generating process. Examples are multivariate classifiers. Here we demonstrate that the parameters of forward models are neurophysiologically interpretable in the sense that significant nonzero weights are only observed at channels the activity of which is related to the brain process under study. In contrast, the interpretation of backward model parameters can lead to wrong conclusions regarding the spatial or temporal origin of the neural signals of interest, since significant nonzero weights may also be observed at channels the activity of which is statistically independent of the brain process under study. As a remedy for the linear case, we propose a procedure for transforming backward models into forward models. This procedure enables the neurophysiological interpretation of the parameters of linear backward models. We hope that this work raises awareness for an often encountered problem and provides a theoretical basis for conducting better interpretable multivariate neuroimaging analyses.},
	urldate = {2015-08-07},
	journal = {NeuroImage},
	author = {Haufe, Stefan and Meinecke, Frank and Görgen, Kai and Dähne, Sven and Haynes, John-Dylan and Blankertz, Benjamin and Bießmann, Felix},
	month = feb,
	year = {2014},
	keywords = {Activation patterns, Decoding, EEG, Encoding, Extraction filters, fMRI, Forward/backward models, Generative/discriminative models, Interpretability, Multivariate, Neuroimaging, Regularization, Sparsity, Univariate},
	pages = {96--110},
	file = {ScienceDirect Full Text PDF:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/4GZX2HVN/Haufe et al. - 2014 - On the interpretation of weight vectors of linear .pdf:application/pdf;ScienceDirect Snapshot:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/FEWBNX2Q/S1053811913010914.html:text/html}
}

@article{springenberg_striving_2014,
	title = {Striving for {Simplicity}: {The} {All} {Convolutional} {Net}},
	shorttitle = {Striving for {Simplicity}},
	url = {http://arxiv.org/abs/1412.6806},
	abstract = {Most modern convolutional neural networks (CNNs) used for object recognition are built using the same principles: Alternating convolution and max-pooling layers followed by a small number of fully connected layers. We re-evaluate the state of the art for object recognition from small images with convolutional networks, questioning the necessity of different components in the pipeline. We find that max-pooling can simply be replaced by a convolutional layer with increased stride without loss in accuracy on several image recognition benchmarks. Following this finding -- and building on other recent work for finding simple network structures -- we propose a new architecture that consists solely of convolutional layers and yields competitive or state of the art performance on several object recognition datasets (CIFAR-10, CIFAR-100, ImageNet). To analyze the network we introduce a new variant of the "deconvolution approach" for visualizing features learned by CNNs, which can be applied to a broader range of network structures than existing approaches.},
	urldate = {2015-08-18},
	journal = {arXiv:1412.6806 [cs]},
	author = {Springenberg, Jost Tobias and Dosovitskiy, Alexey and Brox, Thomas and Riedmiller, Martin},
	month = dec,
	year = {2014},
	note = {arXiv: 1412.6806},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Learning, Computer Science - Neural and Evolutionary Computing},
	annote = {Comment: accepted to ICLR-2015 workshop track; no changes other than style},
	file = {arXiv\:1412.6806 PDF:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/MQQWF3BI/Springenberg et al. - 2014 - Striving for Simplicity The All Convolutional Net.pdf:application/pdf;arXiv.org Snapshot:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/ID7FTSH3/1412.html:text/html}
}

@inproceedings{ang_filter_2008,
	title = {Filter {Bank} {Common} {Spatial} {Pattern} ({FBCSP}) in {Brain}-{Computer} {Interface}},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4634130},
	doi = {10.1109/IJCNN.2008.4634130},
	abstract = {In motor imagery-based brain computer interfaces (BCI), discriminative patterns can be extracted from the electroencephalogram (EEG) using the common spatial pattern (CSP) algorithm. However, the performance of this spatial filter depends on the operational frequency band of the EEG. Thus, setting a broad frequency range, or manually selecting a subject-specific frequency range, are commonly used with the CSP algorithm. To address this problem, this paper proposes a novel filter bank common spatial pattern (FBCSP) to perform autonomous selection of key temporal-spatial discriminative EEG characteristics. After the EEG measurements have been bandpass-filtered into multiple frequency bands, CSP features are extracted from each of these bands. A feature selection algorithm is then used to automatically select discriminative pairs of frequency bands and corresponding CSP features. A classification algorithm is subsequently used to classify the CSP features. A study is conducted to assess the performance of a selection of feature selection and classification algorithms for use with the FBCSP. Extensive experimental results are presented on a publicly available dataset as well as data collected from healthy subjects and unilaterally paralyzed stroke patients. The results show that FBCSP, using a particular combination feature selection and classification algorithm, yields relatively higher cross-validation accuracies compared to prevailing approaches.},
	booktitle = {{IEEE} {International} {Joint} {Conference} on {Neural} {Networks}, 2008. {IJCNN} 2008. ({IEEE} {World} {Congress} on {Computational} {Intelligence})},
	author = {Ang, Kai Keng and Chin, Zheng Yang and Zhang, Haihong and Guan, Cuntai},
	month = jun,
	year = {2008},
	keywords = {Band-pass filters, Brain computer interfaces, brain-computer interfaces, classification algorithm, Classification algorithms, common spatial pattern algorithm, Communication system control, CSP algorithm, EEG, electroencephalogram, electroencephalography, feature extraction, Filter bank, filter bank common spatial pattern, Finite impulse response filter, Frequency measurement, Fuses, medical signal processing, motor imagery-based brain computer interfaces, spatial filter, spatial filters},
	pages = {2390--2397},
	file = {IEEE Xplore Abstract Record:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/S766G9KH/abs_all.html:text/html;IEEE Xplore Full Text PDF:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/IJXFZPZQ/Ang et al. - 2008 - Filter Bank Common Spatial Pattern (FBCSP) in Brai.pdf:application/pdf}
}

@article{gal_bayesian_2015,
	title = {Bayesian {Convolutional} {Neural} {Networks} with {Bernoulli} {Approximate} {Variational} {Inference}},
	url = {http://arxiv.org/abs/1506.02158},
	abstract = {We present an efficient Bayesian convolutional neural network (convnet). The model offers better robustness to over-fitting on small data than traditional approaches. This is by placing a probability distribution over the convnet's kernels (also known as filters). We approximate the model's intractable posterior with Bernoulli variational distributions. This requires no additional model parameters. Our model can be implemented using existing tools in the field. This is by extending the recent interpretation of dropout as approximate inference in the Gaussian process to the case of Bayesian neural networks. The model achieves a considerable improvement in classification accuracy compared to previous approaches. We finish with state-of-the-art results on CIFAR-10 following our new interpretation.},
	urldate = {2015-08-12},
	journal = {arXiv:1506.02158 [cs, stat]},
	author = {Gal, Yarin and Ghahramani, Zoubin},
	month = jun,
	year = {2015},
	note = {arXiv: 1506.02158},
	keywords = {Computer Science - Learning, Statistics - Machine Learning},
	annote = {Comment: 10 pages, 4 figures},
	file = {arXiv\:1506.02158 PDF:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/IME3VNPR/Gal and Ghahramani - 2015 - Bayesian Convolutional Neural Networks with Bernou.pdf:application/pdf;arXiv.org Snapshot:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/NDI44EX6/1506.html:text/html}
}

@inproceedings{chin_multi-class_2009,
	title = {Multi-class filter bank common spatial pattern for four-class motor imagery {BCI}},
	url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=5332383},
	doi = {10.1109/IEMBS.2009.5332383},
	abstract = {This paper investigates the classification of multi-class motor imagery for electroencephalogram (EEG)-based Brain-Computer Interface (BCI) using the Filter Bank Common Spatial Pattern (FBCSP) algorithm. The FBCSP algorithm classifies EEG measurements from features constructed using subject-specific temporal-spatial filters. However, the FBCSP algorithm is limited to binary-class motor imagery. Hence, this paper proposes 3 approaches of multi-class extension to the FBCSP algorithm: One-versus-Rest, Pair-Wise and Divide-and-Conquer. These approaches decompose the multi-class problem into several binary-class problems. The study is conducted on the BCI Competition IV dataset IIa, which comprises single-trial EEG data from 9 subjects performing 4-class motor imagery of left-hand, right-hand, foot and tongue actions. The results showed that the multi-class FBCSP algorithm could extract features that matched neurophysiological knowledge, and yielded the best performance on the evaluation data compared to other international submissions.},
	booktitle = {Annual {International} {Conference} of the {IEEE} {Engineering} in {Medicine} and {Biology} {Society}, 2009. {EMBC} 2009},
	author = {Chin, Zheng Yang and Ang, Kai Keng and Wang, Chuanchu and Guan, Cuntai and Zhang, Haihong},
	month = sep,
	year = {2009},
	keywords = {Algorithms, brain-computer interface, brain-computer interfaces, Brain Mapping, EEG classification, electroencephalogram, electroencephalography, Evoked Potentials, Motor, feature extraction, filter bank common spatial pattern algorithm, filtering theory, four-class motor imagery BCI, Humans, Imagination, medical signal processing, Motor Cortex, multiclass motor imagery classification, neurophysiology, Pattern Recognition, Automated, Reproducibility of Results, Sensitivity and Specificity, signal classification, Signal Processing, Computer-Assisted, subject-specific temporal-spatial filter, User-Computer Interface},
	pages = {571--574},
	file = {IEEE Xplore Abstract Record:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/68IRQ7TK/articleDetails.html:text/html;IEEE Xplore Full Text PDF:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/K93G5CFA/Chin et al. - 2009 - Multi-class filter bank common spatial pattern for.pdf:application/pdf}
}

@article{hochreiter_long_1997,
	title = {Long {Short}-{Term} {Memory}},
	volume = {9},
	issn = {0899-7667},
	url = {http://ieeexplore.ieee.org/xpl/freeabs_all.jsp?arnumber=6795963},
	doi = {10.1162/neco.1997.9.8.1735},
	abstract = {Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms.},
	number = {8},
	journal = {Neural Computation},
	author = {Hochreiter, S and Schmidhuber, J},
	month = nov,
	year = {1997},
	pages = {1735--1780},
	file = {IEEE Xplore Abstract Record:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/HVJX9AJH/freeabs_all.html:text/html}
}

@article{venthur_wyrm:_2015,
	title = {Wyrm: {A} {Brain}-{Computer} {Interface} {Toolbox} in {Python}},
	issn = {1539-2791, 1559-0089},
	shorttitle = {Wyrm},
	url = {http://link.springer.com/article/10.1007/s12021-015-9271-8},
	doi = {10.1007/s12021-015-9271-8},
	abstract = {In the last years Python has gained more and more traction in the scientific community. Projects like NumPy, SciPy, and Matplotlib have created a strong foundation for scientific computing in Python and machine learning packages like scikit-learn or packages for data analysis like Pandas are building on top of it. In this paper we present Wyrm (https://​github.​com/​bbci/​wyrm), an open source BCI toolbox in Python. Wyrm is applicable to a broad range of neuroscientific problems. It can be used as a toolbox for analysis and visualization of neurophysiological data and in real-time settings, like an online BCI application. In order to prevent software defects, Wyrm makes extensive use of unit testing. We will explain the key aspects of Wyrm’s software architecture and design decisions for its data structure, and demonstrate and validate the use of our toolbox by presenting our approach to the classification tasks of two different data sets from the BCI Competition III. Furthermore, we will give a brief analysis of the data sets using our toolbox, and demonstrate how we implemented an online experiment using Wyrm. With Wyrm we add the final piece to our ongoing effort to provide a complete, free and open source BCI system in Python.},
	language = {en},
	urldate = {2015-08-20},
	journal = {Neuroinformatics},
	author = {Venthur, Bastian and Dähne, Sven and Höhne, Johannes and Heller, Hendrik and Blankertz, Benjamin},
	month = may,
	year = {2015},
	keywords = {BCI, Bioinformatics, brain-computer interface, Computational Biology/Bioinformatics, Computer Appl. in Life Sciences, ECoG, EEG, machine learning, Neurology, Neurosciences, Python, signal processing, Toolbox},
	pages = {1--16},
	file = {Full Text PDF:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/A7BREAF5/Venthur et al. - 2015 - Wyrm A Brain-Computer Interface Toolbox in Python.pdf:application/pdf;Snapshot:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/GJQMFF9G/s12021-015-9271-8.html:text/html}
}

@article{pascanu_how_2013,
	title = {How to {Construct} {Deep} {Recurrent} {Neural} {Networks}},
	url = {http://arxiv.org/abs/1312.6026},
	abstract = {In this paper, we explore different ways to extend a recurrent neural network (RNN) to a {\textbackslash}textit\{deep\} RNN. We start by arguing that the concept of depth in an RNN is not as clear as it is in feedforward neural networks. By carefully analyzing and understanding the architecture of an RNN, however, we find three points of an RNN which may be made deeper; (1) input-to-hidden function, (2) hidden-to-hidden transition and (3) hidden-to-output function. Based on this observation, we propose two novel architectures of a deep RNN which are orthogonal to an earlier attempt of stacking multiple recurrent layers to build a deep RNN (Schmidhuber, 1992; El Hihi and Bengio, 1996). We provide an alternative interpretation of these deep RNNs using a novel framework based on neural operators. The proposed deep RNNs are empirically evaluated on the tasks of polyphonic music prediction and language modeling. The experimental result supports our claim that the proposed deep RNNs benefit from the depth and outperform the conventional, shallow RNNs.},
	urldate = {2015-08-18},
	journal = {arXiv:1312.6026 [cs, stat]},
	author = {Pascanu, Razvan and Gulcehre, Caglar and Cho, Kyunghyun and Bengio, Yoshua},
	month = dec,
	year = {2013},
	note = {arXiv: 1312.6026},
	keywords = {Computer Science - Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning},
	annote = {Comment: Accepted at ICLR 2014 (Conference Track). 10-page text + 3-page references},
	file = {arXiv\:1312.6026 PDF:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/VI4BGV22/Pascanu et al. - 2013 - How to Construct Deep Recurrent Neural Networks.pdf:application/pdf;arXiv.org Snapshot:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/VUB6X4MC/1312.html:text/html}
}

@article{zickler_bci_2009,
	title = {{BCI} applications for people with disabilities: defining user needs and user requirements},
	shorttitle = {{BCI} applications for people with disabilities},
	url = {http://www.tobi-project.org/sites/default/files/public/Publications/BCI_applications4_disable_people_ZICKLER.pdf},
	urldate = {2014-02-09},
	journal = {Assistive Technology from Adapted Equipment to Inclusive Environments, AAATE. 25 Assistive Technology Research Series},
	author = {Zickler, Claudia and Di Donna, Valentina and Kaiser, Vera and Al-Khodairy, Abdul and Kleih, Sonja and Kübler, Andrea and Malavasi, Massimiliano and Mattia, Donatella and Mongardi, Simona and Neuper, Christa},
	year = {2009},
	pages = {185--189},
	file = {[PDF] von tobi-project.org:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/R3FBAIJ9/Zickler et al. - 2009 - BCI applications for people with disabilities def.pdf:application/pdf;Snapshot:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/UHIH9JDU/books.html:text/html}
}

@article{townsend_comparison_2006,
	title = {A comparison of common spatial patterns with complex band power features in a four-class {BCI} experiment},
	volume = {53},
	issn = {0018-9294},
	url = {http://ieeexplore.ieee.org/xpls/icp.jsp?arnumber=1608513},
	doi = {10.1109/TBME.2006.870237},
	abstract = {We report on the offline analysis of four-class brain-computer interface (BCI) data recordings. Although the analysis is done within defined time windows (cue-based BCI), our goal is to work toward an approach which classifies on-going electroencephalogram (EEG) signals without the use of such windows (un-cued BCI). To that end, we provide some elements of that analysis related to timing issues that will become important as we pursue this goal in the future. A new set of features called complex band power (CBP) features which make explicit use of phase are introduced and are shown to produce good results. As reference methods we used traditional band power features and the method of common spatial patterns. We consider also for the first time in the context of a four-class problem the issue of variability of the features over time and how much data is required to give good classification results. We do this in a practical way where training data precedes testing data in time.},
	number = {4},
	journal = {IEEE Transactions on Biomedical Engineering},
	author = {Townsend, G. and Graimann, B. and Pfurtscheller, G.},
	month = apr,
	year = {2006},
	keywords = {Algorithms, Artificial Intelligence, Brain, brain-computer interface, Brain-computer interface (BCI), Brain computer interfaces, common spatial filters, common spatial patterns, complex band power features, Diagnosis, Computer-Assisted, Electrodes, electroencephalogram, electroencephalogram (EEG) classification, electroencephalography, Evoked Potentials, Motor, four-class BCI, handicapped aids, Humans, Imagination, medical signal processing, Movement, multi-class BCI, Pattern Recognition, Automated, phase, Power measurement, Reproducibility of Results, Sensitivity and Specificity, Signal analysis, signal classification, spatial filters, Synchronous motors, Testing, Timing, Training data, User-Computer Interface},
	pages = {642--651},
	file = {IEEE Xplore Abstract Record:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/52EQVE2T/icp.html:text/html}
}

@inproceedings{kingma_adam:_2015,
	title = {Adam: {A} {Method} for {Stochastic} {Optimization}},
	shorttitle = {Adam},
	url = {http://arxiv.org/abs/1412.6980},
	abstract = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.},
	urldate = {2015-08-12},
	booktitle = {{arXiv}:1412.6980 [cs]},
	author = {Kingma, Diederik and Ba, Jimmy},
	year = {2015},
	note = {arXiv: 1412.6980},
	keywords = {Computer Science - Learning},
	annote = {Comment: Published as a conference paper at the 3rd International Conference for Learning Representations, San Diego, 2015},
	file = {arXiv\:1412.6980 PDF:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/2HEH4SFH/Kingma and Ba - 2014 - Adam A Method for Stochastic Optimization.pdf:application/pdf;arXiv.org Snapshot:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/AZ6EWF6A/1412.html:text/html}
}

@article{blankertz_bci_2004,
	title = {The {BCI} competition 2003: progress and perspectives in detection and discrimination of {EEG} single trials},
	volume = {51},
	issn = {0018-9294},
	shorttitle = {The {BCI} competition 2003},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1300800},
	doi = {10.1109/TBME.2004.826692},
	abstract = {Interest in developing a new method of man-to-machine communication-a brain-computer interface (BCI)-has grown steadily over the past few decades. BCIs create a new communication channel between the brain and an output device by bypassing conventional motor output pathways of nerves and muscles. These systems use signals recorded from the scalp, the surface of the cortex, or from inside the brain to enable users to control a variety of applications including simple word-processing software and orthotics. BCI technology could therefore provide a new communication and control option for individuals who cannot otherwise express their wishes to the outside world. Signal processing and classification methods are essential tools in the development of improved BCI technology. We organized the BCI Competition 2003 to evaluate the current state of the art of these tools. Four laboratories well versed in EEG-based BCI research provided six data sets in a documented format. We made these data sets (i.e., labeled training sets and unlabeled test sets) and their descriptions available on the Internet. The goal in the competition was to maximize the performance measure for the test labels. Researchers worldwide tested their algorithms and competed for the best classification results. This paper describes the six data sets and the results and function of the most successful algorithms.},
	number = {6},
	journal = {IEEE Transactions on Biomedical Engineering},
	author = {Blankertz, B. and Muller, K. and Curio, G. and Vaughan, T.M. and Schalk, G. and Wolpaw, J.R. and Schlogl, A. and Neuper, C. and Pfurtscheller, G. and Hinterberger, T. and Schroder, M. and Birbaumer, N.},
	month = jun,
	year = {2004},
	keywords = {Adult, Algorithms, Amyotrophic Lateral Sclerosis, Application software, Artificial Intelligence, BCI Competition 2003, biomechanics, Brain, Brain computer interfaces, Cognition, Communication channels, Communication system control, Control systems, cortex, Databases, Factual, EEG single trials, electroencephalography, Evoked Potentials, handicapped aids, Humans, man-to-machine communication, medical signal detection, medical signal processing, motor output pathways, muscle, muscles, nerves, neurophysiology, orthotics, Reproducibility of Results, Scalp, Sensitivity and Specificity, signal classification, signal detection, signal discrimination, signal processing, Signal processing algorithms, Testing, User-Computer Interface, word processing, word-processing software},
	pages = {1044--1051},
	file = {IEEE Xplore Abstract Record:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/34RADQA5/abs_all.html:text/html;IEEE Xplore Full Text PDF:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/6UZINQ2M/Blankertz et al. - 2004 - The BCI competition 2003 progress and perspective.pdf:application/pdf}
}

@misc{wikipedia_linear_2015,
	title = {Linear discriminant analysis},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Linear_discriminant_analysis&oldid=674793958},
	abstract = {Linear discriminant analysis (LDA) is a generalization of Fisher's linear discriminant, a method used in statistics, pattern recognition and machine learning to find a linear combination of features that characterizes or separates two or more classes of objects or events. The resulting combination may be used as a linear classifier, or, more commonly, for dimensionality reduction before later classification.
LDA is closely related to analysis of variance (ANOVA) and regression analysis, which also attempt to express one dependent variable as a linear combination of other features or measurements. However, ANOVA uses categorical independent variables and a continuous dependent variable, whereas discriminant analysis has continuous independent variables and a categorical dependent variable (i.e. the class label). Logistic regression and probit regression are more similar to LDA than ANOVA is, as they also explain a categorical variable by the values of continuous independent variables. These other methods are preferable in applications where it is not reasonable to assume that the independent variables are normally distributed, which is a fundamental assumption of the LDA method.
LDA is also closely related to principal component analysis (PCA) and factor analysis in that they both look for linear combinations of variables which best explain the data. LDA explicitly attempts to model the difference between the classes of data. PCA on the other hand does not take into account any difference in class, and factor analysis builds the feature combinations based on differences rather than similarities. Discriminant analysis is also different from factor analysis in that it is not an interdependence technique: a distinction between independent variables and dependent variables (also called criterion variables) must be made.
LDA works when the measurements made on independent variables for each observation are continuous quantities. When dealing with categorical independent variables, the equivalent technique is discriminant correspondence analysis.},
	language = {en},
	urldate = {2015-08-22},
	journal = {Wikipedia, the free encyclopedia},
	author = {Wikipedia},
	month = aug,
	year = {2015},
	note = {Page Version ID: 674793958},
	file = {Snapshot:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/CNUX5HI6/index.html:text/html}
}

@article{jackson_neuroscience:_2012,
	title = {Neuroscience: {Brain}-controlled robot grabs attention},
	volume = {485},
	shorttitle = {Neuroscience},
	url = {http://www.nature.com/nature/journal/v485/n7398/abs/485317a.html},
	number = {7398},
	urldate = {2014-02-09},
	journal = {Nature},
	author = {Jackson, Andrew},
	year = {2012},
	pages = {317--318},
	file = {Snapshot:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/TGBP854V/485317a.html:text/html}
}

@misc{gal_what_2015,
	title = {What my deep model doesn't know... {\textbar} {Yarin} {Gal} - {Blog} {\textbar} {Cambridge} {Machine} {Learning} {Group}},
	url = {http://mlg.eng.cam.ac.uk/yarin/blog_3d801aa532c1ce.html#uncertainty-sense},
	abstract = {Trying to understand why dropout networks work so well, I was quite surprised to see that we can get principled uncertainty information from these models for free – without changing a thing.},
	urldate = {2015-08-12},
	author = {Gal, Yarin},
	month = jul,
	year = {2015},
	file = {Snapshot:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/XSVKMZFQ/blog_3d801aa532c1ce.html:text/html}
}

@article{schmidhuber_deep_2015,
	title = {Deep {Learning} in {Neural} {Networks}: {An} {Overview}},
	volume = {61},
	issn = {08936080},
	shorttitle = {Deep {Learning} in {Neural} {Networks}},
	url = {http://arxiv.org/abs/1404.7828},
	doi = {10.1016/j.neunet.2014.09.003},
	abstract = {In recent years, deep artificial neural networks (including recurrent ones) have won numerous contests in pattern recognition and machine learning. This historical survey compactly summarises relevant work, much of it from the previous millennium. Shallow and deep learners are distinguished by the depth of their credit assignment paths, which are chains of possibly learnable, causal links between actions and effects. I review deep supervised learning (also recapitulating the history of backpropagation), unsupervised learning, reinforcement learning \& evolutionary computation, and indirect search for short programs encoding deep and large networks.},
	urldate = {2015-08-12},
	journal = {Neural Networks},
	author = {Schmidhuber, Juergen},
	month = jan,
	year = {2015},
	note = {arXiv: 1404.7828},
	keywords = {Computer Science - Learning, Computer Science - Neural and Evolutionary Computing},
	pages = {85--117},
	annote = {Comment: 88 pages, 888 references},
	file = {arXiv\:1404.7828 PDF:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/EIVQXNQN/Schmidhuber - 2015 - Deep Learning in Neural Networks An Overview.pdf:application/pdf;arXiv.org Snapshot:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/M8NSBXRS/1404.html:text/html}
}

@article{blankertz_single-trial_2011,
	series = {Multivariate {Decoding} and {Brain} {Reading}},
	title = {Single-trial analysis and classification of {ERP} components — {A} tutorial},
	volume = {56},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811910009067},
	doi = {10.1016/j.neuroimage.2010.06.048},
	abstract = {Analyzing brain states that correspond to event related potentials (ERPs) on a single trial basis is a hard problem due to the high trial-to-trial variability and the unfavorable ratio between signal (ERP) and noise (artifacts and neural background activity). In this tutorial, we provide a comprehensive framework for decoding ERPs, elaborating on linear concepts, namely spatio-temporal patterns and filters as well as linear ERP classification. However, the bottleneck of these techniques is that they require an accurate covariance matrix estimation in high dimensional sensor spaces which is a highly intricate problem. As a remedy, we propose to use shrinkage estimators and show that appropriate regularization of linear discriminant analysis (LDA) by shrinkage yields excellent results for single-trial ERP classification that are far superior to classical LDA classification. Furthermore, we give practical hints on the interpretation of what classifiers learned from the data and demonstrate in particular that the trade-off between goodness-of-fit and model complexity in regularized LDA relates to a morphing between a difference pattern of ERPs and a spatial filter which cancels non task-related brain activity.},
	number = {2},
	urldate = {2015-07-31},
	journal = {NeuroImage},
	author = {Blankertz, Benjamin and Lemm, Steven and Treder, Matthias and Haufe, Stefan and Müller, Klaus-Robert},
	month = may,
	year = {2011},
	keywords = {BCI, Decoding, EEG, ERP, LDA, machine learning, Shrinkage, spatial filter, Spatial pattern},
	pages = {814--825},
	file = {ScienceDirect Full Text PDF:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/VCJWKWTH/Blankertz et al. - 2011 - Single-trial analysis and classification of ERP co.pdf:application/pdf;ScienceDirect Snapshot:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/AWXWPKHJ/S1053811910009067.html:text/html}
}

@article{tangermann_review_2012,
	title = {Review of the {BCI} {Competition} {IV}},
	volume = {6},
	issn = {1662-4548},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3396284/},
	doi = {10.3389/fnins.2012.00055},
	abstract = {The BCI competition IV stands in the tradition of prior BCI competitions that aim to provide high quality neuroscientific data for open access to the scientific community. As experienced already in prior competitions not only scientists from the narrow field of BCI compete, but scholars with a broad variety of backgrounds and nationalities. They include high specialists as well as students. The goals of all BCI competitions have always been to challenge with respect to novel paradigms and complex data. We report on the following challenges: (1) asynchronous data, (2) synthetic, (3) multi-class continuous data, (4) session-to-session transfer, (5) directionally modulated MEG, (6) finger movements recorded by ECoG. As after past competitions, our hope is that winning entries may enhance the analysis methods of future BCIs.},
	urldate = {2015-08-20},
	journal = {Frontiers in Neuroscience},
	author = {Tangermann, Michael and Müller, Klaus-Robert and Aertsen, Ad and Birbaumer, Niels and Braun, Christoph and Brunner, Clemens and Leeb, Robert and Mehring, Carsten and Miller, Kai J. and Müller-Putz, Gernot R. and Nolte, Guido and Pfurtscheller, Gert and Preissl, Hubert and Schalk, Gerwin and Schlögl, Alois and Vidaurre, Carmen and Waldert, Stephan and Blankertz, Benjamin},
	month = jul,
	year = {2012},
	pmid = {22811657},
	pmcid = {PMC3396284},
	file = {PubMed Central Full Text PDF:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/KAS6VM24/Tangermann et al. - 2012 - Review of the BCI Competition IV.pdf:application/pdf}
}

@article{steriade_basic_1990,
	title = {Basic mechanisms of cerebral rhythmic activities},
	volume = {76},
	issn = {0013-4694},
	url = {http://www.sciencedirect.com/science/article/pii/001346949090001Z},
	doi = {10.1016/0013-4694(90)90001-Z},
	number = {6},
	urldate = {2015-06-28},
	journal = {Electroencephalography and Clinical Neurophysiology},
	author = {Steriade, M. and Gloor, P. and Llinás, R. R. and Lopes da Silva, F. H. and Mesulam, M. -M.},
	month = dec,
	year = {1990},
	pages = {481--508},
	file = {ScienceDirect Full Text PDF:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/3R3WMZ7R/Steriade et al. - 1990 - Basic mechanisms of cerebral rhythmic activities.pdf:application/pdf;ScienceDirect Snapshot:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/AB86VJ5K/001346949090001Z.html:text/html}
}

@article{zeiler_visualizing_2013,
	title = {Visualizing and {Understanding} {Convolutional} {Networks}},
	url = {http://arxiv.org/abs/1311.2901},
	abstract = {Large Convolutional Network models have recently demonstrated impressive classification performance on the ImageNet benchmark. However there is no clear understanding of why they perform so well, or how they might be improved. In this paper we address both issues. We introduce a novel visualization technique that gives insight into the function of intermediate feature layers and the operation of the classifier. We also perform an ablation study to discover the performance contribution from different model layers. This enables us to find model architectures that outperform Krizhevsky {\textbackslash}etal on the ImageNet classification benchmark. We show our ImageNet model generalizes well to other datasets: when the softmax classifier is retrained, it convincingly beats the current state-of-the-art results on Caltech-101 and Caltech-256 datasets.},
	urldate = {2015-07-29},
	journal = {arXiv:1311.2901 [cs]},
	author = {Zeiler, Matthew D. and Fergus, Rob},
	month = nov,
	year = {2013},
	note = {arXiv: 1311.2901},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv\:1311.2901 PDF:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/KBUWXZ2K/Zeiler and Fergus - 2013 - Visualizing and Understanding Convolutional Networ.pdf:application/pdf;arXiv.org Snapshot:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/9APIZDSZ/1311.html:text/html}
}

@article{pfurtscheller_event-related_1999,
	title = {Event-related {EEG}/{MEG} synchronization and desynchronization: basic principles},
	volume = {110},
	issn = {1388-2457},
	shorttitle = {Event-related {EEG}/{MEG} synchronization and desynchronization},
	url = {http://www.sciencedirect.com/science/article/pii/S1388245799001418},
	doi = {10.1016/S1388-2457(99)00141-8},
	abstract = {An internally or externally paced event results not only in the generation of an event-related potential (ERP) but also in a change in the ongoing EEG/MEG in form of an event-related desynchronization (ERD) or event-related synchronization (ERS). The ERP on the one side and the ERD/ERS on the other side are different responses of neuronal structures in the brain. While the former is phase-locked, the latter is not phase-locked to the event. The most important difference between both phenomena is that the ERD/ERS is highly frequency band-specific, whereby either the same or different locations on the scalp can display ERD and ERS simultaneously. Quantification of ERD/ERS in time and space is demonstrated on data from a number of movement experiments.},
	number = {11},
	urldate = {2015-06-28},
	journal = {Clinical Neurophysiology},
	author = {Pfurtscheller, G. and Lopes da Silva, F. H.},
	month = nov,
	year = {1999},
	keywords = {Brain oscillations, Event-related desynchronization (ERD), Event-related synchronization (ERS), Sensorimotor function, Voluntary movement},
	pages = {1842--1857},
	file = {ScienceDirect Full Text PDF:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/CWDWXKAR/Pfurtscheller and Lopes da Silva - 1999 - Event-related EEGMEG synchronization and desynchr.pdf:application/pdf;ScienceDirect Snapshot:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/VQQZXZV7/S1388245799001418.html:text/html}
}

@article{samek_divergence-based_2014,
	title = {Divergence-{Based} {Framework} for {Common} {Spatial} {Patterns} {Algorithms}},
	volume = {7},
	issn = {1937-3333},
	url = {http://ieeexplore.ieee.org/xpls/icp.jsp?arnumber=6662468},
	doi = {10.1109/RBME.2013.2290621},
	abstract = {Controlling a device with a brain-computer interface requires extraction of relevant and robust features from high-dimensional electroencephalographic recordings. Spatial filtering is a crucial step in this feature extraction process. This paper reviews algorithms for spatial filter computation and introduces a general framework for this task based on divergence maximization. We show that the popular common spatial patterns (CSP) algorithm can be formulated as a divergence maximization problem and computed within our framework. Our approach easily permits enforcing different invariances and utilizing information from other subjects; thus, it unifies many of the recently proposed CSP variants in a principled manner. Furthermore, it allows to design novel spatial filtering algorithms by incorporating regularization schemes into the optimization process or applying other divergences. We evaluate the proposed approach using three regularization schemes, investigate the advantages of beta divergence, and show that subject-independent feature spaces can be extracted by jointly optimizing the divergence problems of multiple users. We discuss the relations to several CSP variants and investigate the advantages and limitations of our approach with simulations. Finally, we provide experimental results on a dataset containing recordings from 80 subjects and interpret the obtained patterns from a neurophysiological perspective.},
	journal = {Biomedical Engineering, IEEE Reviews in},
	author = {Samek, W. and Kawanabe, M. and Muller, K.-R.},
	year = {2014},
	keywords = {brain-computer interface, brain-computer interfaces, common spatial pattern algorithms, Covariance matrices, CSP, divergence-based framework, divergence maximization, Electrodes, electroencephalography, feature extraction, high-dimensional electroencephalographic recordings, information geometry, medical signal processing, neurophysiological perspective, neurophysiology, optimisation, Pattern recognition, regularization schemes, review algorithms, Robustness, spatial filter computation, spatial filtering algorithms, spatial filters, subject-independent feature spaces, Symmetric matrices},
	pages = {50--72},
	file = {IEEE Xplore Abstract Record:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/R8SEIV3C/icp.html:text/html}
}

@inproceedings{meng_automated_2009,
	title = {Automated selecting subset of channels based on {CSP} in motor imagery brain-computer interface system},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5420462},
	doi = {10.1109/ROBIO.2009.5420462},
	abstract = {The Common Spatial Pattern (CSP) algorithm is a popular method for efficiently calculating spatial filters. However, several previous studies show that CSP's performance deteriorates especially when the number of channels is large compared to small number of training datasets. As a result, it is necessary to choose an optimal subset of the whole channels to save computational time and retain high classification accuracy. In this paper, we propose a novel heuristic algorithm to select the optimal channels for CSP. The CSP procedure is applied to training datasets firstly and then a channel score based on l norm is defined for each channel. Finally, channels with larger scores are retained for further CSP processing. This approach utilizes CSP procedure twice to select channels and extract features, respectively; hence the complex optimization problem of channel selection for CSP is solved heuristically. We apply our method and other two existing methods to datasets from BCI competition 2005 for comparison and the experiment results show this method provides an effective way to accomplish the task of channel selection.},
	booktitle = {2009 {IEEE} {International} {Conference} on {Robotics} and {Biomimetics} ({ROBIO})},
	author = {Meng, Jianjun and Liu, Guangquan and Huang, Gan and Zhu, Xiangyang},
	month = dec,
	year = {2009},
	keywords = {automated selecting subset, Biomimetics, Brain computer interfaces, brain-computer interfaces, channel selection, common spatial pattern algorithm, complex optimization problem, CSP performance, Electrodes, electroencephalography, feature extraction, Greedy algorithms, heuristic algorithm, Heuristic algorithms, medical image processing, motor imagery brain-computer interface system, optimisation, Robotics and automation, Scalp, spatial filters},
	pages = {2290--2294},
	file = {IEEE Xplore Abstract Record:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/KQUWIS2I/abs_all.html:text/html;IEEE Xplore Full Text PDF:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/ERVHHVEP/Meng et al. - 2009 - Automated selecting subset of channels based on CS.pdf:application/pdf}
}

@article{blankertz_bci_2006,
	title = {The {BCI} competition {III}: validating alternative approaches to actual {BCI} problems},
	volume = {14},
	issn = {1534-4320},
	shorttitle = {The {BCI} competition {III}},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1642757},
	doi = {10.1109/TNSRE.2006.875642},
	abstract = {A brain-computer interface (BCI) is a system that allows its users to control external devices with brain activity. Although the proof-of-concept was given decades ago, the reliable translation of user intent into device control commands is still a major challenge. Success requires the effective interaction of two adaptive controllers: the user's brain, which produces brain activity that encodes intent, and the BCI system, which translates that activity into device control commands. In order to facilitate this interaction, many laboratories are exploring a variety of signal analysis techniques to improve the adaptation of the BCI system to the user. In the literature, many machine learning and pattern classification algorithms have been reported to give impressive results when applied to BCI data in offline analyses. However, it is more difficult to evaluate their relative value for actual online use. BCI data competitions have been organized to provide objective formal evaluations of alternative methods. Prompted by the great interest in the first two BCI Competitions, we organized the third BCI Competition to address several of the most difficult and important analysis problems in BCI research. The paper describes the data sets that were provided to the competitors and gives an overview of the results.},
	number = {2},
	journal = {IEEE Transactions on Neural Systems and Rehabilitation Engineering},
	author = {Blankertz, B. and Muller, K. and Krusienski, D.J. and Schalk, G. and Wolpaw, J.R. and Schlogl, A. and Pfurtscheller, G. and Millan, Jd.R. and Schroder, M. and Birbaumer, N.},
	month = jun,
	year = {2006},
	keywords = {Adaptive control, adaptive controllers, Algorithms, Augmentative communication, BCI, beta rhythm, Brain, brain activity, brain-computer interface, brain–computer interface (BCI), Brain computer interfaces, Classification algorithms, Communication Aids for Disabled, Control systems, Databases, Factual, device control commands, electroencephalography, electroencephalography (EEG), ERP, Evoked Potentials, handicapped aids, Humans, imagined hand movements, Laboratories, learning (artificial intelligence), machine learning, Machine learning algorithms, medical control systems, medical signal processing, mu rhythm, Neuromuscular Diseases, nonstationarity, P300, pattern classification, Programmable control, rehabilitation, Signal analysis, single-trial classification, slow cortical potentials, Software Validation, Technology Assessment, Biomedical, User-Computer Interface},
	pages = {153--159},
	file = {IEEE Xplore Abstract Record:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/BD8JMBTF/abs_all.html:text/html;IEEE Xplore Full Text PDF:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/I2FUUX3F/Blankertz et al. - 2006 - The BCI competition III validating alternative ap.pdf:application/pdf}
}

@article{pruszynski_reading_2015,
	title = {Reading the mind to move the body},
	volume = {348},
	issn = {0036-8075, 1095-9203},
	url = {http://www.sciencemag.org/content/348/6237/860},
	doi = {10.1126/science.aab3464},
	language = {en},
	number = {6237},
	urldate = {2015-08-21},
	journal = {Science},
	author = {Pruszynski, J. Andrew and Diedrichsen, Jörn},
	month = may,
	year = {2015},
	pmid = {25999491},
	pages = {860--861},
	file = {Full Text PDF:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/7TUEERTZ/Pruszynski and Diedrichsen - 2015 - Reading the mind to move the body.pdf:application/pdf;Snapshot:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/2QVZUMG4/860.html:text/html}
}

@article{yosinski_understanding_2015,
	title = {Understanding {Neural} {Networks} {Through} {Deep} {Visualization}},
	url = {http://arxiv.org/abs/1506.06579},
	abstract = {Recent years have produced great advances in training large, deep neural networks (DNNs), including notable successes in training convolutional neural networks (convnets) to recognize natural images. However, our understanding of how these models work, especially what computations they perform at intermediate layers, has lagged behind. Progress in the field will be further accelerated by the development of better tools for visualizing and interpreting neural nets. We introduce two such tools here. The first is a tool that visualizes the activations produced on each layer of a trained convnet as it processes an image or video (e.g. a live webcam stream). We have found that looking at live activations that change in response to user input helps build valuable intuitions about how convnets work. The second tool enables visualizing features at each layer of a DNN via regularized optimization in image space. Because previous versions of this idea produced less recognizable images, here we introduce several new regularization methods that combine to produce qualitatively clearer, more interpretable visualizations. Both tools are open source and work on a pre-trained convnet with minimal setup.},
	urldate = {2015-07-13},
	journal = {arXiv:1506.06579 [cs]},
	author = {Yosinski, Jason and Clune, Jeff and Nguyen, Anh and Fuchs, Thomas and Lipson, Hod},
	month = jun,
	year = {2015},
	note = {arXiv: 1506.06579},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Learning, Computer Science - Neural and Evolutionary Computing},
	annote = {Comment: 12 pages. To appear at ICML Deep Learning Workshop 2015},
	file = {arXiv\:1506.06579 PDF:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/F9EDEUQZ/Yosinski et al. - 2015 - Understanding Neural Networks Through Deep Visuali.pdf:application/pdf;arXiv.org Snapshot:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/7XVS2MAV/1506.html:text/html}
}

@inproceedings{santana_joint_2014,
	title = {Joint optimization of algorithmic suites for {EEG} analysis},
	url = {http://ieeexplore.ieee.org/xpls/icp.jsp?arnumber=6944253},
	doi = {10.1109/EMBC.2014.6944253},
	abstract = {Electroencephalogram (EEG) data analysis algorithms consist of multiple processing steps each with a number of free parameters. A joint optimization methodology can be used as a wrapper to fine-tune these parameters for the patient or application. This approach is inspired by deep learning neural network models, but differs because the processing layers for EEG are heterogeneous with different approaches used for processing space and time. Nonetheless, we treat the processing stages as a neural network and apply backpropagation to jointly optimize the parameters. This approach outperforms previous results on the BCI Competition II - dataset IV; additionally, it outperforms the common spatial patterns (CSP) algorithm on the BCI Competition III dataset IV. In addition, the optimized parameters in the architecture are still interpretable.},
	booktitle = {2014 36th {Annual} {International} {Conference} of the {IEEE} {Engineering} in {Medicine} and {Biology} {Society} ({EMBC})},
	author = {Santana, E. and Brockmeier, A.J. and Principe, J.C.},
	month = aug,
	year = {2014},
	keywords = {algorithmic suites, backpropagation, Band-pass filters, BCI Competition III dataset IV, Biological neural networks, common spatial patterns, CSP algorithm, data analysis, deep learning neural network models, EEG analysis, EEG data analysis algorithms, electroencephalogram, electroencephalography, free parameters, joint optimization, Joints, medical signal processing, multiple processing steps, neural nets, optimisation, optimized parameters, processing layers, Training},
	pages = {2997--3000},
	file = {IEEE Xplore Abstract Record:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/VJ7UM5UU/icp.html:text/html}
}

@incollection{ciresan_mitosis_2013,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Mitosis {Detection} in {Breast} {Cancer} {Histology} {Images} with {Deep} {Neural} {Networks}},
	copyright = {©2013 Springer-Verlag Berlin Heidelberg},
	isbn = {978-3-642-40762-8 978-3-642-40763-5},
	url = {http://link.springer.com/chapter/10.1007/978-3-642-40763-5_51},
	abstract = {We use deep max-pooling convolutional neural networks to detect mitosis in breast histology images. The networks are trained to classify each pixel in the images, using as context a patch centered on the pixel. Simple postprocessing is then applied to the network output. Our approach won the ICPR 2012 mitosis detection competition, outperforming other contestants by a significant margin.},
	language = {en},
	number = {8150},
	urldate = {2015-08-24},
	booktitle = {Medical {Image} {Computing} and {Computer}-{Assisted} {Intervention} – {MICCAI} 2013},
	publisher = {Springer Berlin Heidelberg},
	author = {Cireşan, Dan C. and Giusti, Alessandro and Gambardella, Luca M. and Schmidhuber, Jürgen},
	editor = {Mori, Kensaku and Sakuma, Ichiro and Sato, Yoshinobu and Barillot, Christian and Navab, Nassir},
	year = {2013},
	keywords = {Artificial Intelligence (incl. Robotics), Computer Graphics, Health Informatics, Image Processing and Computer Vision, Imaging / Radiology, Pattern recognition},
	pages = {411--418},
	file = {Full Text PDF:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/XSQZ2XFZ/Cireşan et al. - 2013 - Mitosis Detection in Breast Cancer Histology Image.pdf:application/pdf;Snapshot:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/W2SRIPZW/978-3-642-40763-5_51.html:text/html}
}

@article{fisher_use_1936,
	title = {The {Use} of {Multiple} {Measurements} in {Taxonomic} {Problems}},
	volume = {7},
	copyright = {1936 Blackwell Publishing Ltd/University College London},
	issn = {2050-1439},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1469-1809.1936.tb02137.x/abstract},
	doi = {10.1111/j.1469-1809.1936.tb02137.x},
	abstract = {The articles published by the Annals of Eugenics (1925–1954) have been made available online as an historical archive intended for scholarly use. The work of eugenicists was often pervaded by prejudice against racial, ethnic and disabled groups. The online publication of this material for scholarly research purposes is not an endorsement of those views nor a promotion of eugenics in any way.},
	language = {en},
	number = {2},
	urldate = {2015-08-19},
	journal = {Annals of Eugenics},
	author = {Fisher, R. A.},
	month = sep,
	year = {1936},
	pages = {179--188},
	file = {Full Text PDF:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/SUTPAKU9/Fisher - 1936 - The Use of Multiple Measurements in Taxonomic Prob.pdf:application/pdf;Snapshot:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/2JPJFWTA/abstract.html:text/html}
}

@article{nijboer_p300-based_2008,
	title = {A {P}300-based brain-computer interface for people with amyotrophic lateral sclerosis},
	volume = {119},
	issn = {1388-2457},
	doi = {10.1016/j.clinph.2008.03.034},
	abstract = {OBJECTIVE: The current study evaluates the efficacy of a P300-based brain-computer interface (BCI) communication device for individuals with advanced ALS.
METHODS: Participants attended to one cell of a N x N matrix while the N rows and N columns flashed randomly. Each cell of the matrix contained one character. Every flash of an attended character served as a rare event in an oddball sequence and elicited a P300 response. Classification coefficients derived using a stepwise linear discriminant function were applied to the data after each set of flashes. The character receiving the highest discriminant score was presented as feedback.
RESULTS: In Phase I, six participants used a 6 x 6 matrix on 12 separate days with a mean rate of 1.2 selections/min and mean online and offline accuracies of 62\% and 82\%, respectively. In Phase II, four participants used either a 6 x 6 or a 7 x 7 matrix to produce novel and spontaneous statements with a mean online rate of 2.1 selections/min and online accuracy of 79\%. The amplitude and latency of the P300 remained stable over 40 weeks.
CONCLUSIONS: Participants could communicate with the P300-based BCI and performance was stable over many months.
SIGNIFICANCE: BCIs could provide an alternative communication and control technology in the daily lives of people severely disabled by ALS.},
	language = {eng},
	number = {8},
	journal = {Clinical Neurophysiology: Official Journal of the International Federation of Clinical Neurophysiology},
	author = {Nijboer, F. and Sellers, E. W. and Mellinger, J. and Jordan, M. A. and Matuz, T. and Furdea, A. and Halder, S. and Mochty, U. and Krusienski, D. J. and Vaughan, T. M. and Wolpaw, J. R. and Birbaumer, N. and Kübler, A.},
	month = aug,
	year = {2008},
	pmid = {18571984},
	pmcid = {PMC2853977},
	keywords = {Adult, Aged, Amyotrophic Lateral Sclerosis, Brain, Discriminant analysis, electroencephalography, Event-Related Potentials, P300, Feedback, Psychological, Female, Humans, Male, Middle Aged, Pattern Recognition, Visual, Photic Stimulation, Reaction Time, User-Computer Interface},
	pages = {1909--1916}
}

@article{birbaumer_braincomputer_2007,
	title = {Brain–computer interfaces: communication and restoration of movement in paralysis},
	volume = {579},
	issn = {1469-7793},
	shorttitle = {Brain–computer interfaces},
	url = {http://onlinelibrary.wiley.com/doi/10.1113/jphysiol.2006.125633/abstract},
	doi = {10.1113/jphysiol.2006.125633},
	abstract = {The review describes the status of brain–computer or brain–machine interface research. We focus on non-invasive brain–computer interfaces (BCIs) and their clinical utility for direct brain communication in paralysis and motor restoration in stroke. A large gap between the promises of invasive animal and human BCI preparations and the clinical reality characterizes the literature: while intact monkeys learn to execute more or less complex upper limb movements with spike patterns from motor brain regions alone without concomitant peripheral motor activity usually after extensive training, clinical applications in human diseases such as amyotrophic lateral sclerosis and paralysis from stroke or spinal cord lesions show only limited success, with the exception of verbal communication in paralysed and locked-in patients. BCIs based on electroencephalographic potentials or oscillations are ready to undergo large clinical studies and commercial production as an adjunct or a major assisted communication device for paralysed and locked-in patients. However, attempts to train completely locked-in patients with BCI communication after entering the complete locked-in state with no remaining eye movement failed. We propose that a lack of contingencies between goal directed thoughts and intentions may be at the heart of this problem. Experiments with chronically curarized rats support our hypothesis; operant conditioning and voluntary control of autonomic physiological functions turned out to be impossible in this preparation. In addition to assisted communication, BCIs consisting of operant learning of EEG slow cortical potentials and sensorimotor rhythm were demonstrated to be successful in drug resistant focal epilepsy and attention deficit disorder. First studies of non-invasive BCIs using sensorimotor rhythm of the EEG and MEG in restoration of paralysed hand movements in chronic stroke and single cases of high spinal cord lesions show some promise, but need extensive evaluation in well-controlled experiments. Invasive BMIs based on neuronal spike patterns, local field potentials or electrocorticogram may constitute the strategy of choice in severe cases of stroke and spinal cord paralysis. Future directions of BCI research should include the regulation of brain metabolism and blood flow and electrical and magnetic stimulation of the human brain (invasive and non-invasive). A series of studies using BOLD response regulation with functional magnetic resonance imaging (fMRI) and near infrared spectroscopy demonstrated a tight correlation between voluntary changes in brain metabolism and behaviour.},
	language = {en},
	number = {3},
	urldate = {2016-04-27},
	journal = {The Journal of Physiology},
	author = {Birbaumer, Niels and Cohen, Leonardo G.},
	month = mar,
	year = {2007},
	pages = {621--636},
	file = {Full Text PDF:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/K7XCAER3/Birbaumer and Cohen - 2007 - Brain–computer interfaces communication and resto.pdf:application/pdf;Snapshot:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/2X8GNT94/abstract.html:text/html}
}

@article{nicolas-alonso_brain_2012,
	title = {Brain {Computer} {Interfaces}, a {Review}},
	volume = {12},
	issn = {1424-8220},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3304110/},
	doi = {10.3390/s120201211},
	abstract = {A brain-computer interface (BCI) is a hardware and software communications system that permits cerebral activity alone to control computers or external devices. The immediate goal of BCI research is to provide communications capabilities to severely disabled people who are totally paralyzed or ‘locked in’ by neurological neuromuscular disorders, such as amyotrophic lateral sclerosis, brain stem stroke, or spinal cord injury. Here, we review the state-of-the-art of BCIs, looking at the different steps that form a standard BCI: signal acquisition, preprocessing or signal enhancement, feature extraction, classification and the control interface. We discuss their advantages, drawbacks, and latest advances, and we survey the numerous technologies reported in the scientific literature to design each step of a BCI. First, the review examines the neuroimaging modalities used in the signal acquisition step, each of which monitors a different functional brain activity such as electrical, magnetic or metabolic activity. Second, the review discusses different electrophysiological control signals that determine user intentions, which can be detected in brain activity. Third, the review includes some techniques used in the signal enhancement step to deal with the artifacts in the control signals and improve the performance. Fourth, the review studies some mathematic algorithms used in the feature extraction and classification steps which translate the information in the control signals into commands that operate a computer or other device. Finally, the review provides an overview of various BCI applications that control a range of devices.},
	number = {2},
	urldate = {2016-04-27},
	journal = {Sensors (Basel, Switzerland)},
	author = {Nicolas-Alonso, Luis Fernando and Gomez-Gil, Jaime},
	month = jan,
	year = {2012},
	pmid = {22438708},
	pmcid = {PMC3304110},
	pages = {1211--1279},
	file = {PubMed Central Full Text PDF:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/IZRFC46U/Nicolas-Alonso and Gomez-Gil - 2012 - Brain Computer Interfaces, a Review.pdf:application/pdf}
}

@article{ang_brain-computer_2013,
	title = {Brain-{Computer} {Interface} in {Stroke} {Rehabilitation}},
	volume = {7},
	issn = {1976-4677},
	url = {http://koreascience.or.kr/journal/view.jsp?kj=E1EIKI&py=2013&vnc=v7n2&sp=139},
	doi = {10.5626/JCSE.2013.7.2.139},
	language = {en},
	number = {2},
	urldate = {2016-04-27},
	journal = {Journal of Computing Science and Engineering},
	author = {Ang, Kai Keng and Guan, Cuntai},
	month = jun,
	year = {2013},
	pages = {139--146}
}

@article{leeb_self-paced_2007,
	title = {Self-{Paced} ({Asynchronous}) {BCI} {Control} of a {Wheelchair} in {Virtual} {Environments}: {A} {Case} {Study} with a {Tetraplegic}},
	volume = {2007},
	issn = {1687-5265},
	shorttitle = {Self-{Paced} ({Asynchronous}) {BCI} {Control} of a {Wheelchair} in {Virtual} {Environments}},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2272302/},
	doi = {10.1155/2007/79642},
	abstract = {The aim of the present study was to demonstrate for the first time that brain waves can be used by
a tetraplegic to control movements of his wheelchair in virtual reality (VR). In this case study, the spinal
cord injured (SCI) subject was able to generate bursts of beta oscillations in the electroencephalogram
(EEG) by imagination of movements of his paralyzed feet. These beta oscillations were used for a self-paced
(asynchronous) brain-computer interface (BCI) control based on a single bipolar EEG recording.
The subject was placed inside a virtual street populated with avatars. The task was to “go” from avatar to avatar towards the end of the street, but to stop at each avatar and talk to them. In average, the
participant was able to successfully perform this asynchronous experiment with a performance of 90\%,
single runs up to 100\%.},
	urldate = {2016-04-27},
	journal = {Computational Intelligence and Neuroscience},
	author = {Leeb, Robert and Friedman, Doron and Müller-Putz, Gernot R. and Scherer, Reinhold and Slater, Mel and Pfurtscheller, Gert},
	year = {2007},
	pmid = {18368142},
	pmcid = {PMC2272302},
	file = {PubMed Central Full Text PDF:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/GFEAN2G3/Leeb et al. - 2007 - Self-Paced (Asynchronous) BCI Control of a Wheelch.pdf:application/pdf}
}

@article{galan_brain-actuated_2008,
	title = {A brain-actuated wheelchair: asynchronous and non-invasive {Brain}-computer interfaces for continuous control of robots},
	volume = {119},
	issn = {1388-2457},
	shorttitle = {A brain-actuated wheelchair},
	doi = {10.1016/j.clinph.2008.06.001},
	abstract = {OBJECTIVE: To assess the feasibility and robustness of an asynchronous and non-invasive EEG-based Brain-Computer Interface (BCI) for continuous mental control of a wheelchair.
METHODS: In experiment 1 two subjects were asked to mentally drive both a real and a simulated wheelchair from a starting point to a goal along a pre-specified path. Here we only report experiments with the simulated wheelchair for which we have extensive data in a complex environment that allows a sound analysis. Each subject participated in five experimental sessions, each consisting of 10 trials. The time elapsed between two consecutive experimental sessions was variable (from 1h to 2months) to assess the system robustness over time. The pre-specified path was divided into seven stretches to assess the system robustness in different contexts. To further assess the performance of the brain-actuated wheelchair, subject 1 participated in a second experiment consisting of 10 trials where he was asked to drive the simulated wheelchair following 10 different complex and random paths never tried before.
RESULTS: In experiment 1 the two subjects were able to reach 100\% (subject 1) and 80\% (subject 2) of the final goals along the pre-specified trajectory in their best sessions. Different performances were obtained over time and path stretches, what indicates that performance is time and context dependent. In experiment 2, subject 1 was able to reach the final goal in 80\% of the trials.
CONCLUSIONS: The results show that subjects can rapidly master our asynchronous EEG-based BCI to control a wheelchair. Also, they can autonomously operate the BCI over long periods of time without the need for adaptive algorithms externally tuned by a human operator to minimize the impact of EEG non-stationarities. This is possible because of two key components: first, the inclusion of a shared control system between the BCI system and the intelligent simulated wheelchair; second, the selection of stable user-specific EEG features that maximize the separability between the mental tasks.
SIGNIFICANCE: These results show the feasibility of continuously controlling complex robotics devices using an asynchronous and non-invasive BCI.},
	language = {eng},
	number = {9},
	journal = {Clinical Neurophysiology: Official Journal of the International Federation of Clinical Neurophysiology},
	author = {Galán, F. and Nuttin, M. and Lew, E. and Ferrez, P. W. and Vanacker, G. and Philips, J. and Millán, J. Del R.},
	month = sep,
	year = {2008},
	pmid = {18621580},
	keywords = {Brain, Brain Mapping, electroencephalography, Humans, Robotics, User-Computer Interface, Wheelchairs},
	pages = {2159--2169}
}

@article{millan_combining_2010,
	title = {Combining {Brain}–{Computer} {Interfaces} and {Assistive} {Technologies}: {State}-of-the-{Art} and {Challenges}},
	volume = {4},
	issn = {1662-4548},
	shorttitle = {Combining {Brain}–{Computer} {Interfaces} and {Assistive} {Technologies}},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2944670/},
	doi = {10.3389/fnins.2010.00161},
	abstract = {In recent years, new research has brought the field of electroencephalogram (EEG)-based brain–computer interfacing (BCI) out of its infancy and into a phase of relative maturity through many demonstrated prototypes such as brain-controlled wheelchairs, keyboards, and computer games. With this proof-of-concept phase in the past, the time is now ripe to focus on the development of practical BCI technologies that can be brought out of the lab and into real-world applications. In particular, we focus on the prospect of improving the lives of countless disabled individuals through a combination of BCI technology with existing assistive technologies (AT). In pursuit of more practical BCIs for use outside of the lab, in this paper, we identify four application areas where disabled individuals could greatly benefit from advancements in BCI technology, namely, “Communication and Control”, “Motor Substitution”, “Entertainment”, and “Motor Recovery”. We review the current state of the art and possible future developments, while discussing the main research issues in these four areas. In particular, we expect the most progress in the development of technologies such as hybrid BCI architectures, user–machine adaptation algorithms, the exploitation of users’ mental states for BCI reliability and confidence measures, the incorporation of principles in human–computer interaction (HCI) to improve BCI usability, and the development of novel BCI technology including better EEG devices.},
	urldate = {2016-04-27},
	journal = {Frontiers in Neuroscience},
	author = {Millán, J. d. R. and Rupp, R. and Müller-Putz, G. R. and Murray-Smith, R. and Giugliemma, C. and Tangermann, M. and Vidaurre, C. and Cincotti, F. and Kübler, A. and Leeb, R. and Neuper, C. and Müller, K.-R. and Mattia, D.},
	month = sep,
	year = {2010},
	pmid = {20877434},
	pmcid = {PMC2944670},
	file = {PubMed Central Full Text PDF:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/XR7KR79W/Millán et al. - 2010 - Combining Brain–Computer Interfaces and Assistive .pdf:application/pdf}
}

@article{meinel_pre-trial_2016,
	title = {Pre-{Trial} {EEG}-{Based} {Single}-{Trial} {Motor} {Performance} {Prediction} to {Enhance} {Neuroergonomics} for a {Hand} {Force} {Task}},
	url = {http://journal.frontiersin.org/article/10.3389/fnhum.2016.00170/full},
	doi = {10.3389/fnhum.2016.00170},
	abstract = {We propose a framework for building electrophysiological predictors of single-trial motor performance variations, exemplified for SVIPT, a sequential isometric force control task suitable for hand motor rehabilitation after stroke. Electroencephalogram (EEG) data of 20 subjects with mean age of 53 years was recorded prior to and during 400 trials of SVIPT. They were executed within a single session with the non-dominant left hand, while receiving continuous visual feedback of the produced force trajectories. The behavioral data showed strong trial-by-trial performance variations for five clinically relevant metrics, which accounted for reaction time as well as for the smoothness and precision of the produced force trajectory. 18 out of 20 tested subjects remained after preprocessing and entered offline analysis. Source Power Comodulation (SPoC) was applied on EEG data of a short time interval prior to the start of each SVIPT trial. For 11 subjects, SPoC revealed robust oscillatory EEG subspace components, whose bandpower activity are predictive for the performance of the upcoming trial. Since SPoC may overfit to non-informative subspaces, we propose to apply three selection criteria accounting for the meaningfulness of the features. Across all subjects, the obtained components were spread along the frequency spectrum and showed a variety of spatial activity patterns. Those containing the highest level of predictive information resided in and close to the alpha band. Their spatial patterns resemble topologies reported for visual attention processes as well as those of imagined or executed hand motor tasks. In summary, we identified subject-specific single predictors that explain up to 36\% of the performance fluctuations and may serve for enhancing neuroergonomics of motor rehabilitation scenarios.},
	urldate = {2016-04-27},
	journal = {Frontiers in Human Neuroscience},
	author = {Meinel, Andreas and Castaño-Candamil, Sebastián and Reis, Janine and Tangermann, Michael},
	year = {2016},
	keywords = {EEG, hand motor rehabilitation, isometric force modulation, oscillatory subspace, single-trial performance prediction, spatial filtering, trial-by-trial variability, visuomotor integration},
	pages = {170}
}

@article{munsinger_brain_2010,
	title = {Brain {Painting}: {First} {Evaluation} of a {New} {Brain}–{Computer} {Interface} {Application} with {ALS}-{Patients} and {Healthy} {Volunteers}},
	volume = {4},
	issn = {1662-4548},
	shorttitle = {Brain {Painting}},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2996245/},
	doi = {10.3389/fnins.2010.00182},
	abstract = {Brain–computer interfaces (BCIs) enable paralyzed patients to communicate; however, up to date, no creative expression was possible. The current study investigated the accuracy and user-friendliness of P300-Brain Painting, a new BCI application developed to paint pictures using brain activity only. Two different versions of the P300-Brain Painting application were tested: A colored matrix tested by a group of ALS-patients (n = 3) and healthy participants (n = 10), and a black and white matrix tested by healthy participants (n = 10). The three ALS-patients achieved high accuracies; two of them reaching above 89\% accuracy. In healthy subjects, a comparison between the P300-Brain Painting application (colored matrix) and the P300-Spelling application revealed significantly lower accuracy and P300 amplitudes for the P300-Brain Painting application. This drop in accuracy and P300 amplitudes was not found when comparing the P300-Spelling application to an adapted, black and white matrix of the P300-Brain Painting application. By employing a black and white matrix, the accuracy of the P300-Brain Painting application was significantly enhanced and reached the accuracy of the P300-Spelling application. ALS-patients greatly enjoyed P300-Brain Painting and were able to use the application with the same accuracy as healthy subjects. P300-Brain Painting enables paralyzed patients to express themselves creatively and to participate in the prolific society through exhibitions.},
	urldate = {2016-04-27},
	journal = {Frontiers in Neuroscience},
	author = {Münßinger, Jana I. and Halder, Sebastian and Kleih, Sonja C. and Furdea, Adrian and Raco, Valerio and Hösle, Adi and Kübler, Andrea},
	month = nov,
	year = {2010},
	pmid = {21151375},
	pmcid = {PMC2996245}
}

@article{wang_novel_2015,
	title = {A {Novel} {Audiovisual} {Brain}-{Computer} {Interface} and {Its} {Application} in {Awareness} {Detection}},
	volume = {5},
	issn = {2045-2322},
	url = {http://www.nature.com/articles/srep09962},
	doi = {10.1038/srep09962},
	urldate = {2016-04-27},
	journal = {Scientific Reports},
	author = {Wang, Fei and He, Yanbin and Pan, Jiahui and Xie, Qiuyou and Yu, Ronghao and Zhang, Rui and Li, Yuanqing},
	month = jun,
	year = {2015},
	pages = {9962}
}

@article{bouton_restoring_2016,
	title = {Restoring cortical control of functional movement in a human with quadriplegia},
	volume = {advance online publication},
	copyright = {© 2016 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	issn = {0028-0836},
	url = {http://www.nature.com/nature/journal/vaop/ncurrent/full/nature17435.html},
	doi = {10.1038/nature17435},
	abstract = {Millions of people worldwide suffer from diseases that lead to paralysis through disruption of signal pathways between the brain and the muscles. Neuroprosthetic devices are designed to restore lost function and could be used to form an electronic ‘neural bypass’ to circumvent disconnected pathways in the nervous system. It has previously been shown that intracortically recorded signals can be decoded to extract information related to motion, allowing non-human primates and paralysed humans to control computers and robotic arms through imagined movements. In non-human primates, these types of signal have also been used to drive activation of chemically paralysed arm muscles. Here we show that intracortically recorded signals can be linked in real-time to muscle activation to restore movement in a paralysed human. We used a chronically implanted intracortical microelectrode array to record multiunit activity from the motor cortex in a study participant with quadriplegia from cervical spinal cord injury. We applied machine-learning algorithms to decode the neuronal activity and control activation of the participant’s forearm muscles through a custom-built high-resolution neuromuscular electrical stimulation system. The system provided isolated finger movements and the participant achieved continuous cortical control of six different wrist and hand motions. Furthermore, he was able to use the system to complete functional tasks relevant to daily living. Clinical assessment showed that, when using the system, his motor impairment improved from the fifth to the sixth cervical (C5–C6) to the seventh cervical to first thoracic (C7–T1) level unilaterally, conferring on him the critical abilities to grasp, manipulate, and release objects. This is the first demonstration to our knowledge of successful control of muscle activation using intracortically recorded signals in a paralysed human. These results have significant implications in advancing neuroprosthetic technology for people worldwide living with the effects of paralysis.},
	language = {en},
	urldate = {2016-04-27},
	journal = {Nature},
	author = {Bouton, Chad E. and Shaikhouni, Ammar and Annetta, Nicholas V. and Bockbrader, Marcia A. and Friedenberg, David A. and Nielson, Dylan M. and Sharma, Gaurav and Sederberg, Per B. and Glenn, Bradley C. and Mysiw, W. Jerry and Morgan, Austin G. and Deogaonkar, Milind and Rezai, Ali R.},
	month = apr,
	year = {2016},
	file = {Full Text PDF:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/NE4QM2ND/Bouton et al. - 2016 - Restoring cortical control of functional movement .pdf:application/pdf;Snapshot:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/2N75WHT9/nature17435.html:text/html}
}

@article{stober_deep_2015,
	title = {Deep {Feature} {Learning} for {EEG} {Recordings}},
	url = {http://arxiv.org/abs/1511.04306},
	abstract = {We introduce and compare several strategies for learning discriminative features from electroencephalography (EEG) recordings using deep learning techniques. EEG data are generally only available in small quantities, they are high-dimensional with a poor signal-to-noise ratio, and there is considerable variability between individual subjects and recording sessions. Our proposed techniques specifically address these challenges for feature learning. Cross-trial encoding forces auto-encoders to focus on features that are stable across trials. Similarity-constraint encoders learn features that allow to distinguish between classes by demanding that two trials from the same class are more similar to each other than to trials from other classes. This tuple-based training approach is especially suitable for small datasets. Hydra-nets allow for separate processing pathways adapting to subsets of a dataset and thus combine the advantages of individual feature learning (better adaptation of early, low-level processing) with group model training (better generalization of higher-level processing in deeper layers). This way, models can, for instance, adapt to each subject individually to compensate for differences in spatial patterns due to anatomical differences or variance in electrode positions. The different techniques are evaluated using the publicly available OpenMIIR dataset of EEG recordings taken while participants listened to and imagined music.},
	urldate = {2016-04-27},
	journal = {arXiv:1511.04306 [cs]},
	author = {Stober, Sebastian and Sternin, Avital and Owen, Adrian M. and Grahn, Jessica A.},
	month = nov,
	year = {2015},
	note = {arXiv: 1511.04306},
	keywords = {Computer Science - Learning, Computer Science - Neural and Evolutionary Computing},
	annote = {Comment: submitted as conference paper for ICLR 2016},
	file = {arXiv\:1511.04306 PDF:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/4ZDWPU7J/Stober et al. - 2015 - Deep Feature Learning for EEG Recordings.pdf:application/pdf;arXiv.org Snapshot:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/4JJHGH63/1511.html:text/html}
}

@article{dahne_spoc:_2014,
	title = {{SPoC}: {A} novel framework for relating the amplitude of neuronal oscillations to behaviorally relevant parameters},
	volume = {86},
	issn = {1053-8119},
	shorttitle = {{SPoC}},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811913008483},
	doi = {10.1016/j.neuroimage.2013.07.079},
	abstract = {Previously, modulations in power of neuronal oscillations have been functionally linked to sensory, motor and cognitive operations. Such links are commonly established by relating the power modulations to specific target variables such as reaction times or task ratings. Consequently, the resulting spatio-spectral representation is subjected to neurophysiological interpretation. As an alternative, independent component analysis (ICA) or alternative decomposition methods can be applied and the power of the components may be related to the target variable. In this paper we show that these standard approaches are suboptimal as the first does not take into account the superposition of many sources due to volume conduction, while the second is unable to exploit available information about the target variable. To improve upon these approaches we introduce a novel (supervised) source separation framework called Source Power Comodulation (SPoC). SPoC makes use of the target variable in the decomposition process in order to give preference to components whose power comodulates with the target variable. We present two algorithms that implement the SPoC approach. Using simulations with a realistic head model, we show that the SPoC algorithms are able extract neuronal components exhibiting high correlation of power with the target variable. In this task, the SPoC algorithms outperform other commonly used techniques that are based on the sensor data or ICA approaches. Furthermore, using real electroencephalography (EEG) recordings during an auditory steady state paradigm, we demonstrate the utility of the SPoC algorithms by extracting neuronal components exhibiting high correlation of power with the intensity of the auditory input. Taking into account the results of the simulations and real EEG recordings, we conclude that SPoC represents an adequate approach for the optimal extraction of neuronal components showing coupling of power with continuously changing behaviorally relevant parameters.},
	urldate = {2016-06-20},
	journal = {NeuroImage},
	author = {Dähne, Sven and Meinecke, Frank C. and Haufe, Stefan and Höhne, Johannes and Tangermann, Michael and Müller, Klaus-Robert and Nikulin, Vadim V.},
	month = feb,
	year = {2014},
	keywords = {ASSEP, EEG, MEG, Oscillations, Source power comodulation, SPoC},
	pages = {111--122}
}

@article{lecun_deep_2015,
	title = {Deep learning},
	volume = {521},
	copyright = {© 2015 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	issn = {0028-0836},
	url = {http://www.nature.com/nature/journal/v521/n7553/full/nature14539.html},
	doi = {10.1038/nature14539},
	abstract = {Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech.},
	language = {en},
	number = {7553},
	urldate = {2016-05-11},
	journal = {Nature},
	author = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
	month = may,
	year = {2015},
	keywords = {Computer science, Mathematics and computing},
	pages = {436--444}
}

@article{bashivan_learning_2015,
	title = {Learning {Representations} from {EEG} with {Deep} {Recurrent}-{Convolutional} {Neural} {Networks}},
	url = {http://arxiv.org/abs/1511.06448},
	abstract = {One of the challenges in modeling cognitive events from electroencephalogram (EEG) data is finding representations that are invariant to inter- and intra-subject differences, as well as to inherent noise associated with such data. Herein, we propose a novel approach for learning such representations from multi-channel EEG time-series, and demonstrate its advantages in the context of mental load classification task. First, we transform EEG activities into a sequence of topology-preserving multi-spectral images, as opposed to standard EEG analysis techniques that ignore such spatial information. Next, we train a deep recurrent-convolutional network inspired by state-of-the-art video classification to learn robust representations from the sequence of images. The proposed approach is designed to preserve the spatial, spectral, and temporal structure of EEG which leads to finding features that are less sensitive to variations and distortions within each dimension. Empirical evaluation on the cognitive load classification task demonstrated significant improvements in classification accuracy over current state-of-the-art approaches in this field.},
	urldate = {2016-05-11},
	journal = {arXiv:1511.06448 [cs]},
	author = {Bashivan, Pouya and Rish, Irina and Yeasin, Mohammed and Codella, Noel},
	month = nov,
	year = {2015},
	note = {arXiv: 1511.06448},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Learning},
	annote = {Comment: To be published as a conference paper at ICLR 2016},
	file = {arXiv.org Snapshot:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/3RDXARZS/1511.html:text/html}
}

@inproceedings{heger_subject--subject_2013,
	title = {Subject-to-subject transfer for {CSP} based {BCIs}: {Feature} space transformation and decision-level fusion},
	shorttitle = {Subject-to-subject transfer for {CSP} based {BCIs}},
	doi = {10.1109/EMBC.2013.6610823},
	abstract = {Modern Brain Computer Interfaces (BCIs) usually require a calibration session to train a machine learning system before each usage. In general, such trained systems are highly specialized to the subject's characteristic activation patterns and cannot be used for other sessions or subjects. This paper presents a feature space transformation that transforms features generated using subject-specific spatial filters into a subject-independent feature space. The transformation can be estimated from little adaptation data of the subject. Furthermore, we combine three different Common Spatial Pattern based feature extraction approaches using decision-level fusion, which enables BCI use when little calibration data is available, but also outperformed the subject-dependent reference approaches for larger amounts of training data.},
	booktitle = {2013 35th {Annual} {International} {Conference} of the {IEEE} {Engineering} in {Medicine} and {Biology} {Society} ({EMBC})},
	author = {Heger, D. and Putze, F. and Herff, C. and Schultz, T.},
	month = jul,
	year = {2013},
	keywords = {Brain computer interfaces, brain-computer interfaces, calibration, common spatial patterns, decision-level fusion, electroencephalography, feature extraction, feature space transformation, learning (artificial intelligence), machine learning system, sensor fusion, spatial filters, subject-independent feature space, subject-specific spatial filters, subject-to-subject transfer, Testing, Training, Transforms},
	pages = {5614--5617},
	file = {IEEE Xplore Abstract Record:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/QJU7WU83/abs_all.html:text/html;IEEE Xplore Full Text PDF:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/A9P68KWS/Heger et al. - 2013 - Subject-to-subject transfer for CSP based BCIs Fe.pdf:application/pdf}
}

@article{krauledat_towards_2008,
	title = {Towards {Zero} {Training} for {Brain}-{Computer} {Interfacing}},
	volume = {3},
	issn = {1932-6203},
	url = {http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0002967},
	doi = {10.1371/journal.pone.0002967},
	abstract = {Electroencephalogram (EEG) signals are highly subject-specific and vary considerably even between recording sessions of the  same user  within the same experimental paradigm. This challenges a stable operation of Brain-Computer Interface (BCI) systems. The classical approach is to train users by neurofeedback to produce fixed stereotypical patterns of brain activity. In the machine learning approach, a widely adapted method for dealing with those variances is to record a so called calibration measurement on the beginning of each session in order to optimize spatial filters and classifiers specifically for each subject and each day. This adaptation of the system to the individual brain signature of each user relieves from the need of extensive user training. In this paper we suggest a new method that overcomes the requirement of these time-consuming calibration recordings for long-term BCI users. The method takes advantage of knowledge collected in previous sessions: By a novel technique, prototypical spatial filters are determined which have better generalization properties compared to single-session filters. In particular, they can be used in follow-up sessions without the need to recalibrate the system. This way the calibration periods can be dramatically shortened or even completely omitted for these ‘experienced’ BCI users. The feasibility of our novel approach is demonstrated with a series of online BCI experiments. Although performed without any calibration measurement at all, no loss of classification performance was observed.},
	number = {8},
	urldate = {2016-05-11},
	journal = {PLOS ONE},
	author = {Krauledat, Matthias and Tangermann, Michael and Blankertz, Benjamin and Müller, Klaus-Robert},
	month = aug,
	year = {2008},
	keywords = {Bandpass filters, Eigenvalues, electroencephalography, Instrument calibration, machine learning, Man-computer interface, Prototypes, Signal filtering},
	pages = {e2967},
	file = {Full Text PDF:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/K6P8XZM2/Krauledat et al. - 2008 - Towards Zero Training for Brain-Computer Interfaci.pdf:application/pdf;Snapshot:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/6CZE6NQQ/article.html:text/html}
}

@article{ramos-murguialday_brainmachine_2013,
	title = {Brain–machine interface in chronic stroke rehabilitation: {A} controlled study},
	volume = {74},
	copyright = {Copyright © 2013 American Neurological Association},
	issn = {1531-8249},
	shorttitle = {Brain–machine interface in chronic stroke rehabilitation},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/ana.23879/abstract},
	doi = {10.1002/ana.23879},
	abstract = {Objective

Chronic stroke patients with severe hand weakness respond poorly to rehabilitation efforts. Here, we evaluated efficacy of daily brain–machine interface (BMI) training to increase the hypothesized beneficial effects of physiotherapy alone in patients with severe paresis in a double-blind sham-controlled design proof of concept study.


Methods

Thirty-two chronic stroke patients with severe hand weakness were randomly assigned to 2 matched groups and participated in 17.8 ± 1.4 days of training rewarding desynchronization of ipsilesional oscillatory sensorimotor rhythms with contingent online movements of hand and arm orthoses (experimental group, n = 16). In the control group (sham group, n = 16), movements of the orthoses occurred randomly. Both groups received identical behavioral physiotherapy immediately following BMI training or the control intervention. Upper limb motor function scores, electromyography from arm and hand muscles, placebo–expectancy effects, and functional magnetic resonance imaging (fMRI) blood oxygenation level–dependent activity were assessed before and after intervention.


Results

A significant group × time interaction in upper limb (combined hand and modified arm) Fugl–Meyer assessment (cFMA) motor scores was found. cFMA scores improved more in the experimental than in the control group, presenting a significant improvement of cFMA scores (3.41 ± 0.563-point difference, p = 0.018) reflecting a clinically meaningful change from no activity to some in paretic muscles. cFMA improvements in the experimental group correlated with changes in fMRI laterality index and with paretic hand electromyography activity. Placebo–expectancy scores were comparable for both groups.


Interpretation

The addition of BMI training to behaviorally oriented physiotherapy can be used to induce functional improvements in motor function in chronic stroke patients without residual finger movements and may open a new door in stroke neurorehabilitation. ANN NEUROL 2013;74:100–108},
	language = {en},
	number = {1},
	urldate = {2016-05-11},
	journal = {Annals of Neurology},
	author = {Ramos-Murguialday, Ander and Broetz, Doris and Rea, Massimiliano and Läer, Leonhard and Yilmaz, Oezge and Brasil, Fabricio L. and Liberati, Giulia and Curado, Marco R. and Garcia-Cossio, Eliana and Vyziotis, Alexandros and Cho, Woosang and Agostini, Manuel and Soares, Ernesto and Soekadar, Surjo and Caria, Andrea and Cohen, Leonardo G. and Birbaumer, Niels},
	month = jul,
	year = {2013},
	pages = {100--108},
	file = {Full Text PDF:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/FB4AJ5VU/Ramos-Murguialday et al. - 2013 - Brain–machine interface in chronic stroke rehabili.pdf:application/pdf;Snapshot:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/BCNMZJA4/abstract\;jsessionid=1E9CDE7DDCA11DCDFD332FF7ACEE24ED.html:text/html}
}

@article{he_deep_2015,
	title = {Deep {Residual} {Learning} for {Image} {Recognition}},
	url = {http://arxiv.org/abs/1512.03385},
	abstract = {Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers---8x deeper than VGG nets but still having lower complexity. An ensemble of these residual nets achieves 3.57\% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28\% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC \& COCO 2015 competitions, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.},
	urldate = {2016-05-11},
	journal = {arXiv:1512.03385 [cs]},
	author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	month = dec,
	year = {2015},
	note = {arXiv: 1512.03385},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: Tech report},
	file = {arXiv.org Snapshot:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/2JMRVKR6/1512.html:text/html}
}

@misc{noauthor_ieee_nodate,
	title = {{IEEE} {Xplore} {Under} {Maintenance}},
	url = {https://ecopyright.ieee.org/xplore/down.html},
	urldate = {2016-05-11},
	file = {IEEE Xplore Under Maintenance:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/XEQVICXM/down.html:text/html}
}

@article{tangermann_review_2012-1,
	title = {Review of the {BCI} competition {IV}},
	volume = {6},
	url = {http://journal.frontiersin.org/article/10.3389/fnins.2012.00055/full},
	doi = {10.3389/fnins.2012.00055},
	abstract = {The BCI competition IV stands in the tradition of prior BCI competitions that aim to provide high quality neuroscientific data for open access to the scientific community. As experienced already in prior competitions not only scientists from the narrow field of BCI compete, but scholars with a broad variety of backgrounds and nationalities. They include high specialists as well as students. The goals of all BCI competitions have always been to challenge with respect to novel paradigms and complex data. We report on the following challenges: (1) asynchronous data, (2) synthetic, (3) multi-class continuous data, (4) session-to-session transfer, (5) directionally modulated MEG, (6) finger movements recorded by ECoG. As after past competitions, our hope is that winning entries may enhance the analysis methods of future BCIs.},
	urldate = {2016-06-20},
	journal = {Neuroprosthetics},
	author = {Tangermann, Michael and Müller, Klaus-Robert and Aertsen, Ad and Birbaumer, Niels and Braun, Christoph and Brunner, Clemens and Leeb, Robert and Mehring, Carsten and Miller, Kai J. and Mueller-Putz, Gernot and Nolte, Guido and Pfurtscheller, Gert and Preissl, Hubert and Schalk, Gerwin and Schlögl, Alois and Vidaurre, Carmen and Waldert, Stephan and Blankertz, Benjamin},
	year = {2012},
	keywords = {BCI, brain-computer interface, competition},
	pages = {55}
}

@article{ramoser_optimal_2000,
	title = {Optimal spatial filtering of single trial {EEG} during imagined hand movement},
	volume = {8},
	issn = {1063-6528},
	doi = {10.1109/86.895946},
	abstract = {The development of an electroencephalograph (EEG)-based brain-computer interface (BCI) requires rapid and reliable discrimination of EEG patterns, e.g., associated with imaginary movement. One-sided hand movement imagination results in EEG changes located at contra- and ipsilateral central areas. The authors demonstrate that spatial filters for multichannel EEG effectively extract discriminatory information from two populations of single-trial EEG, recorded during left- and right-hand movement imagery. The best classification results for three subjects are 90.8\%, 92.7\%, and 99.7\%. The spatial filters are estimated from a set of data by the method of common spatial patterns and reflect the specific activation of cortical areas. The method performs a weighting of the electrodes according to their importance for the classification task. The high recognition rates and computational simplicity make it a promising method for an EEG-based brain-computer interface},
	number = {4},
	journal = {IEEE Transactions on Rehabilitation Engineering},
	author = {Ramoser, H. and Muller-Gerking, J. and Pfurtscheller, G.},
	month = dec,
	year = {2000},
	keywords = {assistive communication, biomechanics, Biomedical informatics, Brain computer interfaces, Computer interfaces, contralateral central area, cortical areas activation, Data mining, EEG-based brain-computer interface, EEG classification, Electrodes, electrodes weighting, electroencephalography, event-related desynchronization, Filtering, Finite impulse response filter, handicapped aids, imagined hand movement, ipsilateral central area, left-hand movement imagery, medical signal processing, mu rhythm, optimal spatial filtering, Rhythm, right-hand movement imagery, single trial EEG, spatial filters},
	pages = {441--446}
}

@article{szegedy_rethinking_2015,
	title = {Rethinking the inception architecture for computer vision},
	url = {http://arxiv.org/abs/1512.00567},
	urldate = {2016-06-22},
	journal = {arXiv preprint arXiv:1512.00567},
	author = {Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jonathon and Wojna, Zbigniew},
	year = {2015}
}

@inproceedings{santana_joint_2014-1,
	title = {Joint optimization of algorithmic suites for {EEG} analysis},
	doi = {10.1109/EMBC.2014.6944253},
	abstract = {Electroencephalogram (EEG) data analysis algorithms consist of multiple processing steps each with a number of free parameters. A joint optimization methodology can be used as a wrapper to fine-tune these parameters for the patient or application. This approach is inspired by deep learning neural network models, but differs because the processing layers for EEG are heterogeneous with different approaches used for processing space and time. Nonetheless, we treat the processing stages as a neural network and apply backpropagation to jointly optimize the parameters. This approach outperforms previous results on the BCI Competition II - dataset IV; additionally, it outperforms the common spatial patterns (CSP) algorithm on the BCI Competition III dataset IV. In addition, the optimized parameters in the architecture are still interpretable.},
	booktitle = {2014 36th {Annual} {International} {Conference} of the {IEEE} {Engineering} in {Medicine} and {Biology} {Society}},
	author = {Santana, E. and Brockmeier, A. J. and Principe, J. C.},
	month = aug,
	year = {2014},
	keywords = {algorithmic suites, backpropagation, Band-pass filters, BCI Competition III dataset IV, Biological neural networks, common spatial patterns, CSP algorithm, data analysis, deep learning neural network models, EEG analysis, EEG data analysis algorithms, electroencephalogram, electroencephalography, free parameters, joint optimization, Joints, medical signal processing, multiple processing steps, neural nets, optimisation, optimized parameters, processing layers, Training},
	pages = {2997--3000}
}

@article{rouse_cortical_2013,
	title = {Cortical {Adaptation} to a {Chronic} {Micro}-{Electrocorticographic} {Brain} {Computer} {Interface}},
	volume = {33},
	issn = {0270-6474, 1529-2401},
	url = {http://www.jneurosci.org/content/33/4/1326},
	doi = {10.1523/JNEUROSCI.0271-12.2013},
	abstract = {Brain–computer interface (BCI) technology decodes neural signals in real time to control external devices. In this study, chronic epidural micro-electrocorticographic recordings were performed over primary motor (M1) and dorsal premotor (PMd) cortex of three macaque monkeys. The differential gamma-band amplitude (75–105 Hz) from two arbitrarily chosen 300 μm electrodes (one located over each cortical area) was used for closed-loop control of a one-dimensional BCI device. Each monkey rapidly learned over a period of days to successfully control the velocity of a computer cursor. While both cortical areas contributed to success on the BCI task, the control signals from M1 were consistently modulated more strongly than those from PMd. Additionally, we observe that gamma-band power during active BCI control is always above resting brain activity. This suggests that purposeful gamma-band modulation is an active process that is obtained through increased cortical activation.},
	language = {en},
	number = {4},
	urldate = {2016-06-20},
	journal = {The Journal of Neuroscience},
	author = {Rouse, Adam G. and Williams, Jordan J. and Wheeler, Jesse J. and Moran, Daniel W.},
	month = jan,
	year = {2013},
	pmid = {23345208},
	pages = {1326--1330}
}

@inproceedings{sakhavi_parallel_2015,
	title = {Parallel convolutional-linear neural network for motor imagery classification},
	doi = {10.1109/EUSIPCO.2015.7362882},
	abstract = {Deep learning, recently, has been successfully applied to image classification, object recognition and speech recognition. However, the benefits of deep learning and accompanying architectures have been largely unknown for BCI applications. In motor imagery-based BCI, an energy-based feature, typically after spatial filtering, is commonly used for classification. Although this feature corresponds to the estimate of event-related synchronization/desynchronization in the brain, it neglects energy dynamics which may contain valuable discriminative information. Because traditional classiication methods, such as SVM, cannot handle this dynamical property, we proposed an architecture that inputs a dynamic energy representation of EEG data and utilizes convolutional neural networks for classification. By combining this network with a static energy network, we saw a significant increase in performance. We evaluated the proposed method and compared with SVM on a multi-class motor imagery dataset (BCI competition dataset IV-2a). Our method outperforms SVM with static energy features significantly (p {\textless}; 0.01).},
	booktitle = {Signal {Processing} {Conference} ({EUSIPCO}), 2015 23rd {European}},
	author = {Sakhavi, S. and Guan, C. and Yan, S.},
	month = aug,
	year = {2015},
	keywords = {BCI competition dataset IV-2a, brain-computer interface, brain-computer interfaces, Computer architecture, convolution, Convolutional Neural Network, deep learning, dynamic energy representation, EEG, EEG data, electroencephalography, energy-based feature, energy dynamics, Europe, event-related synchronization-desynchronization, feature extraction, learning (artificial intelligence), medical signal processing, Motor Imagery, motor imagery-based BCI, motor imagery classification, multiclass motor imagery dataset, neural nets, parallel convolutional-linear neural network, signal classification, static energy network, Support vector machines, synchronisation},
	pages = {2736--2740}
}

@article{pfurtscheller_event-related_1977,
	title = {Event-related cortical desynchronization detected by power measurements of scalp {EEG}},
	volume = {42},
	issn = {0013-4694},
	abstract = {Changes in the background EEG activity occurring at the same time as visual and auditory evoked potentials, as well as during the interstimulus interval in a CNV paradigm were analysed in human subjects, using serial power measurements of overlapping EEG segments. The analysis was focused on the power of the rhythmic activity within the alpha band (RAAB power). A decrease in RAAB power occurring during these event-related phenomena was indicative of desynchronization. Phasic, i.e. short lasting, localised desynchronization was present during sensory stimulation, and also preceding the imperative signal and motor response (motor preactivation) in the CNV paradigm.},
	language = {eng},
	number = {6},
	journal = {Electroencephalography and Clinical Neurophysiology},
	author = {Pfurtscheller, G. and Aranibar, A.},
	month = jun,
	year = {1977},
	pmid = {67933},
	keywords = {Auditory Perception, Computers, Cortical Synchronization, electroencephalography, Evoked Potentials, Humans, Time Factors, Visual Perception},
	pages = {817--826}
}

@article{orsborn_creating_2013,
	title = {Creating new functional circuits for action via brain-machine interfaces},
	volume = {7},
	issn = {1662-5188},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3817362/},
	doi = {10.3389/fncom.2013.00157},
	abstract = {Brain-machine interfaces (BMIs) are an emerging technology with great promise for developing restorative therapies for those with disabilities. BMIs also create novel, well-defined functional circuits for action that are distinct from the natural sensorimotor apparatus. Closed-loop control of BMI systems can also actively engage learning and adaptation. These properties make BMIs uniquely suited to study learning of motor and non-physical, abstract skills. Recent work used motor BMIs to shed light on the neural representations of skill formation and motor adaptation. Emerging work in sensory BMIs, and other novel interface systems, also highlight the promise of using BMI systems to study fundamental questions in learning and sensorimotor control. This paper outlines the interpretation of BMIs as novel closed-loop systems and the benefits of these systems for studying learning. We review BMI learning studies, their relation to motor control, and propose future directions for this nascent field. Understanding learning in BMIs may both elucidate mechanisms of natural motor and abstract skill learning, and aid in developing the next generation of neuroprostheses.},
	urldate = {2016-06-20},
	journal = {Frontiers in Computational Neuroscience},
	author = {Orsborn, Amy L. and Carmena, Jose M.},
	month = nov,
	year = {2013},
	pmid = {24204342},
	pmcid = {PMC3817362}
}

@article{wolpaw_control_2004,
	title = {Control of a two-dimensional movement signal by a noninvasive brain-computer interface in humans},
	volume = {101},
	issn = {0027-8424},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC535103/},
	doi = {10.1073/pnas.0403504101},
	abstract = {Brain-computer interfaces (BCIs) can provide communication and control to people who are totally paralyzed. BCIs can use noninvasive or invasive methods for recording the brain signals that convey the user's commands. Whereas noninvasive BCIs are already in use for simple applications, it has been widely assumed that only invasive BCIs, which use electrodes implanted in the brain, can provide multidimensional movement control of a robotic arm or a neuroprosthesis. We now show that a noninvasive BCI that uses scalp-recorded electroencephalographic activity and an adaptive algorithm can provide humans, including people with spinal cord injuries, with multidimensional point-to-point movement control that falls within the range of that reported with invasive methods in monkeys. In movement time, precision, and accuracy, the results are comparable to those with invasive BCIs. The adaptive algorithm used in this noninvasive BCI identifies and focuses on the electroencephalographic features that the person is best able to control and encourages further improvement in that control. The results suggest that people with severe motor disabilities could use brain signals to operate a robotic arm or a neuroprosthesis without needing to have electrodes implanted in their brains.},
	number = {51},
	urldate = {2016-06-20},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	author = {Wolpaw, Jonathan R. and McFarland, Dennis J.},
	month = dec,
	year = {2004},
	pmid = {15585584},
	pmcid = {PMC535103},
	pages = {17849--17854}
}

@inproceedings{dosovitskiy_inverting_2016,
	title = {Inverting {Visual} {Representations} with {Convolutional} {Networks}},
	url = {http://cia.informatik.uni-freiburg.de//Publications/2016/DB16},
	booktitle = {{IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	author = {Dosovitskiy, Alexey and Brox, Thomas},
	year = {2016},
	note = {arXiv:1506.02753}
}

@phdthesis{samek_robust_2014,
	title = {On robust spatial filtering of {EEG} in nonstationary environments},
	url = {http://d-nb.info/1066547033/},
	urldate = {2016-06-08},
	school = {Berlin, Technische Universität Berlin, Diss., 2014},
	author = {Samek, Wojciech},
	year = {2014},
	file = {Snapshot:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/2NDEPG7J/opac.html:text/html}
}

@article{hammer_role_2013,
	title = {The role of {ECoG} magnitude and phase in decoding position, velocity, and acceleration during continuous motor behavior},
	volume = {7},
	issn = {1662-4548},
	doi = {10.3389/fnins.2013.00200},
	abstract = {In neuronal population signals, including the electroencephalogram (EEG) and electrocorticogram (ECoG), the low-frequency component (LFC) is particularly informative about motor behavior and can be used for decoding movement parameters for brain-machine interface (BMI) applications. An idea previously expressed, but as of yet not quantitatively tested, is that it is the LFC phase that is the main source of decodable information. To test this issue, we analyzed human ECoG recorded during a game-like, one-dimensional, continuous motor task with a novel decoding method suitable for unfolding magnitude and phase explicitly into a complex-valued, time-frequency signal representation, enabling quantification of the decodable information within the temporal, spatial and frequency domains and allowing disambiguation of the phase contribution from that of the spectral magnitude. The decoding accuracy based only on phase information was substantially (at least 2 fold) and significantly higher than that based only on magnitudes for position, velocity and acceleration. The frequency profile of movement-related information in the ECoG data matched well with the frequency profile expected when assuming a close time-domain correlate of movement velocity in the ECoG, e.g., a (noisy) "copy" of hand velocity. No such match was observed with the frequency profiles expected when assuming a copy of either hand position or acceleration. There was also no indication of additional magnitude-based mechanisms encoding movement information in the LFC range. Thus, our study contributes to elucidating the nature of the informative LFC of motor cortical population activity and may hence contribute to improve decoding strategies and BMI performance.},
	language = {eng},
	journal = {Frontiers in Neuroscience},
	author = {Hammer, Jiri and Fischer, Jörg and Ruescher, Johanna and Schulze-Bonhage, Andreas and Aertsen, Ad and Ball, Tonio},
	year = {2013},
	pmid = {24198757},
	pmcid = {PMC3814578},
	keywords = {brain-machine interfaces, continuous movement, Decoding, Fourier descriptors, low-frequency component, multiple linear regression, phase},
	pages = {200}
}

@misc{noauthor_review_nodate,
	title = {Review of the {BCI} {Competition} {IV}},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3396284/},
	urldate = {2016-05-30}
}

@article{abdel-hamid_convolutional_2014,
	title = {Convolutional {Neural} {Networks} for {Speech} {Recognition}},
	volume = {22},
	issn = {2329-9290},
	doi = {10.1109/TASLP.2014.2339736},
	abstract = {Recently, the hybrid deep neural network (DNN)-hidden Markov model (HMM) has been shown to significantly improve speech recognition performance over the conventional Gaussian mixture model (GMM)-HMM. The performance improvement is partially attributed to the ability of the DNN to model complex correlations in speech features. In this paper, we show that further error rate reduction can be obtained by using convolutional neural networks (CNNs). We first present a concise description of the basic CNN and explain how it can be used for speech recognition. We further propose a limited-weight-sharing scheme that can better model speech features. The special structure such as local connectivity, weight sharing, and pooling in CNNs exhibits some degree of invariance to small shifts of speech features along the frequency axis, which is important to deal with speaker and environment variations. Experimental results show that CNNs reduce the error rate by 6\%-10\% compared with DNNs on the TIMIT phone recognition and the voice search large vocabulary speech recognition tasks.},
	number = {10},
	journal = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},
	author = {Abdel-Hamid, O. and Mohamed, A. r and Jiang, H. and Deng, L. and Penn, G. and Yu, D.},
	month = oct,
	year = {2014},
	keywords = {complex correlations, convolution, convolutional neural networks, Gaussian mixture model, Gaussian processes, hidden Markov model, hidden Markov models, hybrid deep neural network, Limited Weight Sharing (LWS) scheme, limited-weight-sharing scheme, local connectivity, mixture models, neural nets, Neural networks, pooling, Speech, Speech recognition, Training, Vectors, weight sharing},
	pages = {1533--1545}
}

@inproceedings{sun_review_2014,
	title = {A review of adaptive feature extraction and classification methods for {EEG}-based brain-computer interfaces},
	doi = {10.1109/IJCNN.2014.6889525},
	abstract = {A brain-computer interface (BCI) is a system that allows its users to control external devices which are independent of peripheral nerves and muscles with brain activities. Electroencephalogram (EEG) signals are electrical signals collected from the scalp. They are frequently used in brain-computer interaction. However, EEG signals which change over time are highly non-stationary. One major challenge in current BCI research is how to extract features of time-varying EEG signals and classify the signals as accurately as possible. An effective BCI should be robust against and adaptive to the dynamic variations of brain activities. Adaptive learning in a BCI system, a rapidly developing application of machine learning, would be an effective approach to conquer the challenge. This paper reviews representative adaptive feature extraction and classification methods for EEG-based BCIs and further discusses some important open problems which can hopefully be useful to promote the research of the BCIs.},
	booktitle = {2014 {International} {Joint} {Conference} on {Neural} {Networks} ({IJCNN})},
	author = {Sun, S. and Zhou, J.},
	month = jul,
	year = {2014},
	keywords = {Adaptation models, Adaptive Classification, adaptive classification method, Adaptive Feature Extraction, adaptive feature extraction method, adaptive learning, Bayes methods, BCI, brain activities, brain-computer interface, brain-computer interfaces, Brain modeling, Covariance matrices, EEG-based brain-computer interfaces, electroencephalogram, electroencephalography, feature extraction, learning (artificial intelligence), machine learning, medical signal processing, signal classification, Support vector machines, time-varying EEG signals},
	pages = {1746--1753},
	file = {IEEE Xplore Abstract Record:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/VE9GVM6B/abs_all.html:text/html;IEEE Xplore Full Text PDF:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/IXT3MJJU/Sun and Zhou - 2014 - A review of adaptive feature extraction and classi.pdf:application/pdf}
}

@inproceedings{tonin_brain-controlled_2011,
	title = {Brain-controlled telepresence robot by motor-disabled people},
	doi = {10.1109/IEMBS.2011.6091049},
	abstract = {In this paper we present the first results of users with disabilities in mentally controlling a telepresence robot, a rather complex task as the robot is continuously moving and the user must control it for a long period of time (over 6 minutes) to go along the whole path. These two users drove the telepresence robot from their clinic more than 100 km away. Remarkably, although the patients had never visited the location where the telepresence robot was operating, they achieve similar performances to a group of four healthy users who were familiar with the environment. In particular, the experimental results reported in this paper demonstrate the benefits of shared control for brain-controlled telepresence robots. It allows all subjects (including novel BMI subjects as our users with disabilities) to complete a complex task in similar time and with similar number of commands to those required by manual control.},
	booktitle = {2011 {Annual} {International} {Conference} of the {IEEE} {Engineering} in {Medicine} and {Biology} {Society}},
	author = {Tonin, L. and Carlson, T. and Leeb, R. and Millán, J. del R.},
	month = aug,
	year = {2011},
	keywords = {brain-computer interfaces, brain-controlled telepresence robot, brain-machine interfaces, Disabled Persons, EEG, electroencephalography, Female, Humans, Male, Manuals, medical computing, medical robotics, Mobile robots, motor-disabled people, Navigation, neurophysiology, Robotics, Robot sensing systems, telerobotics, virtual reality, Wheelchairs},
	pages = {4227--4230},
	file = {IEEE Xplore Abstract Record:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/EZ3ASVSA/abs_all.html:text/html;IEEE Xplore Full Text PDF:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/HNE2APZN/Tonin et al. - 2011 - Brain-controlled telepresence robot by motor-disab.pdf:application/pdf}
}

@article{tu_subject_2012,
	title = {A subject transfer framework for {EEG} classification},
	volume = {82},
	issn = {0925-2312},
	url = {http://www.sciencedirect.com/science/article/pii/S0925231211007156},
	doi = {10.1016/j.neucom.2011.10.024},
	abstract = {This paper proposes a subject transfer framework for EEG classification. It aims to improve the classification performance when the training set of the target subject (namely user) is small owing to the need to reduce the calibration session. Our framework pursues improvement not only at the feature extraction stage, but also at the classification stage. At the feature extraction stage, we first obtain a candidate filter set for each subject through a previously proposed feature extraction method. Then, we design different criterions to learn two sparse subsets of the candidate filter set, which are called the robust filter bank and adaptive filter bank, respectively. Given robust and adaptive filter banks, at the classification step, we learn classifiers corresponding to these filter banks and employ a two-level ensemble strategy to dynamically and locally combine their outcomes to reach a single decision output. The proposed framework, as validated by experimental results, can achieve positive knowledge transfer for improving the performance of EEG classification.},
	urldate = {2016-05-11},
	journal = {Neurocomputing},
	author = {Tu, Wenting and Sun, Shiliang},
	month = apr,
	year = {2012},
	keywords = {EEG classification, Ensemble learning, Sparse representation, Transfer learning},
	pages = {109--116},
	file = {ScienceDirect Full Text PDF:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/TNSMHF5S/Tu and Sun - 2012 - A subject transfer framework for EEG classificatio.pdf:application/pdf;ScienceDirect Snapshot:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/7A2CQCTQ/S0925231211007156.html:text/html}
}

@article{klein_fast_2016,
	title = {Fast {Bayesian} {Optimization} of {Machine} {Learning} {Hyperparameters} on {Large} {Datasets}},
	url = {http://arxiv.org/abs/1605.07079},
	abstract = {Bayesian optimization has become a successful tool for hyperparameter optimization of machine learning algorithms, such as support vector machines or deep neural networks. But it is still costly if each evaluation of the objective requires training and validating the algorithm being optimized, which, for large datasets, often takes hours, days, or even weeks. To accelerate hyperparameter optimization, we propose a generative model for the validation error as a function of training set size, which is learned during the optimization process and allows exploration of preliminary configurations on small subsets, by extrapolating to the full dataset. We construct a Bayesian optimization procedure, dubbed FABOLAS, which models loss and training time as a function of dataset size and automatically trades off high information gain about the global optimum against computational cost. Experiments optimizing support vector machines and deep neural networks show that FABOLAS often finds high-quality solutions 10 to 100 times faster than other state-of-the-art Bayesian optimization methods.},
	urldate = {2016-06-20},
	journal = {arXiv:1605.07079 [cs, stat]},
	author = {Klein, Aaron and Falkner, Stefan and Bartels, Simon and Hennig, Philipp and Hutter, Frank},
	month = may,
	year = {2016},
	note = {arXiv: 1605.07079},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Learning, Statistics - Machine Learning}
}

@article{golub_braincomputer_2016,
	series = {Neurobiology of cognitive behavior},
	title = {Brain–computer interfaces for dissecting cognitive processes underlying sensorimotor control},
	volume = {37},
	issn = {0959-4388},
	url = {http://www.sciencedirect.com/science/article/pii/S095943881500183X},
	doi = {10.1016/j.conb.2015.12.005},
	abstract = {Sensorimotor control engages cognitive processes such as prediction, learning, and multisensory integration. Understanding the neural mechanisms underlying these cognitive processes with arm reaching is challenging because we currently record only a fraction of the relevant neurons, the arm has nonlinear dynamics, and multiple modalities of sensory feedback contribute to control. A brain–computer interface (BCI) is a well-defined sensorimotor loop with key simplifying advantages that address each of these challenges, while engaging similar cognitive processes. As a result, BCI is becoming recognized as a powerful tool for basic scientific studies of sensorimotor control. Here, we describe the benefits of BCI for basic scientific inquiries and review recent BCI studies that have uncovered new insights into the neural mechanisms underlying sensorimotor control.},
	urldate = {2016-05-29},
	journal = {Current Opinion in Neurobiology},
	author = {Golub, Matthew D and Chase, Steven M and Batista, Aaron P and Yu, Byron M},
	month = apr,
	year = {2016},
	pages = {53--58}
}

@article{wander_braincomputer_2014,
	series = {Theoretical and computational neuroscience},
	title = {Brain–computer interfaces: a powerful tool for scientific inquiry},
	volume = {25},
	issn = {0959-4388},
	shorttitle = {Brain–computer interfaces},
	url = {http://www.sciencedirect.com/science/article/pii/S0959438813002249},
	doi = {10.1016/j.conb.2013.11.013},
	abstract = {Brain–computer interfaces (BCIs) are devices that record from the nervous system, provide input directly to the nervous system, or do both. Sensory BCIs such as cochlear implants have already had notable clinical success and motor BCIs have shown great promise for helping patients with severe motor deficits. Clinical and engineering outcomes aside, BCIs can also be tremendously powerful tools for scientific inquiry into the workings of the nervous system. They allow researchers to inject and record information at various stages of the system, permitting investigation of the brain in vivo and facilitating the reverse engineering of brain function. Most notably, BCIs are emerging as a novel experimental tool for investigating the tremendous adaptive capacity of the nervous system.},
	urldate = {2016-06-20},
	journal = {Current Opinion in Neurobiology},
	author = {Wander, Jeremiah D and Rao, Rajesh PN},
	month = apr,
	year = {2014},
	pages = {70--75}
}

@article{sainath_deep_2015,
	series = {Special {Issue} on “{Deep} {Learning} of {Representations}”},
	title = {Deep {Convolutional} {Neural} {Networks} for {Large}-scale {Speech} {Tasks}},
	volume = {64},
	issn = {0893-6080},
	url = {http://www.sciencedirect.com/science/article/pii/S0893608014002007},
	doi = {10.1016/j.neunet.2014.08.005},
	abstract = {Convolutional Neural Networks (CNNs) are an alternative type of neural network that can be used to reduce spectral variations and model spectral correlations which exist in signals. Since speech signals exhibit both of these properties, we hypothesize that CNNs are a more effective model for speech compared to Deep Neural Networks (DNNs). In this paper, we explore applying CNNs to large vocabulary continuous speech recognition (LVCSR) tasks. First, we determine the appropriate architecture to make CNNs effective compared to DNNs for LVCSR tasks. Specifically, we focus on how many convolutional layers are needed, what is an appropriate number of hidden units, what is the best pooling strategy. Second, investigate how to incorporate speaker-adapted features, which cannot directly be modeled by CNNs as they do not obey locality in frequency, into the CNN framework. Third, given the importance of sequence training for speech tasks, we introduce a strategy to use ReLU+dropout during Hessian-free sequence training of CNNs. Experiments on 3 LVCSR tasks indicate that a CNN with the proposed speaker-adapted and ReLU+dropout ideas allow for a 12\%–14\% relative improvement in WER over a strong DNN system, achieving state-of-the art results in these 3 tasks.},
	urldate = {2016-06-20},
	journal = {Neural Networks},
	author = {Sainath, Tara N. and Kingsbury, Brian and Saon, George and Soltau, Hagen and Mohamed, Abdel-rahman and Dahl, George and Ramabhadran, Bhuvana},
	month = apr,
	year = {2015},
	keywords = {deep learning, Neural networks, Speech recognition},
	pages = {39--48}
}

@article{masc_review_2013,
	title = {A {Review} of {EEG}-{Based} {Brain}-{Computer} {Interfaces} as {Access} {Pathways} for {Individuals} with {Severe} {Disabilities}},
	volume = {25},
	issn = {1040-0435},
	url = {http://dx.doi.org/10.1080/10400435.2012.723298},
	doi = {10.1080/10400435.2012.723298},
	abstract = {Electroencephalography (EEG) is a non-invasive method for measuring brain activity and is a strong candidate for brain-computer interface (BCI) development. While BCIs can be used as a means of communication for individuals with severe disabilities, the majority of existing studies have reported BCI evaluations by able-bodied individuals. Considering the many differences in body functions and usage scenarios between individuals with disabilities and able-bodied individuals, involvement of the target population in BCI evaluation is necessary. In this review, 39 studies reporting EEG-oriented BCI assessment by individuals with disabilities were identified in the past decade. With respect to participant populations, a need for assessing BCI performance for the pediatric population with severe disabilities was identified as an important future direction. Acquiring a reliable communication pathway during early stages of development is crucial in avoiding learned helplessness in pediatric-onset disabilities. With respect to evaluation, augmenting traditional measures of system performance with those relating to contextual factors was recommended for realizing user-centered designs appropriate for integration in real-life. Considering indicators of user state and developing more effective training paradigms are recommended for future studies of BCI involving individuals with disabilities.},
	number = {2},
	urldate = {2016-05-14},
	journal = {Assistive Technology},
	author = {MASc, Saba Moghimi and PhD, Azadeh Kushki MASc and FRCPC, Anne Marie Guerguerian MD FAAP and PhD, Tom Chau MASc},
	month = apr,
	year = {2013},
	pmid = {23923692},
	pages = {99--110}
}

@article{lotte_review_2007,
	title = {A review of classification algorithms for {EEG}-based brain–computer interfaces},
	volume = {4},
	issn = {1741-2552},
	url = {http://stacks.iop.org/1741-2552/4/i=2/a=R01},
	doi = {10.1088/1741-2560/4/2/R01},
	abstract = {In this paper we review classification algorithms used to design brain–computer interface (BCI) systems based on electroencephalography (EEG). We briefly present the commonly employed algorithms and describe their critical properties. Based on the literature, we compare them in terms of performance and provide guidelines to choose the suitable classification algorithm(s) for a specific BCI.},
	language = {en},
	number = {2},
	urldate = {2016-05-11},
	journal = {Journal of Neural Engineering},
	author = {Lotte, F. and Congedo, M. and Lécuyer, A. and Lamarche, F. and Arnaldi, B.},
	year = {2007},
	pages = {R1},
	file = {IOP Full Text PDF:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/CRSPREI4/Lotte et al. - 2007 - A review of classification algorithms for EEG-base.pdf:application/pdf}
}

@inproceedings{heger_subject--subject_2013-1,
	title = {Subject-to-subject transfer for {CSP} based {BCIs}: {Feature} space transformation and decision-level fusion},
	shorttitle = {Subject-to-subject transfer for {CSP} based {BCIs}},
	doi = {10.1109/EMBC.2013.6610823},
	abstract = {Modern Brain Computer Interfaces (BCIs) usually require a calibration session to train a machine learning system before each usage. In general, such trained systems are highly specialized to the subject's characteristic activation patterns and cannot be used for other sessions or subjects. This paper presents a feature space transformation that transforms features generated using subject-specific spatial filters into a subject-independent feature space. The transformation can be estimated from little adaptation data of the subject. Furthermore, we combine three different Common Spatial Pattern based feature extraction approaches using decision-level fusion, which enables BCI use when little calibration data is available, but also outperformed the subject-dependent reference approaches for larger amounts of training data.},
	booktitle = {2013 35th {Annual} {International} {Conference} of the {IEEE} {Engineering} in {Medicine} and {Biology} {Society} ({EMBC})},
	author = {Heger, D. and Putze, F. and Herff, C. and Schultz, T.},
	month = jul,
	year = {2013},
	keywords = {Brain computer interfaces, brain-computer interfaces, calibration, common spatial patterns, decision-level fusion, electroencephalography, feature extraction, feature space transformation, learning (artificial intelligence), machine learning system, sensor fusion, spatial filters, subject-independent feature space, subject-specific spatial filters, subject-to-subject transfer, Testing, Training, Transforms},
	pages = {5614--5617},
	file = {IEEE Xplore Abstract Record:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/UBE63AU7/abs_all.html:text/html;IEEE Xplore Full Text PDF:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/48HTAV88/Heger et al. - 2013 - Subject-to-subject transfer for CSP based BCIs Fe.pdf:application/pdf}
}

@misc{dieleman_lasagne:_2015,
	title = {Lasagne: {First} release.},
	shorttitle = {Lasagne},
	url = {http://zenodo.org/record/27878},
	abstract = {core contributors, in alphabetical order:


Eric Battenberg (@ebattenberg)
Sander Dieleman (@benanne)
Daniel Nouri (@dnouri)
Eben Olson (@ebenolson)
Aäron van den Oord (@avdnoord)
Colin Raffel (@craffel)
Jan Schlüter (@f0k)
Søren Kaae Sønderby (@skaae)



extra contributors, in chronological order:


Daniel Maturana (@dimatura): documentation, cuDNN layers, LRN
Jonas Degrave (@317070): get\_all\_param\_values() fix
Jack Kelly (@JackKelly): help with recurrent layers
Gábor Takács (@takacsg84): support broadcastable parameters in lasagne.updates
Diogo Moitinho de Almeida (@diogo149): MNIST example fixes
Brian McFee (@bmcfee): MaxPool2DLayer fix
Martin Thoma (@MartinThoma): documentation
Jeffrey De Fauw (@JeffreyDF): documentation, ADAM fix
Michael Heilman (@mheilman): NonlinearityLayer, lasagne.random
Gregory Sanders (@instagibbs): documentation fix
Jon Crall (@erotemic): check for non-positive input shapes
Hendrik Weideman (@hjweide): set\_all\_param\_values() test, MaxPool2DCCLayer fix
Kashif Rasul (@kashif): ADAM simplification
Peter de Rivaz (@peterderivaz): documentation fix},
	urldate = {2016-06-20},
	author = {Dieleman, Sander and Heilman, Michael and Kelly, Jack and Thoma, Martin and Rasul, Dr Kashif and Battenberg, Eric and Weideman, Hendrik and Sønderby, Søren Kaae and instagibbs and Britefury and Raffel, Colin and Degrave, Jonas and peterderivaz and Jon and Fauw, Jeffrey De and diogo149 and Nouri, Daniel and Schlüter, Jan and Maturana, Daniel and CongLiu and Olson, Eben and McFee, Brian and takacsg84},
	month = aug,
	year = {2015},
	note = {DOI: 10.5281/zenodo.27878}
}

@inproceedings{ren_convolutional_2014,
	title = {Convolutional deep belief networks for feature extraction of {EEG} signal},
	doi = {10.1109/IJCNN.2014.6889383},
	abstract = {In recent years, deep learning approaches have been successfully used to learn hierarchical representations of image data, audio data etc. However, to our knowledge, these deep learning approaches have not been extensively studied for electroencephalographic (EEG) data. Considering the properties of EEG data, high-dimensional and multichannel, we applied convolutional deep belief networks to the feature learning of EEG data and evaluated it on the datasets from previous BCI competitions. Compared with other state-of-the-art feature extraction methods, the learned features using convolutional deep belief network have better performance.},
	booktitle = {2014 {International} {Joint} {Conference} on {Neural} {Networks} ({IJCNN})},
	author = {Ren, Y. and Wu, Y.},
	month = jul,
	year = {2014},
	keywords = {Accuracy, audio data, BCI competitions, belief networks, convolution, Convolutional codes, convolutional deep belief networks, data analysis, datasets, deep learning, deep learning approaches, EEG, EEG signal, electroencephalographic data, electroencephalography, feature extraction, feature extraction methods, feature learning, hierarchical representations, high-dimensional data, image data, learning (artificial intelligence), medical signal processing, multichannel data, Probabilistic logic, Training},
	pages = {2850--2853}
}

@article{moxon_brain-machine_2015,
	title = {Brain-machine interfaces beyond neuroprosthetics},
	volume = {86},
	issn = {1097-4199},
	doi = {10.1016/j.neuron.2015.03.036},
	abstract = {The field of invasive brain-machine interfaces (BMIs) is typically associated with neuroprosthetic applications aiming to recover loss of motor function. However, BMIs also represent a powerful tool to address fundamental questions in neuroscience. The observed subjects of BMI experiments can also be considered as indirect observers of their own neurophysiological activity, and the relationship between observed neurons and (artificial) behavior can be genuinely causal rather than indirectly correlative. These two characteristics defy the classical object-observer duality, making BMIs particularly appealing for investigating how information is encoded and decoded by neural circuits in real time, how this coding changes with physiological learning and plasticity, and how it is altered in pathological conditions. Within neuroengineering, BMI is like a tree that opens its branches into many traditional engineering fields, but also extends deep roots into basic neuroscience beyond neuroprosthetics.},
	language = {eng},
	number = {1},
	journal = {Neuron},
	author = {Moxon, Karen A. and Foffani, Guglielmo},
	month = apr,
	year = {2015},
	pmid = {25856486},
	keywords = {Animals, Brain, brain-computer interfaces, Humans, Neural Prostheses, Neurons},
	pages = {55--67}
}

@article{sermanet_overfeat:_2013,
	title = {{OverFeat}: {Integrated} {Recognition}, {Localization} and {Detection} using {Convolutional} {Networks}},
	shorttitle = {{OverFeat}},
	url = {http://arxiv.org/abs/1312.6229},
	abstract = {We present an integrated framework for using Convolutional Networks for classification, localization and detection. We show how a multiscale and sliding window approach can be efficiently implemented within a ConvNet. We also introduce a novel deep learning approach to localization by learning to predict object boundaries. Bounding boxes are then accumulated rather than suppressed in order to increase detection confidence. We show that different tasks can be learned simultaneously using a single shared network. This integrated framework is the winner of the localization task of the ImageNet Large Scale Visual Recognition Challenge 2013 (ILSVRC2013) and obtained very competitive results for the detection and classifications tasks. In post-competition work, we establish a new state of the art for the detection task. Finally, we release a feature extractor from our best model called OverFeat.},
	urldate = {2016-08-12},
	journal = {arXiv:1312.6229 [cs]},
	author = {Sermanet, Pierre and Eigen, David and Zhang, Xiang and Mathieu, Michael and Fergus, Rob and LeCun, Yann},
	month = dec,
	year = {2013},
	note = {arXiv: 1312.6229},
	keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@article{howard_improvements_2013,
	title = {Some {Improvements} on {Deep} {Convolutional} {Neural} {Network} {Based} {Image} {Classification}},
	url = {http://arxiv.org/abs/1312.5402},
	abstract = {We investigate multiple techniques to improve upon the current state of the art deep convolutional neural network based image classification pipeline. The techiques include adding more image transformations to training data, adding more transformations to generate additional predictions at test time and using complementary models applied to higher resolution images. This paper summarizes our entry in the Imagenet Large Scale Visual Recognition Challenge 2013. Our system achieved a top 5 classification error rate of 13.55\% using no external data which is over a 20\% relative improvement on the previous year's winner.},
	urldate = {2016-07-25},
	journal = {arXiv:1312.5402 [cs]},
	author = {Howard, Andrew G.},
	month = dec,
	year = {2013},
	note = {arXiv: 1312.5402},
	keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@article{ball_movement_2008-1,
	title = {Movement related activity in the high gamma range of the human {EEG}},
	volume = {41},
	issn = {1053-8119},
	doi = {10.1016/j.neuroimage.2008.02.032},
	abstract = {Electrocorticographic (ECoG) recordings obtained using intracranially implanted electrodes in epilepsy patients indicate that high gamma band (HGB) activity of sensorimotor cortex is focally increased during voluntary movement. These movement related HGB modulations may play an important role in sensorimotor cortex function. It is however currently not clear to what extent this type of neural activity can be detected using non-invasive electroencephalography (EEG) and how similar HGB responses in healthy human subjects are to those observed in epilepsy patients. Using the same arm reaching task, we have investigated spectral power changes both in intracranial ECoG recordings in epilepsy patients and in non-invasive EEG recordings optimized for detecting HGB activity in healthy subjects. Our results show a common HGB response pattern both in ECoG and EEG recorded above the sensorimotor cortex contralateral to the side of arm movement. In both cases, HGB activity increased around movement onset in the 60-90 Hz range and became most pronounced at reaching movement end. Additionally, we found EEG HGB activity above the frontal midline possibly generated by the anterior supplementary motor area (SMA), a region that was however not covered by the intracranial electrodes used in the present study. In summary, our findings show that HGB activity from human sensorimotor cortex can be non-invasively detected in healthy subjects using EEG, opening a new perspective for investigating the role of high gamma range neuronal activity both in function and dysfunction of the human cortical sensorimotor network.},
	language = {eng},
	number = {2},
	journal = {NeuroImage},
	author = {Ball, Tonio and Demandt, Evariste and Mutschler, Isabella and Neitzel, Eva and Mehring, Carsten and Vogt, Klaus and Aertsen, Ad and Schulze-Bonhage, Andreas},
	month = jun,
	year = {2008},
	pmid = {18424182},
	keywords = {Adult, Brain, Brain Mapping, electroencephalography, Epilepsy, Female, Humans, Male, Movement},
	pages = {302--310}
}

@inproceedings{hertel_deep_2015,
	title = {Deep convolutional neural networks as generic feature extractors},
	doi = {10.1109/IJCNN.2015.7280683},
	abstract = {Recognizing objects in natural images is an intricate problem involving multiple conflicting objectives. Deep convolutional neural networks, trained on large datasets, achieve convincing results and are currently the state-of-the-art approach for this task. However, the long time needed to train such deep networks is a major drawback. We tackled this problem by reusing a previously trained network. For this purpose, we first trained a deep convolutional network on the ILSVRC-12 dataset. We then maintained the learned convolution kernels and only retrained the classification part on different datasets. Using this approach, we achieved an accuracy of 67.68\% on CIFAR-100, compared to the previous state-of-the-art result of 65.43\%. Furthermore, our findings indicate that convolutional networks are able to learn generic feature extractors that can be used for different tasks.},
	booktitle = {2015 {International} {Joint} {Conference} on {Neural} {Networks} ({IJCNN})},
	author = {Hertel, L. and Barth, E. and Käster, T. and Martinetz, T.},
	month = jul,
	year = {2015},
	keywords = {Art, convolution, deep convolutional neural network, feature extraction, feature extractor, Handwriting recognition, image classification, Kernel, natural image classification, neural nets, object recognition},
	pages = {1--4}
}

@inproceedings{krizhevsky_imagenet_2012,
	title = {Imagenet classification with deep convolutional neural networks},
	url = {http://papers.nips.cc/paper/4824-imagenet-classification-w},
	urldate = {2016-07-25},
	booktitle = {Advances in neural information processing systems},
	author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
	year = {2012},
	pages = {1097--1105}
}

@book{nunez_electric_2006,
	title = {Electric fields of the brain: the neurophysics of {EEG}},
	publisher = {Oxford University Press, USA},
	author = {Nunez, Paul L and Srinivasan, Ramesh},
	year = {2006}
}

@article{canolty_high_2006,
	title = {High gamma power is phase-locked to theta oscillations in human neocortex},
	volume = {313},
	url = {http://science.sciencemag.org/content/313/5793/1626.short},
	number = {5793},
	urldate = {2017-01-09},
	journal = {Science},
	author = {Canolty, Ryan T. and Edwards, Erik and Dalal, Sarang S. and Soltani, Maryam and Nagarajan, Srikantan S. and Kirsch, Heidi E. and Berger, Mitchel S. and Barbaro, Nicholas M. and Knight, Robert T.},
	year = {2006},
	pages = {1626--1628}
}

@inproceedings{bergstra_making_2013,
	title = {Making a {Science} of {Model} {Search}: {Hyperparameter} {Optimization} in {Hundreds} of {Dimensions} for {Vision} {Architectures}},
	shorttitle = {Making a {Science} of {Model} {Search}},
	url = {http://jmlr.org/proceedings/papers/v28/bergstra13.html},
	urldate = {2016-12-21},
	author = {Bergstra, James and Yamins, Daniel and Cox, David},
	year = {2013},
	pages = {115--123}
}

@article{manor_convolutional_2015,
	title = {Convolutional {Neural} {Network} for {Multi}-{Category} {Rapid} {Serial} {Visual} {Presentation} {BCI}},
	volume = {9},
	doi = {10.3389/fncom.2015.00146},
	abstract = {Brain computer interfaces rely on machine learning (ML) algorithms to decode the brain's electrical activity into decisions. For example, in rapid serial visual presentation (RSVP) tasks, the subject is presented with a continuous stream of images containing rare target images among standard images, while the algorithm has to detect brain activity associated with target images. Here, we continue our previous work, presenting a deep neural network model for the use of single trial EEG classification in RSVP tasks. Deep neural networks have shown state of the art performance in computer vision and speech recognition and thus have great promise for other learning tasks, like classification of EEG samples. In our model, we introduce a novel spatio-temporal regularization for EEG data to reduce overfitting. We show improved classification performance compared to our earlier work on a five categories RSVP experiment. In addition, we compare performance on data from different sessions and validate the model on a public benchmark data set of a P300 speller task. Finally, we discuss the advantages of using neural network models compared to manually designing feature extraction algorithms.},
	language = {eng},
	journal = {Frontiers in Computational Neuroscience},
	author = {Manor, Ran and Geva, Amir B.},
	year = {2015},
	pmid = {26696875},
	pmcid = {PMC4667102},
	keywords = {Brain computer interface (BCI), convolutional neural networks, deep learning, electroencephalography (EEG), P300, rapid serial visual presentation (RSVP)},
	pages = {146}
}

@article{pfurtscheller_evaluation_1979,
	title = {Evaluation of event-related desynchronization ({ERD}) preceding and following voluntary self-paced movement},
	volume = {46},
	issn = {0013-4694},
	url = {http://www.sciencedirect.com/science/article/pii/0013469479900634},
	doi = {10.1016/0013-4694(79)90063-4},
	abstract = {A method of accurate storage and on-line preprocessing of an EEG signal, preceding and following a trigger signal, elicited by button pressing, is described. The method was used to study the changes occurring in the power of the rhythmic activity within the alpha band in central areas, during voluntary, self-paced movement in 10 normal humans.

A short-lasting decrease or phasic event-related desynchronization (ERD) of alpha power, representing mu activity, was observed in all 10 subjects.

During the 2 sec period preceding movement the phasic ERD was mostly bilateral, but larger prior to right than to left thumb movement. At onset and during the first second of execution of movement, the phasic ERD was mostly bilateral but predominant in ipsilateral areas. Preceding or during movement, maximum ERD was observed in most cases in central-vertex regions.},
	number = {2},
	urldate = {2017-01-09},
	journal = {Electroencephalography and Clinical Neurophysiology},
	author = {Pfurtscheller, G and Aranibar, A},
	month = feb,
	year = {1979},
	pages = {138--146}
}

@article{gadhoumi_seizure_2016,
	series = {Methods and {Models} in {Epilepsy} {Research}},
	title = {Seizure prediction for therapeutic devices: {A} review},
	volume = {260},
	issn = {0165-0270},
	shorttitle = {Seizure prediction for therapeutic devices},
	url = {http://www.sciencedirect.com/science/article/pii/S0165027015002277},
	doi = {10.1016/j.jneumeth.2015.06.010},
	abstract = {Research in seizure prediction has come a long way since its debut almost 4 decades ago. Early studies suffered methodological caveats leading to overoptimistic results and lack of statistical significance. The publication of guidelines addressing mainly the question of performance evaluation and statistical validation in seizure prediction helped revising the status of the field. While many studies failed to prove that above chance prediction is possible by applying these guidelines, other studies were successful. Methods based on EEG analysis using linear and nonlinear measures were reportedly successful in detecting preictal changes and using them to predict seizures above chance. In this review, we present a selection of studies in seizure prediction published in the last decade. The studies were selected based on the validity of the methods and the statistical significance of performance results. These results varied between studies and many showed acceptable levels of sensitivity and specificity that could be appealing for therapeutic devices. The relatively large prediction horizon and early preictal changes reported in most studies suggest that seizure prediction may work better in closed loop seizure control devices rather than as seizure advisory devices. The emergence of a large database of annotated long-term EEG recordings should help prospective assessment of prediction methods. Some questions remain to be addressed before large clinical trials involving seizure prediction can be carried out.},
	urldate = {2016-12-20},
	journal = {Journal of Neuroscience Methods},
	author = {Gadhoumi, Kais and Lina, Jean-Marc and Mormann, Florian and Gotman, Jean},
	month = feb,
	year = {2016},
	keywords = {Algorithms, Focal epilepsy, Intracerebral EEG, Seizure prediction, Statistical validation, Therapeutic devices},
	pages = {270--282}
}

@article{lawhern_eegnet:_2016,
	title = {{EEGNet}: {A} {Compact} {Convolutional} {Network} for {EEG}-based {Brain}-{Computer} {Interfaces}},
	shorttitle = {{EEGNet}},
	url = {http://arxiv.org/abs/1611.08024},
	abstract = {Objective: Brain-Computer Interface technologies (BCI) enable the direct communication between humans and computers by analyzing brain measurements, such as electroencephalography (EEG). These technologies have been applied to a variety of domains, including neuroprosthetic control and the monitoring of epileptic seizures. Existing BCI systems primarily use a priori knowledge of EEG features of interest to build machine learning models. Recently, convolutional networks have been used for automatic feature extraction of large image databases, where they have obtained state-of-the-art results. In this work we introduce EEGNet, a compact fully convolutional network for EEG-based BCIs developed using Deep Learning approaches. Methods: EEGNet is a 4-layer convolutional network that uses filter factorization for learning a compact representation of EEG time series. EEGNet is one of the smallest convolutional networks to date, having less than 2200 parameters for a binary classification. Results: We show state-of-the-art classification performance across four different BCI paradigms: P300 event-related potential, error-related negativity, movement-related cortical potential, and sensory motor rhythm, with as few as 500 EEG trials. We also show that adding more trials reduces the error variance of prediction rather than improving classification performance. Conclusion: We provide preliminary evidence suggesting that our model can be used with small EEG databases while improving upon the state-of-the-art performance across several tasks and across subjects. Significance: The EEGNet neural network architecture provides state-of-the-art performance across several tasks and across subjects, challenging the notion that large datasets are required to obtain optimal performance.},
	urldate = {2016-12-20},
	journal = {arXiv:1611.08024 [cs, q-bio, stat]},
	author = {Lawhern, Vernon J. and Solon, Amelia J. and Waytowich, Nicholas R. and Gordon, Stephen M. and Hung, Chou P. and Lance, Brent J.},
	month = nov,
	year = {2016},
	note = {arXiv: 1611.08024},
	keywords = {Computer Science - Learning, Quantitative Biology - Neurons and Cognition, Statistics - Machine Learning},
	annote = {Comment: Under review at IEEE Transactions on Biomedical Engineering}
}

@article{moghimi_review_2013,
	title = {A review of {EEG}-based brain-computer interfaces as access pathways for individuals with severe disabilities},
	volume = {25},
	issn = {1040-0435},
	doi = {10.1080/10400435.2012.723298},
	abstract = {Electroencephalography (EEG) is a non-invasive method for measuring brain activity and is a strong candidate for brain-computer interface (BCI) development. While BCIs can be used as a means of communication for individuals with severe disabilities, the majority of existing studies have reported BCI evaluations by able-bodied individuals. Considering the many differences in body functions and usage scenarios between individuals with disabilities and able-bodied individuals, involvement of the target population in BCI evaluation is necessary. In this review, 39 studies reporting EEG-oriented BCI assessment by individuals with disabilities were identified in the past decade. With respect to participant populations, a need for assessing BCI performance for the pediatric population with severe disabilities was identified as an important future direction. Acquiring a reliable communication pathway during early stages of development is crucial in avoiding learned helplessness in pediatric-onset disabilities. With respect to evaluation, augmenting traditional measures of system performance with those relating to contextual factors was recommended for realizing user-centered designs appropriate for integration in real-life. Considering indicators of user state and developing more effective training paradigms are recommended for future studies of BCI involving individuals with disabilities.},
	language = {eng},
	number = {2},
	journal = {Assistive technology: the official journal of RESNA},
	author = {Moghimi, Saba and Kushki, Azadeh and Guerguerian, Anne Marie and Chau, Tom},
	year = {2013},
	pmid = {23923692},
	keywords = {brain-computer interfaces, Communication Aids for Disabled, electroencephalography, Humans},
	pages = {99--110}
}

@inproceedings{sermanet_overfeat:_2014,
	title = {{OverFeat}: {Integrated} {Recognition}, {Localization} and {Detection} using {Convolutional} {Networks}},
	shorttitle = {{OverFeat}},
	url = {http://arxiv.org/abs/1312.6229},
	urldate = {2017-01-09},
	booktitle = {International {Conference} on {Learning} {Representations} ({ICLR} 2014)},
	publisher = {arXiv preprint arXiv:1312.6229},
	author = {Sermanet, Pierre and Eigen, David and Zhang, Xiang and Mathieu, Michael and Fergus, Rob and LeCun, Yann},
	year = {2014}
}

@article{mishkin_systematic_2016,
	title = {Systematic evaluation of {CNN} advances on the {ImageNet}},
	url = {http://arxiv.org/abs/1606.02228},
	abstract = {The paper systematically studies the impact of a range of recent advances in CNN architectures and learning methods on the object categorization (ILSVRC) problem. The evalution tests the influence of the following choices of the architecture: non-linearity (ReLU, ELU, maxout, compatibility with batch normalization), pooling variants (stochastic, max, average, mixed), network width, classifier design (convolutional, fully-connected, SPP), image pre-processing, and of learning parameters: learning rate, batch size, cleanliness of the data, etc. The performance gains of the proposed modifications are first tested individually and then in combination. The sum of individual gains is bigger than the observed improvement when all modifications are introduced, but the "deficit" is small suggesting independence of their benefits. We show that the use of 128x128 pixel images is sufficient to make qualitative conclusions about optimal network structure that hold for the full size Caffe and VGG nets. The results are obtained an order of magnitude faster than with the standard 224 pixel images.},
	urldate = {2017-01-09},
	journal = {arXiv:1606.02228 [cs]},
	author = {Mishkin, Dmytro and Sergievskiy, Nikolay and Matas, Jiri},
	month = jun,
	year = {2016},
	note = {arXiv: 1606.02228},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Learning, Computer Science - Neural and Evolutionary Computing},
	annote = {Comment: Submitted to CVIU Special Issue on Deep Learning. Updated dataset quality experiment}
}

@inproceedings{antoniades_deep_2016,
	title = {Deep learning for epileptic intracranial {EEG} data},
	doi = {10.1109/MLSP.2016.7738824},
	abstract = {Detection algorithms for electroencephalography (EEG) data typically employ handcrafted features that take advantage of the signal's specific properties. In the field of interictal epileptic discharge (IED) detection, the feature representation that provides optimal classification performance is still an unresolved issue. In this paper, we consider deep learning for automatic feature generation from epileptic intracranial EEG data in the time domain. Specifically, we consider convolutional neural networks (CNNs) in a subject independent fashion and demonstrate that meaningful features, representing IEDs are automatically learned. The resulting model achieves state of the art classification performance, provides insights for the different types of IEDs within the group, and is invariant to time differences between the IEDs. This study suggests that automatic feature generation via deep learning is suitable for IEDs and EEG in general.},
	booktitle = {2016 {IEEE} 26th {International} {Workshop} on {Machine} {Learning} for {Signal} {Processing} ({MLSP})},
	author = {Antoniades, A. and Spyrou, L. and Took, C. C. and Sanei, S.},
	month = sep,
	year = {2016},
	keywords = {automatic feature generation, Brain modeling, CNNs, convolution, convolutional neural networks, deep learning, EEG, EEG data, electroencephalography, electroencephalography data, Epilepsy, feature extraction, feature representation, IED detection, interictal epileptic discharge detection, Kernel, learning (artificial intelligence), machine learning, medical signal processing, neural nets, Neural networks, optimal classification performance, pattern classification},
	pages = {1--6}
}

@article{toro_event-related_1994,
	title = {Event-related desynchronization and movement-related cortical potentials on the {ECoG} and {EEG}},
	volume = {93},
	issn = {0013-4694},
	abstract = {Event-related desynchronization (ERD) 2.0 sec before and 1.0 sec after movement in the frequency bands of 8-10, 10-12, 12-20 and 20-30 Hz and movement-related cortical potentials (MRCPs) to self-paced movements were studied from subdural recordings over the central region in 3 patients, and from scalp-recorded EEGs in 20 normal volunteers. In direct cortical recordings, the peak ERD response and peak MRCP amplitude to self-paced finger movements were maximal over recording sites in the contralateral hand motor representations. The topography and time of onset of the ERD response to finger and foot movements suggest that the ERD responses in the 8-10 Hz and 10-12 Hz bands are more somatotopically restricted than the responses in the higher frequency bands. The power recovery and subsequent overshoot in the different frequency bands occurred in an orderly fashion with the faster frequencies recovering earlier. The ERD responses on the scalp-recorded EEGs were of lower magnitude and more widely distributed than those occurring on the subdural recordings. Across the population, there was no relation between the magnitude of the ERD response in any of the frequency bands studied and the peak amplitude of the negative slope (pNS') and the frontal peak of the motor potential (fpMP) of the MRCPs. MRCPs and ERD responses originate in similar cortical regions and share some common timing features, but the magnitude and spatial distribution of the two responses appear to be independent of each other, which suggests that the physiological mechanisms governing these two events are different and may represent different aspects of motor cortex activation. Differences in the timing and topographical features of the ERD responses in the various frequency bands also suggest a distinct functional significance for the various spectral components of the electrical activity in the motor cortex.},
	language = {eng},
	number = {5},
	journal = {Electroencephalography and Clinical Neurophysiology},
	author = {Toro, C. and Deuschl, G. and Thatcher, R. and Sato, S. and Kufta, C. and Hallett, M.},
	month = oct,
	year = {1994},
	pmid = {7525246},
	keywords = {Adult, Aged, Brain Mapping, Cortical Synchronization, Electric Stimulation, Evoked Potentials, Female, Humans, Male, Middle Aged, Motor Cortex, Movement, Psychomotor Performance},
	pages = {380--389}
}

@article{lapuschkin_lrp_2016,
	title = {The {LRP} {Toolbox} for {Artificial} {Neural} {Networks}},
	volume = {17},
	url = {http://www.jmlr.org/papers/v17/15-618.html},
	number = {114},
	urldate = {2017-01-17},
	journal = {Journal of Machine Learning Research},
	author = {Lapuschkin, Sebastian and Binder, Alexander and Montavon, Grégoire and Müller, Klaus-Robert and Samek, Wojciech},
	year = {2016},
	pages = {1--5}
}

@article{koles_spatial_1990,
	title = {Spatial patterns underlying population differences in the background {EEG}},
	volume = {2},
	issn = {0896-0267, 1573-6792},
	url = {http://link.springer.com/article/10.1007/BF01129656},
	doi = {10.1007/BF01129656},
	abstract = {SummaryA method is described which can be used to extract common spatial patterns underlying the EEGs from two human populations. These spatial patterns account, in the least-squares sense, maximally for the variance in the EEGs from one population and minimally for the variance in the other population and therefore would seem to be optimal for quantitatively discriminating between the individual EEGs in the two populations. By using this method, it is suggested that the problems associated with the more common approach to discriminating EEGs, significance probability mapping, can be avoided. The method is tested using EEGs from a population of normal subjects and using the EEGs from a population of patients with neurologic disorders. The results in most cases are excellent and the misclassification which occurs in some cases is attributed to the nonhomogeneity of the patient population particularly. The advantages of the method for feature selection, for automatically classifying the clinical EEG, and with respect to the reference-free nature of the selected features are discussed.},
	language = {en},
	number = {4},
	urldate = {2017-01-09},
	journal = {Brain Topography},
	author = {Koles, Zoltan J. and Lazar, Michael S. and Zhou, Steven Z.},
	month = jun,
	year = {1990},
	pages = {275--284}
}

@article{buzsaki_neuronal_2004,
	title = {Neuronal {Oscillations} in {Cortical} {Networks}},
	volume = {304},
	copyright = {American Association for the Advancement of Science},
	issn = {0036-8075, 1095-9203},
	url = {http://science.sciencemag.org/content/304/5679/1926},
	doi = {10.1126/science.1099745},
	abstract = {Clocks tick, bridges and skyscrapers vibrate, neuronal networks oscillate. Are neuronal oscillations an inevitable by-product, similar to bridge vibrations, or an essential part of the brain's design? Mammalian cortical neurons form behavior-dependent oscillating networks of various sizes, which span five orders of magnitude in frequency. These oscillations are phylogenetically preserved, suggesting that they are functionally relevant. Recent findings indicate that network oscillations bias input selection, temporally link neurons into assemblies, and facilitate synaptic plasticity, mechanisms that cooperatively support temporal representation and long-term consolidation of information.},
	language = {en},
	number = {5679},
	urldate = {2017-01-09},
	journal = {Science},
	author = {Buzsáki, György and Draguhn, Andreas},
	month = jun,
	year = {2004},
	pmid = {15218136},
	pages = {1926--1929}
}

@article{rivet_xdawn_2009,
	title = {{xDAWN} {Algorithm} to {Enhance} {Evoked} {Potentials}: {Application} to {Brain}-{Computer} {Interface}},
	volume = {56},
	issn = {0018-9294},
	shorttitle = {{xDAWN} {Algorithm} to {Enhance} {Evoked} {Potentials}},
	doi = {10.1109/TBME.2009.2012869},
	abstract = {A brain-computer interface (BCI) is a communication system that allows to control a computer or any other device thanks to the brain activity. The BCI described in this paper is based on the P300 speller BCI paradigm introduced by Farwell and Donchin. An unsupervised algorithm is proposed to enhance P300 evoked potentials by estimating spatial filters; the raw EEG signals are then projected into the estimated signal subspace. Data recorded on three subjects were used to evaluate the proposed method. The results, which are presented using a Bayesian linear discriminant analysis classifier, show that the proposed method is efficient and accurate.},
	number = {8},
	journal = {IEEE Transactions on Biomedical Engineering},
	author = {Rivet, B. and Souloumiac, A. and Attina, V. and Gibert, G.},
	month = aug,
	year = {2009},
	keywords = {Adult, Algorithms, Application software, Artificial Intelligence, Bayesian linear discriminant analysis classifier, Bayesian methods, Bayes methods, bioelectric potentials, Brain, brain activity, brain-computer interface, brain–computer interface (BCI), Brain computer interfaces, brain-computer interfaces, Communication system control, Computer interfaces, Control systems, EEG signal, electroencephalography, evoked potential, Evoked Potentials, Humans, Laboratories, Linear discriminant analysis, Male, Man-Machine Systems, medical disorders, medical signal processing, neuromuscular disorder, P300 speller, P300 speller BCI paradigm, signal classification, Signal Processing, Computer-Assisted, spatial enhancement, spatial filter, spatial filters, Stochastic processes, unsupervised algorithm, unsupervised learning, xDAWN algorithm},
	pages = {2035--2043}
}

@inproceedings{ribeiro_why_2016,
	title = {Why {Should} {I} {Trust} {You}?: {Explaining} the {Predictions} of {Any} {Classifier}},
	shorttitle = {Why {Should} {I} {Trust} {You}?},
	url = {http://dl.acm.org/citation.cfm?id=2939778},
	urldate = {2017-04-24},
	booktitle = {Proceedings of the 22nd {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} and {Data} {Mining}},
	publisher = {ACM},
	author = {Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
	year = {2016},
	pages = {1135--1144}
}

@article{quandt_single_2012,
	title = {Single trial discrimination of individual finger movements on one hand: {A} combined {MEG} and {EEG} study},
	volume = {59},
	issn = {1053-8119},
	shorttitle = {Single trial discrimination of individual finger movements on one hand},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811911013358},
	doi = {10.1016/j.neuroimage.2011.11.053},
	abstract = {It is crucial to understand what brain signals can be decoded from single trials with different recording techniques for the development of Brain–Machine Interfaces. A specific challenge for non-invasive recording methods are activations confined to small spatial areas on the cortex such as the finger representation of one hand. Here we study the information content of single trial brain activity in non-invasive MEG and EEG recordings elicited by finger movements of one hand. We investigate the feasibility of decoding which of four fingers of one hand performed a slight button press. With MEG we demonstrate reliable discrimination of single button presses performed with the thumb, the index, the middle or the little finger (average over all subjects and fingers 57\%, best subject 70\%, empirical guessing level: 25.1\%). EEG decoding performance was less robust (average over all subjects and fingers 43\%, best subject 54\%, empirical guessing level 25.1\%). Spatiotemporal patterns of amplitude variations in the time series provided best information for discriminating finger movements. Non-phase-locked changes of mu and beta oscillations were less predictive. Movement related high gamma oscillations were observed in average induced oscillation amplitudes in the MEG but did not provide sufficient information about the finger's identity in single trials. Importantly, pre-movement neuronal activity provided information about the preparation of the movement of a specific finger. Our study demonstrates the potential of non-invasive MEG to provide informative features for individual finger control in a Brain–Machine Interface neuroprosthesis.},
	number = {4},
	urldate = {2017-01-17},
	journal = {NeuroImage},
	author = {Quandt, F. and Reichert, C. and Hinrichs, H. and Heinze, H. J. and Knight, R. T. and Rieger, J. W.},
	month = feb,
	year = {2012},
	keywords = {Brain–Machine Interface, electroencephalography, Finger decoding, High-gamma oscillations, Magnetoencephalography, Motor Cortex},
	pages = {3316--3324}
}

@article{chatrian_blocking_1959,
	title = {The blocking of the rolandic wicket rhythm and some central changes related to movement},
	volume = {11},
	issn = {0013-4694},
	url = {http://www.sciencedirect.com/science/article/pii/0013469459900483},
	doi = {10.1016/0013-4694(59)90048-3},
	abstract = {Analysis of the 500 most recent scalp recordings made in the electroencephalographic laboratory at the Rochester (Minnesota) State Hospital has revealed the presence of a rolandic wicket (“en arceau”) rhythm in 18 persons.

Passive movements and reflex movements provoked blocking of the wicket rhythm. The interval between the beginning of the movement and the blocking was approximately the same for both types of movement. In comparison with the effect of passive movement, the blocking provoked by reflex movement was shorter and predominated more markedly on the contralateral hemisphere.

Blocking of the wicket rhythm was noted also in relation to spontaneous voluntary movements. When these were unilateral the blocking effect involved both central areas, usually the contralateral before the homolateral. The beginning of the contralateral blocking usually preceded the onset of the muscular contraction.

Blocking was observed also with movements on command. At first it had the characteristics of a generalized arousal; in succeeding tests it became limited to the wicket rhythm of the rolandic areas. The wicket blocking followed with a fairly constant short delay after the beginning of the spoken order and, depending on the duration of the order, was seen approximately simultaneously with or a varied time before the onset of the muscular contraction.

Tactile stimuli also produced bilateral blocking of wicket rhythm, with the stronger effect on the contralateral side.

Visual and mental activity were able to provoke some degree of wicket together with alpha blocking in accord with the level of attention required.

The mechanisms through which the above stimuli provoke the blocking of the wicket rhythm are discussed.},
	number = {3},
	urldate = {2016-12-21},
	journal = {Electroencephalography and Clinical Neurophysiology},
	author = {Chatrian, Gian Emilio and Petersen, Magnus C. and Lazarte, Jorge A.},
	month = aug,
	year = {1959},
	pages = {497--510}
}

@article{wilcoxon_individual_1945,
	title = {Individual {Comparisons} by {Ranking} {Methods}},
	volume = {1},
	issn = {0099-4987},
	url = {http://www.jstor.org/stable/3001968},
	doi = {10.2307/3001968},
	number = {6},
	urldate = {2017-01-09},
	journal = {Biometrics Bulletin},
	author = {Wilcoxon, Frank},
	year = {1945},
	pages = {80--83}
}

@article{stansbury_natural_2013,
	title = {Natural {Scene} {Statistics} {Account} for the {Representation} of {Scene} {Categories} in {Human} {Visual} {Cortex}},
	volume = {79},
	issn = {0896-6273},
	url = {http://www.cell.com/neuron/abstract/S0896-6273(13)00550-3},
	doi = {10.1016/j.neuron.2013.06.034},
	abstract = {During natural vision, humans categorize the scenes they encounter: an office, the beach, and so on. These categories are informed by knowledge of the way that objects co-occur in natural scenes. How does the human brain aggregate information about objects to represent scene categories? To explore this issue, we used statistical learning methods to learn categories that objectively capture the co-occurrence statistics of objects in a large collection of natural scenes. Using the learned categories, we modeled fMRI brain signals evoked in human subjects when viewing images of scenes. We find that evoked activity across much of anterior visual cortex is explained by the learned categories. Furthermore, a decoder based on these scene categories accurately predicts the categories and objects comprising novel scenes from brain activity evoked by those scenes. These results suggest that the human brain represents scene categories that capture the co-occurrence statistics of objects in the world.},
	language = {English},
	number = {5},
	urldate = {2016-12-20},
	journal = {Neuron},
	author = {Stansbury, Dustin E. and Naselaris, Thomas and Gallant, Jack L.},
	month = sep,
	year = {2013},
	pmid = {23932491},
	pages = {1025--1034}
}

@article{sturm_interpretable_2016,
	title = {Interpretable deep neural networks for single-trial {EEG} classification},
	volume = {274},
	issn = {0165-0270},
	url = {http://www.sciencedirect.com/science/article/pii/S0165027016302333},
	doi = {10.1016/j.jneumeth.2016.10.008},
	abstract = {Background
In cognitive neuroscience the potential of deep neural networks (DNNs) for solving complex classification tasks is yet to be fully exploited. The most limiting factor is that DNNs as notorious ‘black boxes’ do not provide insight into neurophysiological phenomena underlying a decision. Layer-wise relevance propagation (LRP) has been introduced as a novel method to explain individual network decisions.
New method
We propose the application of DNNs with LRP for the first time for EEG data analysis. Through LRP the single-trial DNN decisions are transformed into heatmaps indicating each data point's relevance for the outcome of the decision.
Results
DNN achieves classification accuracies comparable to those of CSP-LDA. In subjects with low performance subject-to-subject transfer of trained DNNs can improve the results. The single-trial LRP heatmaps reveal neurophysiologically plausible patterns, resembling CSP-derived scalp maps. Critically, while CSP patterns represent class-wise aggregated information, LRP heatmaps pinpoint neural patterns to single time points in single trials.
Comparison with existing method(s)
We compare the classification performance of DNNs to that of linear CSP-LDA on two data sets related to motor-imaginary BCI.
Conclusion
We have demonstrated that DNN is a powerful non-linear tool for EEG analysis. With LRP a new quality of high-resolution assessment of neural activity can be reached. LRP is a potential remedy for the lack of interpretability of DNNs that has limited their utility in neuroscientific applications. The extreme specificity of the LRP-derived heatmaps opens up new avenues for investigating neural activity underlying complex perception or decision-related processes.},
	urldate = {2017-02-21},
	journal = {Journal of Neuroscience Methods},
	author = {Sturm, Irene and Lapuschkin, Sebastian and Samek, Wojciech and Müller, Klaus-Robert},
	month = dec,
	year = {2016},
	keywords = {Brain–computer interfacing, Interpretability, Neural networks},
	pages = {141--145}
}

@article{kurth-nelson_fast_2016,
	title = {Fast {Sequences} of {Non}-spatial {State} {Representations} in {Humans}},
	volume = {91},
	issn = {1097-4199},
	doi = {10.1016/j.neuron.2016.05.028},
	abstract = {Fast internally generated sequences of neural representations are suggested to support learning and online planning. However, these sequences have only been studied in the context of spatial tasks and never in humans. Here, we recorded magnetoencephalography (MEG) while human subjects performed a novel non-spatial reasoning task. The task required selecting paths through a set of six visual objects. We trained pattern classifiers on the MEG activity elicited by direct presentation of the visual objects alone and tested these classifiers on activity recorded during periods when no object was presented. During these object-free periods, the brain spontaneously visited representations of approximately four objects in fast sequences lasting on the order of 120 ms. These sequences followed backward trajectories along the permissible paths in the task. Thus, spontaneous fast sequential representation of states can be measured non-invasively in humans, and these sequences may be a fundamental feature of neural computation across tasks.},
	language = {eng},
	number = {1},
	journal = {Neuron},
	author = {Kurth-Nelson, Zeb and Economides, Marcos and Dolan, Raymond J. and Dayan, Peter},
	month = jul,
	year = {2016},
	pmid = {27321922},
	pmcid = {PMC4942698},
	pages = {194--204}
}

@inproceedings{kingma_adam:_2014,
	title = {Adam: {A} {Method} for {Stochastic} {Optimization}},
	shorttitle = {Adam},
	url = {http://arxiv.org/abs/1412.6980},
	urldate = {2017-01-09},
	booktitle = {Proceedings of the 3rd {International} {Conference} on {Learning} {Representations} ({ICLR})},
	author = {Kingma, Diederik P. and Ba, Jimmy},
	year = {2014}
}

@article{gratton_dealing_1998,
	title = {Dealing with artifacts: {The} {EOG} contamination of the event-related brain potential},
	volume = {30},
	issn = {0743-3808, 1532-5970},
	shorttitle = {Dealing with artifacts},
	url = {http://link.springer.com/article/10.3758/BF03209415},
	doi = {10.3758/BF03209415},
	abstract = {Eye movements and blinks represent a major source of artifacts in the electroencephalogram (EEG) and event-related brain potentials (ERPs). The origin of this artifact is the large difference in potential that exists between the cornea and the retina. Eye movements and blinks produce shifts of the electric fields that propagate across the whole head and that can be several times larger than the activity generated by the brain. Ocular activity can be monitored by electrodes located near the eyes (electrooculogram, or EOG). The electric fields associated with eye movements and blinks are somewhat different. The simplest procedure for dealing with ocular artifacts is to eliminate trials on which EOG activity is detected (rejection). However, this technique may result in data loss and biased data samples, especially when one is comparing clinical populations or tasks involving large amounts of eye movements. Another approach involves estimation and correction of the ocular artifact on the EEG and ERP traces. Several techniques have been proposed. Some of them are reviewed in the present paper. Issues related to the accuracy of the various techniques, as well as other advantages and limitations, are also discussed. Finally, general guidelines for how to deal with ocular artifacts are proposed.},
	language = {en},
	number = {1},
	urldate = {2017-01-09},
	journal = {Behavior Research Methods, Instruments, \& Computers},
	author = {Gratton, Gabriele},
	month = mar,
	year = {1998},
	pages = {44--53}
}

@article{crone_functional_1998,
	title = {Functional mapping of human sensorimotor cortex with electrocorticographic spectral analysis. {II}. {Event}-related synchronization in the gamma band.},
	volume = {121},
	issn = {0006-8950},
	url = {https://academic.oup.com/brain/article/121/12/2301/371496/Functional-mapping-of-human-sensorimotor-cortex},
	doi = {10.1093/brain/121.12.2301},
	number = {12},
	urldate = {2017-01-17},
	journal = {Brain},
	author = {Crone, N. E. and Miglioretti, D. L. and Gordon, B. and Lesser, R. P.},
	month = dec,
	year = {1998},
	pages = {2301--2315}
}

@article{bach_pixel-wise_2015,
	title = {On {Pixel}-{Wise} {Explanations} for {Non}-{Linear} {Classifier} {Decisions} by {Layer}-{Wise} {Relevance} {Propagation}},
	volume = {10},
	issn = {1932-6203},
	url = {http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0130140},
	doi = {10.1371/journal.pone.0130140},
	abstract = {Understanding and interpreting classification decisions of automated image classification systems is of high value in many applications, as it allows to verify the reasoning of the system and provides additional information to the human expert. Although machine learning methods are solving very successfully a plethora of tasks, they have in most cases the disadvantage of acting as a black box, not providing any information about what made them arrive at a particular decision. This work proposes a general solution to the problem of understanding classification decisions by pixel-wise decomposition of nonlinear classifiers. We introduce a methodology that allows to visualize the contributions of single pixels to predictions for kernel-based classifiers over Bag of Words features and for multilayered neural networks. These pixel contributions can be visualized as heatmaps and are provided to a human expert who can intuitively not only verify the validity of the classification decision, but also focus further analysis on regions of potential interest. We evaluate our method for classifiers trained on PASCAL VOC 2009 images, synthetic image data containing geometric shapes, the MNIST handwritten digits data set and for the pre-trained ImageNet model available as part of the Caffe open source package.},
	number = {7},
	urldate = {2017-01-09},
	journal = {PLOS ONE},
	author = {Bach, Sebastian and Binder, Alexander and Montavon, Grégoire and Klauschen, Frederick and Müller, Klaus-Robert and Samek, Wojciech},
	month = jul,
	year = {2015},
	keywords = {Algorithms, Coding mechanisms, Imaging techniques, Kernel functions, Kernel methods, Neural networks, Neurons, Vision},
	pages = {e0130140}
}

@article{yang_use_2015,
	title = {On the use of convolutional neural networks and augmented {CSP} features for multi-class motor imagery of {EEG} signals classification},
	volume = {2015},
	issn = {1557-170X},
	doi = {10.1109/EMBC.2015.7318929},
	abstract = {Learning the deep structures and unknown correlations is important for the detection of motor imagery of EEG signals (MI-EEG). This study investigates the use of convolutional neural networks (CNNs) for the classification of multi-class MI-EEG signals. Augmented common spatial pattern (ACSP) features are generated based on pair-wise projection matrices, which covers various frequency ranges. We propose a frequency complementary feature map selection (FCMS) scheme by constraining the dependency among frequency bands. Experiments are conducted on BCI competition IV dataset IIa with 9 subjects. Averaged cross-validation accuracy of 68.45\% and 69.27\% is achieved for FCMS and all feature maps, respectively, which is significantly higher (4.53\% and 5.34\%) than random map selection and higher (1.44\% and 2.26\%) than filter-bank CSP (FBCSP). The results demonstrate that the CNNs are capable of learning discriminant, deep structure features for EEG classification without relying on the handcrafted features.},
	language = {eng},
	journal = {Conference proceedings: ... Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engineering in Medicine and Biology Society. Annual Conference},
	author = {Yang, Huijuan and Sakhavi, Siavash and Ang, Kai Keng and Guan, Cuntai},
	year = {2015},
	pmid = {26736829},
	keywords = {Algorithms, Electrodes, electroencephalography, Humans, Movement, Neural Networks (Computer), Signal Processing, Computer-Assisted},
	pages = {2620--2623}
}

@inproceedings{liang_predicting_2016,
	title = {Predicting {Seizures} from {Electroencephalography} {Recordings}: {A} {Knowledge} {Transfer} {Strategy}},
	shorttitle = {Predicting {Seizures} from {Electroencephalography} {Recordings}},
	doi = {10.1109/ICHI.2016.27},
	abstract = {Epilepsy, a brain disorder afflicts nearly 1\% of the world's population, is characterized by the occurrence of spontaneous seizures. For most epilepsy patients, the drugs are either not effective or produce severe side-effects. Seizure forecasting systems have the potential to help patients with epilepsy lead more normal lives. Recently multi-center clinical studies showed evidence of premonitory symptoms in 6.2\% of 500 patients with epilepsy, and some interviews of epilepsy patients also found that a certain amount of patients felt "auras". All these are promising signs suggesting that seizure might be predictable. In this paper, we will study the application of deep learning techniques for seizure prediction with EEG signals. Deep learning methods have been shown to be very effective on exploring the latent structures from continuous signals and they have achieved state-of-the-art performance on speech analysis. One potential requirement for deep learning algorithms to work is a huge training set, which could be difficult for a specific medical problem. Therefore we specifically investigated a transfer learning strategy: we performed the major seizure prediction task on the data from American Epilepsy Society Seizure Prediction Challenge1, and we adopted another 6 publicly available EEG datasets2, which are not directly related to seizure prediction, as auxiliary information to pre-train the deep neural network for getting a good initial point. Our results show that with those auxiliary information, the prediction performance can be boosted. This observation is validated with different predictive models, which opens another gate for effective integration and utilization of medical data resources.},
	booktitle = {2016 {IEEE} {International} {Conference} on {Healthcare} {Informatics} ({ICHI})},
	author = {Liang, J. and Lu, R. and Zhang, C. and Wang, F.},
	month = oct,
	year = {2016},
	keywords = {American Epilepsy Society Seizure Prediction Challenge, Brain, brain disorder, Brain models, deep learning techniques, deep neural network pretraining, EEG datasets, EEG signals, electroencephalography, electroencephalography recordings, Epilepsy, epilepsy patients, feature extraction, knowledge management, knowledge transfer strategy, learning (artificial intelligence), machine learning, medical data resource utilization, medical disorders, medical signal processing, neural nets, Seizure prediction, speech analysis, spontaneous seizures, Training, transfer learning strategy},
	pages = {184--191}
}

@inproceedings{ren_convolutional_2014-1,
	title = {Convolutional deep belief networks for feature extraction of {EEG} signal},
	url = {http://ieeexplore.ieee.org/document/6889383/},
	doi = {10.1109/IJCNN.2014.6889383},
	abstract = {In recent years, deep learning approaches have been successfully used to learn hierarchical representations of image data, audio data etc. However, to our knowledge, these deep learning approaches have not been extensively studied for electroencephalographic (EEG) data. Considering the properties of EEG data, high-dimensional and multichannel, we applied convolutional deep belief networks to the feature learning of EEG data and evaluated it on the datasets from previous BCI competitions. Compared with other state-of-the-art feature extraction methods, the learned features using convolutional deep belief network have better performance.},
	booktitle = {2014 {International} {Joint} {Conference} on {Neural} {Networks} ({IJCNN})},
	author = {Ren, Y. and Wu, Y.},
	month = jul,
	year = {2014},
	keywords = {Accuracy, audio data, BCI competitions, belief networks, convolution, Convolutional codes, convolutional deep belief networks, data analysis, datasets, deep learning, deep learning approaches, EEG, EEG signal, electroencephalographic data, electroencephalography, feature extraction, feature extraction methods, feature learning, hierarchical representations, high-dimensional data, image data, learning (artificial intelligence), medical signal processing, multichannel data, Probabilistic logic, Training},
	pages = {2850--2853}
}

@article{schalk_bci2000:_2004,
	title = {{BCI}2000: a general-purpose brain-computer interface ({BCI}) system},
	volume = {51},
	issn = {0018-9294},
	shorttitle = {{BCI}2000},
	doi = {10.1109/TBME.2004.827072},
	abstract = {Many laboratories have begun to develop brain-computer interface (BCI) systems that provide communication and control capabilities to people with severe motor disabilities. Further progress and realization of practical applications depends on systematic evaluations and comparisons of different brain signals, recording methods, processing algorithms, output formats, and operating protocols. However, the typical BCI system is designed specifically for one particular BCI method and is, therefore, not suited to the systematic studies that are essential for continued progress. In response to this problem, we have developed a documented general-purpose BCI research and development platform called BCI2000. BCI2000 can incorporate alone or in combination any brain signals, signal processing methods, output devices, and operating protocols. This report is intended to describe to investigators, biomedical engineers, and computer scientists the concepts that the BCI2000 system is based upon and gives examples of successful BCI implementations using this system. To date, we have used BCI2000 to create BCI systems for a variety of brain signals, processing methods, and applications. The data show that these systems function well in online operation and that BCI2000 satisfies the stringent real-time requirements of BCI systems. By substantially reducing labor and cost, BCI2000 facilitates the implementation of different BCI systems and other psychophysiological experiments. It is available with full documentation and free of charge for research or educational purposes and is currently being used in a variety of studies by many research groups.},
	number = {6},
	journal = {IEEE Transactions on Biomedical Engineering},
	author = {Schalk, G. and McFarland, D. J. and Hinterberger, T. and Birbaumer, N. and Wolpaw, J. R.},
	month = jun,
	year = {2004},
	keywords = {Algorithms, assistive devices, Augmentative communication, BCI2000, bioelectric potentials, Biomedical engineering, Biomedical signal processing, Brain, Brain computer interfaces, brain signals, Cognition, Communication Aids for Disabled, Communication system control, Computer Peripherals, Control systems, diseases, ECoG, EEG, electroencephalography, Equipment Design, Equipment Failure Analysis, Evoked Potentials, general-purpose brain-computer interface system, handicapped aids, Humans, Laboratories, medical signal processing, operating protocols, output devices, patient rehabilitation, Protocols, psychophysiology, rehabilitation, Research and development, signal processing, Signal processing algorithms, signal processing methods, Systems Integration, User-Computer Interface},
	pages = {1034--1043}
}

@article{das_predicting_2010,
	title = {Predicting variations of perceptual performance across individuals from neural activity using pattern classifiers},
	volume = {51},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811910003174},
	doi = {10.1016/j.neuroimage.2010.03.030},
	abstract = {Within the past decade computational approaches adopted from the field of machine learning have provided neuroscientists with powerful new tools for analyzing neural data. For instance, previous studies have applied pattern classification algorithms to electroencephalography data to predict the category of presented visual stimuli, human observer decision choices and task difficulty. Here, we quantitatively compare the ability of pattern classifiers and three ERP metrics (peak amplitude, mean amplitude, and onset latency of the face-selective N170) to predict variations across individuals' behavioral performance in a difficult perceptual task identifying images of faces and cars embedded in noise. We investigate three different pattern classifiers (Classwise Principal Component Analysis, CPCA; Linear Discriminant Analysis, LDA; and Support Vector Machine, SVM), five training methods differing in the selection of training data sets and three analyses procedures for the ERP measures. We show that all three pattern classifier algorithms surpass traditional ERP measurements in their ability to predict individual differences in performance. Although the differences across pattern classifiers were not large, the CPCA method with training data sets restricted to EEG activity for trials in which observers expressed high confidence about their decisions performed the highest at predicting perceptual performance of observers. We also show that the neural activity predicting the performance across individuals was distributed through time starting at 120 ms, and unlike the face-selective ERP response, sustained for more than 400 ms after stimulus presentation, indicating that both early and late components contain information correlated with observers' behavioral performance. Together, our results further demonstrate the potential of pattern classifiers compared to more traditional ERP techniques as an analysis tool for modeling spatiotemporal dynamics of the human brain and relating neural activity to behavior.},
	number = {4},
	urldate = {2016-12-20},
	journal = {NeuroImage},
	author = {Das, Koel and Giesbrecht, Barry and Eckstein, Miguel P.},
	month = jul,
	year = {2010},
	keywords = {ERP analysis, Neural correlates of human behavior, Pattern classifiers},
	pages = {1425--1437}
}

@article{pfurtscheller_visualization_1994,
	title = {Visualization of sensorimotor areas involved in preparation for hand movement based on classification of μ and central β rhythms in single {EEG} trials in man},
	volume = {181},
	issn = {0304-3940},
	url = {http://www.sciencedirect.com/science/article/pii/0304394094905568},
	doi = {10.1016/0304-3940(94)90556-8},
	abstract = {It is well known that μ and central β rhythms start to desynchronize \&gt; 1 s before active hand or finger movement. To investigate whether the same cortical areas are involved in desynchronization of μ and central β rhythms, 56-channel EEG recordings were made during right- and left-finger flexions in three normal subjects. The event-related desynchronization (ERD) was quantified in single EEG trials and classified by the Distinction Sensitive Learning Vector Quantization (DSLVQ) algorithm. This DSLVQ selects the most relevant features (electrode positions) for discrimination between the preparatory state for left- and right-finger movements. It was found that the most important electrode positions were close to the primary hand area. However, in all three subjects the focus of the central β ERD was slightly anterior to the focus of μ desynchronization. This can be interpreted that different neural networks are involved in the generation of μ and central β rhythms.},
	number = {1–2},
	urldate = {2016-12-21},
	journal = {Neuroscience Letters},
	author = {Pfurtscheller, G. and Pregenzer, M. and Neuper, C.},
	month = nov,
	year = {1994},
	keywords = {Central β rhythm, event-related desynchronization, Finger movement, single-trial classification, μ rhythm},
	pages = {43--46}
}

@inproceedings{giusti_fast_2013,
	title = {Fast image scanning with deep max-pooling convolutional neural networks},
	doi = {10.1109/ICIP.2013.6738831},
	abstract = {Deep Neural Networks now excel at image classification, detection and segmentation. When used to scan images by means of a sliding window, however, their high computational complexity can bring even the most powerful hardware to its knees. We show how dynamic programming can speedup the process by orders of magnitude, even when max-pooling layers are present.},
	booktitle = {2013 {IEEE} {International} {Conference} on {Image} {Processing}},
	author = {Giusti, A. and Cireşan, D. C. and Masci, J. and Gambardella, L. M. and Schmidhuber, J.},
	month = sep,
	year = {2013},
	keywords = {Biomedical imaging, convolution, Convolutional Neural Network, deep max-pooling, Deep neural network, deep neural networks, Detection, dynamic programming, Forward-Propagation, image classification, image detection, image scanning, image segmentation, Max-Pooling, max-pooling layer, neural nets, Segmentation, sliding window},
	pages = {4034--4038}
}

@inproceedings{sun_novel_2010,
	title = {A novel frequency band selection method for {Common} {Spatial} {Pattern} in {Motor} {Imagery} based {Brain} {Computer} {Interface}},
	url = {https://waseda.pure.elsevier.com/ja/publications/a-novel-frequency-band-selection-method-for-common-spatial-patter},
	doi = {10.1109/IJCNN.2010.5596474},
	language = {English},
	urldate = {2017-01-09},
	author = {Sun, Gufei and Hu, Jinglu and Wu, Gengfeng},
	year = {2010}
}

@inproceedings{domhan_speeding_2015,
	title = {Speeding {Up} {Automatic} {Hyperparameter} {Optimization} of {Deep} {Neural} {Networks} by {Extrapolation} of {Learning} {Curves}},
	copyright = {Authors who submit to this conference agree to the following terms:    a) Authors transfer their copyrights in their paper to the International Joint Conferences on Artificial Intelligence, Inc. (IJCAI), in order to deal with future requests for reprints, translations, anthologies, reproductions, excerpts, and other publications. This grant will include, without limitation, the entire copyright in the paper in all countries of the world, including all renewals, extensions, and reversions thereof, whether such rights currently exist or hereafter come into effect, and also the exclusive right to create electronic versions of the paper, to the extent that such right is not subsumed under copyright.    b) Every named author warrants that he/she is the sole author and owner of the copyright in the paper, except for those portions shown to be in quotations; that the paper is original throughout; and that their right to make the grants set forth above is complete and unencumbered. If anyone brings any claim or action alleging facts that, if true, constitute a breach of any of the foregoing warranties, each author, individually and collectively, will hold harmless and indemnify IJCAI, their grantees, their licensees, and their distributors against any liability, whether under judgment, decree, or compromise, and any legal fees and expenses arising out of that claim or actions, and the undersigned will cooperate fully in any defense IJCAI may make to such claim or action. Moreover, each author agrees to cooperate in any claim or other action seeking to protect or enforce any right the author has granted to IJCAI in the paper. If any such claim or action fails because of facts that constitute a breach of any of the foregoing warranties, each author agrees to reimburse whomever brings such claim or action for expenses and attorney\&rsquo;s fees incurred therein.   c) \&nbsp;In return for these rights, IJCAI hereby grants to each author, and the employers for whom the work was performed, royalty-free permission to: 1. retain all proprietary rights (such as patent rights) other than copyright and the publication rights transferred to IJCAI; 2. personally reuse all or portions of the paper in other works of their own authorship; 3. make oral presentation of the material in any forum; 4. reproduce, or have reproduced, the  paper for the author\&rsquo;s personal use, or for company use provided that IJCAI copyright and the source are indicated, and that the copies are not used in a way that implies IJCAI endorsement of a product or service of an employer, and that the copies per se are not offered for sale. The foregoing right shall not permit the posting of the paper in electronic or digital form on any computer network, except by the author or the author\&rsquo;s employer, and then only on the author\&rsquo;s or the employer\&rsquo;s own World Wide Web page or ftp site. Such Web page or ftp site, in addition to the aforementioned requirements of this Paragraph, must provide an electronic reference or link back to the IJCAI electronic server (http://www.ijcai.org), and shall not post other IJCAI copyrighted materials not of the author\&rsquo;s or the employer\&rsquo;s creation (including tables of contents with links to other papers) without IJCAI\&rsquo;s written permission; \&gt;5. make limited distribution of all or portions of the above paper prior to publication. 6. In the case of work performed under U.S. Government contract, IJCAI grants the U.S. Government royalty-free permission to reproduce all or portions of the above paper, and to authorize others to do so, for U.S. Government purposes. In the event the above paper is not accepted and published by IJCAI, or is withdrawn by the author(s) before acceptance by IJCAI, this agreement becomes null and void.},
	url = {http://www.aaai.org/ocs/index.php/IJCAI/IJCAI15/paper/view/11468},
	abstract = {Deep neural networks (DNNs) show very strong performance on many machine learning problems, but they are very sensitive to the setting of their hyperparameters. Automated hyperparameter optimization methods have recently been shown to yield settings competitive with those found by human experts, but their widespread adoption is hampered by the fact that they require more computational resources than human experts. Humans have one advantage: when they evaluate a poor hyperparameter setting they can quickly detect (after a few SGD steps) that the resulting network performs poorly and terminate the corresponding evaluation to save time. Here, we mimic this early termination of bad runs based on a probabilistic model that extrapolates performance from the first part of a learning curve. Experiments with different neural network architectures show that our resulting approach speeds up state-of-the-art hyperparameter optimization methods for DNNs roughly twofold, enabling them to find DNN settings that yield better performance than those chosen by human experts.},
	language = {en},
	urldate = {2016-12-21},
	booktitle = {Twenty-{Fourth} {International} {Joint} {Conference} on {Artificial} {Intelligence}},
	author = {Domhan, Tobias and Springenberg, Jost Tobias and Hutter, Frank},
	month = jun,
	year = {2015}
}

@article{hajinoroozi_eeg-based_2016,
	title = {{EEG}-based prediction of driver's cognitive performance by deep convolutional neural network},
	volume = {47},
	issn = {0923-5965},
	url = {http://www.sciencedirect.com/science/article/pii/S0923596516300832},
	doi = {10.1016/j.image.2016.05.018},
	abstract = {We considered the prediction of driver's cognitive states related to driving performance using EEG signals. We proposed a novel channel-wise convolutional neural network (CCNN) whose architecture considers the unique characteristics of EEG data. We also discussed CCNN-R, a CCNN variation that uses Restricted Boltzmann Machine to replace the convolutional filter, and derived the detailed algorithm. To test the performance of CCNN and CCNN-R, we assembled a large EEG dataset from 3 studies of driver fatigue that includes samples from 37 subjects. Using this dataset, we investigated the new CCNN and CCNN-R on raw EEG data and also Independent Component Analysis (ICA) decomposition. We tested both within-subject and cross-subject predictions and the results showed CCNN and CCNN-R achieved robust and improved performance over conventional DNN and CNN as well as other non-DL algorithms.},
	urldate = {2016-12-20},
	journal = {Signal Processing: Image Communication},
	author = {Hajinoroozi, Mehdi and Mao, Zijing and Jung, Tzyy-Ping and Lin, Chin-Teng and Huang, Yufei},
	month = sep,
	year = {2016},
	keywords = {Cognitive states, Convolutional Neural Network, Deep neural network},
	pages = {549--555}
}

@article{shelhamer_fully_2016,
	title = {Fully {Convolutional} {Networks} for {Semantic} {Segmentation}},
	volume = {PP},
	issn = {0162-8828},
	doi = {10.1109/TPAMI.2016.2572683},
	abstract = {Convolutional networks are powerful visual models that yield hierarchies of features. We show that convolutional networks by themselves, trained end-to-end, pixels-to-pixels, improve on the previous best result in semantic segmentation. Our key insight is to build “fully convolutional” networks that take input of arbitrary size and produce correspondingly-sized output with efficient inference and learning. We define and detail the space of fully convolutional networks, explain their application to spatially dense prediction tasks, and draw connections to prior models. We adapt contemporary classification networks (AlexNet, the VGG net, and GoogLeNet) into fully convolutional networks and transfer their learned representations by fine-tuning to the segmentation task. We then define a skip architecture that combines semantic information from a deep, coarse layer with appearance information from a shallow, fine layer to produce accurate and detailed segmentations. Our fully convolutional network achieves improved segmentation of PASCAL VOC (30\% relative improvement to 67.2\% mean IU on 2012), NYUDv2, SIFT Flow, and PASCAL-Context, while inference takes one tenth of a second for a typical image.},
	number = {99},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Shelhamer, E. and Long, J. and Darrell, T.},
	year = {2016},
	keywords = {Computer architecture, convolution, Convolutional Networks, deep learning, Fuses, image segmentation, Proposals, Semantics, Semantic Segmentation, Training, Transfer learning},
	pages = {1--1}
}

@inproceedings{thodoroff_learning_2016,
	title = {Learning {Robust} {Features} using {Deep} {Learning} for {Automatic} {Seizure} {Detection}},
	volume = {56},
	url = {http://www.jmlr.org/proceedings/papers/v56/Thodoroff16.pdf},
	urldate = {2017-02-14},
	booktitle = {{JMLR} {Workshop} and {Conference} {Proceedings}},
	author = {Thodoroff, Pierre and Pineau, Joelle and Lim, Andrew},
	year = {2016}
}

@article{knops_recruitment_2009,
	title = {Recruitment of an {Area} {Involved} in {Eye} {Movements} {During} {Mental} {Arithmetic}},
	volume = {324},
	copyright = {Copyright © 2009, American Association for the Advancement of Science},
	issn = {0036-8075, 1095-9203},
	url = {http://science.sciencemag.org/content/324/5934/1583},
	doi = {10.1126/science.1171599},
	abstract = {Throughout the history of mathematics, concepts of number and space have been tightly intertwined. We tested the hypothesis that cortical circuits for spatial attention contribute to mental arithmetic in humans. We trained a multivariate classifier algorithm to infer the direction of an eye movement, left or right, from the brain activation measured in the posterior parietal cortex. Without further training, the classifier then generalized to an arithmetic task. Its left versus right classification could be used to sort out subtraction versus addition trials, whether performed with symbols or with sets of dots. These findings are consistent with the suggestion that mental arithmetic co-opts parietal circuitry associated with spatial coding.
Addition and subtraction are encoded in the same part of the brain that is responsible for eye movements and spatial attention.
Addition and subtraction are encoded in the same part of the brain that is responsible for eye movements and spatial attention.},
	language = {en},
	number = {5934},
	urldate = {2016-12-20},
	journal = {Science},
	author = {Knops, André and Thirion, Bertrand and Hubbard, Edward M. and Michel, Vincent and Dehaene, Stanislas},
	month = jun,
	year = {2009},
	pmid = {19423779},
	pages = {1583--1585}
}

@inproceedings{stober_using_2014,
	address = {Cambridge, MA, USA},
	series = {{NIPS}'14},
	title = {Using {Convolutional} {Neural} {Networks} to {Recognize} {Rhythm} {Stimuli} from {Electroencephalography} {Recordings}},
	url = {http://dl.acm.org/citation.cfm?id=2968826.2968988},
	abstract = {Electroencephalography (EEG) recordings of rhythm perception might contain enough information to distinguish different rhythm types/genres or even identify the rhythms themselves. We apply convolutional neural networks (CNNs) to analyze and classify EEG data recorded within a rhythm perception study in Kigali, Rwanda which comprises 12 East African and 12 Western rhythmic stimuli - each presented in a loop for 32 seconds to 13 participants. We investigate the impact of the data representation and the pre-processing steps for this classification tasks and compare different network structures. Using CNNs, we are able to recognize individual rhythms from the EEG with a mean classification accuracy of 24.4\% (chance level 4.17\%) over all subjects by looking at less than three seconds from a single channel. Aggregating predictions for multiple channels, a mean accuracy of up to 50\% can be achieved for individual subjects.},
	urldate = {2016-12-20},
	booktitle = {Proceedings of the 27th {International} {Conference} on {Neural} {Information} {Processing} {Systems}},
	publisher = {MIT Press},
	author = {Stober, Sebastian and Cameron, Daniel J. and Grahn, Jessica A.},
	year = {2014},
	pages = {1449--1457}
}

@article{vanhatalo_infraslow_2004,
	title = {Infraslow oscillations modulate excitability and interictal epileptic activity in the human cortex during sleep},
	volume = {101},
	url = {http://www.pnas.org/content/101/14/5053.short},
	number = {14},
	urldate = {2017-01-09},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	author = {Vanhatalo, Sampsa and Palva, J. Matias and Holmes, M. D. and Miller, J. W. and Voipio, Juha and Kaila, Kai},
	year = {2004},
	pages = {5053--5057}
}

@article{nguyen_synthesizing_2016,
	title = {Synthesizing the preferred inputs for neurons in neural networks via deep generator networks},
	url = {https://arxiv.org/abs/1605.09304},
	journal = {NIPS 29},
	author = {Nguyen, Anh and Dosovitskiy, Alexey and Yosinski, Jason band Brox, Thomas and Clune, Jeff},
	year = {2016}
}

@inproceedings{ioffe_batch_2015,
	title = {Batch {Normalization}: {Accelerating} {Deep} {Network} {Training} by {Reducing} {Internal} {Covariate} {Shift}},
	shorttitle = {Batch {Normalization}},
	url = {http://www.jmlr.org/proceedings/papers/v37/ioffe15.html},
	urldate = {2016-12-21},
	booktitle = {Proceedings of {The} 32nd {International} {Conference} on {Machine} {Learning}},
	author = {Ioffe, Sergey and Szegedy, Christian},
	year = {2015},
	pages = {448--456}
}

@article{lotte_regularizing_2011,
	title = {Regularizing {Common} {Spatial} {Patterns} to {Improve} {BCI} {Designs}: {Unified} {Theory} and {New} {Algorithms}},
	volume = {58},
	issn = {0018-9294},
	shorttitle = {Regularizing {Common} {Spatial} {Patterns} to {Improve} {BCI} {Designs}},
	doi = {10.1109/TBME.2010.2082539},
	abstract = {One of the most popular feature extraction algorithms for brain-computer interfaces (BCI) is common spatial patterns (CSPs). Despite its known efficiency and widespread use, CSP is also known to be very sensitive to noise and prone to overfitting. To address this issue, it has been recently proposed to regularize CSP. In this paper, we present a simple and unifying theoretical framework to design such a regularized CSP (RCSP). We then present a review of existing RCSP algorithms and describe how to cast them in this framework. We also propose four new RCSP algorithms. Finally, we compare the performances of 11 different RCSP (including the four new ones and the original CSP), on electroencephalography data from 17 subjects, from BCI competition datasets. Results showed that the best RCSP methods can outperform CSP by nearly 10\% in median classification accuracy and lead to more neurophysiologically relevant spatial filters. They also enable us to perform efficient subject-to-subject transfer. Overall, the best RCSP algorithms were CSP with Tikhonov regularization and weighted Tikhonov regularization, both proposed in this paper.},
	number = {2},
	journal = {IEEE Transactions on Biomedical Engineering},
	author = {Lotte, F. and Guan, C.},
	month = feb,
	year = {2011},
	keywords = {Algorithm design and analysis, Algorithms, BCI competition datasets, BCI designs, brain-computer interfaces, Brain–computer interfaces (BCI), common spatial patterns, common spatial patterns (CSP), Covariance matrix, Eigenvalues and eigenfunctions, Electrodes, electroencephalography, electroencephalography data, electroencephalography (EEG), feature extraction, feature extraction algorithms, Humans, Man-Machine Systems, medical signal processing, Models, Neurological, neurophysiologically relevant spatial filters, Noise, Pattern Recognition, Automated, Regression Analysis, Regularization, regularized CSP, Signal Processing, Computer-Assisted, spatial filters, subject-to-subject transfer, Tikhonov regularization, Training, User-Computer Interface},
	pages = {355--362}
}

@inproceedings{springenberg_bayesian_2016,
	title = {Bayesian {Optimization} with {Robust} {Bayesian} {Neural} {Networks}},
	url = {http://papers.nips.cc/paper/6117-bayesian-optimization-with-robust-bayesian-neural-networks},
	urldate = {2016-12-21},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Springenberg, Jost Tobias and Klein, Aaron and Falkner, Stefan and Hutter, Frank},
	year = {2016},
	pages = {4134--4142}
}

@article{hammer_predominance_2016,
	title = {Predominance of {Movement} {Speed} {Over} {Direction} in {Neuronal} {Population} {Signals} of {Motor} {Cortex}: {Intracranial} {EEG} {Data} and {A} {Simple} {Explanatory} {Model}},
	volume = {26},
	issn = {1047-3211},
	shorttitle = {Predominance of {Movement} {Speed} {Over} {Direction} in {Neuronal} {Population} {Signals} of {Motor} {Cortex}},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4869816/},
	doi = {10.1093/cercor/bhw033},
	abstract = {How neuronal activity of motor cortex is related to movement is a central topic in motor neuroscience. Motor-cortical single neurons are more closely related to hand movement velocity than speed, that is, the magnitude of the (directional) velocity vector. Recently, there is also increasing interest in the representation of movement parameters in neuronal population activity, such as reflected in the intracranial EEG (iEEG). We show that in iEEG, contrasting to what has been previously found on the single neuron level, speed predominates over velocity. The predominant speed representation was present in nearly all iEEG signal features, up to the 600–1000 Hz range. Using a model of motor-cortical signals arising from neuronal populations with realistic single neuron tuning properties, we show how this reversal can be understood as a consequence of increasing population size. Our findings demonstrate that the information profile in large population signals may systematically differ from the single neuron level, a principle that may be helpful in the interpretation of neuronal population signals in general, including, for example, EEG and functional magnetic resonance imaging. Taking advantage of the robust speed population signal may help in developing brain–machine interfaces exploiting population signals.},
	number = {6},
	urldate = {2017-01-11},
	journal = {Cerebral Cortex (New York, NY)},
	author = {Hammer, Jiří and Pistohl, Tobias and Fischer, Jörg and Kršek, Pavel and Tomášek, Martin and Marusič, Petr and Schulze-Bonhage, Andreas and Aertsen, Ad and Ball, Tonio},
	month = jun,
	year = {2016},
	pmid = {26984895},
	pmcid = {PMC4869816},
	pages = {2863--2881}
}


@inproceedings{sercu_very_2016,
	title = {Very deep multilingual convolutional neural networks for {LVCSR}},
	doi = {10.1109/ICASSP.2016.7472620},
	abstract = {Convolutional neural networks (CNNs) are a standard component of many current state-of-the-art Large Vocabulary Continuous Speech Recognition (LVCSR) systems. However, CNNs in LVCSR have not kept pace with recent advances in other domains where deeper neural networks provide superior performance. In this paper we propose a number of architectural advances in CNNs for LVCSR. First, we introduce a very deep convolutional network architecture with up to 14 weight layers. There are multiple convolutional layers before each pooling layer, with small 3×3 kernels, inspired by the VGG Imagenet 2014 architecture. Then, we introduce multilingual CNNs with multiple untied layers. Finally, we introduce multi-scale input features aimed at exploiting more context at negligible computational cost. We evaluate the improvements first on a Babel task for low resource speech recognition, obtaining an absolute 5.77\% WER improvement over the baseline PLP DNN by training our CNN on the combined data of six different languages. We then evaluate the very deep CNNs on the Hub5'00 benchmark (using the 262 hours of SWB-1 training data) achieving a word error rate of 11.8\% after cross-entropy training, a 1.4\% WER improvement (10.6\% relative) over the best published CNN result so far.},
	booktitle = {2016 {IEEE} {International} {Conference} on {Acoustics}, {Speech} and {Signal} {Processing} ({ICASSP})},
	author = {Sercu, T. and Puhrsch, C. and Kingsbury, B. and LeCun, Y.},
	month = mar,
	year = {2016},
	keywords = {acoustic modeling, CNN, Computer architecture, Context, Convolutional Networks, hidden Markov models, Kernel, large vocabulary continuous speech recognition systems, LVCSR, Multilingual, natural language processing, neural nets, Neural networks, Speech recognition, Training, Training data, very deep multilingual convolutional neural networks, word error rate},
	pages = {4955--4959}
}

@article{pfurtscheller_occipital_1978,
	title = {Occipital rhythmic activity within the alpha band during conditioned externally paced movement},
	volume = {45},
	issn = {0013-4694},
	url = {http://www.sciencedirect.com/science/article/pii/0013469478900068},
	doi = {10.1016/0013-4694(78)90006-8},
	abstract = {The time-dependent behaviour of the power within the alpha band during conditioned movement was studied from the scalp EEG of 9 normal humans. Two tasks were used: (1) button pressing at imperative signal S1 and release at signal S2; (2) button pressing at imperative signal S2, preceded by warning signal S1. Together with a complex correlate of the CNV and EPs, the components of power decrease related to initiation of movement were not clearly identifiable in the central areas. They were sharply isolated in the occipital areas, using tone as the imperative signal.

During initiation of movement a significant short-lasting decrease in power of the occipital alpha activities was observed in all 9 subjects. However, ‘mu activity’, tested in the classical manner and with help of power spectra, was not present in some of these subjects.},
	number = {2},
	urldate = {2016-12-21},
	journal = {Electroencephalography and Clinical Neurophysiology},
	author = {Pfurtscheller, G and Aranibar, A},
	month = aug,
	year = {1978},
	pages = {226--235}
}

@book{nunez_electric_2006-1,
	address = {Oxford ; New York},
	edition = {2nd ed.},
	title = {Electric {Fields} of the {Brain}: {The} {Neurophysics} of {EEG}},
	isbn = {978-0-19-505038-7},
	shorttitle = {Electric {Fields} of the {Brain}},
	abstract = {This second edition expands the widely acclaimed 1981 book, filling more gaps between EEG and the physical sciences. EEG opens a "window on the mind" by finding new connections between psychology and physiology. Topics include synaptic sources, electrode placement, choice of reference, volume conduction, power and coherence, projection of scalp potentials to dura surface, dynamic signatures of conscious experience, and neural networks immersed in global fields of synaptic action.},
	language = {Englisch},
	publisher = {Oxford University Press},
	author = {Nunez, Paul L. and Srinivasan, Ramesh},
	month = jan,
	year = {2006}
}

@inproceedings{dosovitskiy_inverting_2016-1,
	title = {Inverting {Visual} {Representations} with {Convolutional} {Networks}},
	url = {http://lmb.informatik.uni-freiburg.de//Publications/2016/DB16},
	booktitle = {{IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	author = {Dosovitskiy, A. and {T.Brox}},
	year = {2016},
	note = {arXiv:1506.02753}
}

@inproceedings{yeager_effective_2016,
	title = {Effective {Visualizations} for {Training} and {Evaluating} {Deep} {Models}},
	url = {http://icmlviz.github.io/assets/papers/16.pdf},
	author = {Yeager, Luke},
	year = {2016}
}

@article{manor_multimodal_2016,
	title = {Multimodal {Neural} {Network} for {Rapid} {Serial} {Visual} {Presentation} {Brain} {Computer} {Interface}},
	volume = {10},
	issn = {1662-5188},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC5168930/},
	doi = {10.3389/fncom.2016.00130},
	abstract = {Brain computer interfaces allow users to preform various tasks using only the electrical activity of the brain. BCI applications often present the user a set of stimuli and record the corresponding electrical response. The BCI algorithm will then have to decode the acquired brain response and perform the desired task. In rapid serial visual presentation (RSVP) tasks, the subject is presented with a continuous stream of images containing rare target images among standard images, while the algorithm has to detect brain activity associated with target images. In this work, we suggest a multimodal neural network for RSVP tasks. The network operates on the brain response and on the initiating stimulus simultaneously, providing more information for the BCI application. We present two variants of the multimodal network, a supervised model, for the case when the targets are known in advanced, and a semi-supervised model for when the targets are unknown. We test the neural networks with a RSVP experiment on satellite imagery carried out with two subjects. The multimodal networks achieve a significant performance improvement in classification metrics. We visualize what the networks has learned and discuss the advantages of using neural network models for BCI applications.},
	urldate = {2017-02-03},
	journal = {Frontiers in Computational Neuroscience},
	author = {Manor, Ran and Mishali, Liran and Geva, Amir B.},
	month = dec,
	year = {2016},
	pmid = {28066220},
	pmcid = {PMC5168930}
}

@inproceedings{bashivan_learning_2016,
	title = {Learning {Representations} from {EEG} with {Deep} {Recurrent}-{Convolutional} {Neural} {Networks}},
	url = {http://arxiv.org/abs/1511.06448},
	abstract = {One of the challenges in modeling cognitive events from electroencephalogram (EEG) data is finding representations that are invariant to inter- and intra-subject differences, as well as to inherent noise associated with such data. Herein, we propose a novel approach for learning such representations from multi-channel EEG time-series, and demonstrate its advantages in the context of mental load classification task. First, we transform EEG activities into a sequence of topology-preserving multi-spectral images, as opposed to standard EEG analysis techniques that ignore such spatial information. Next, we train a deep recurrent-convolutional network inspired by state-of-the-art video classification to learn robust representations from the sequence of images. The proposed approach is designed to preserve the spatial, spectral, and temporal structure of EEG which leads to finding features that are less sensitive to variations and distortions within each dimension. Empirical evaluation on the cognitive load classification task demonstrated significant improvements in classification accuracy over current state-of-the-art approaches in this field.},
	urldate = {2016-12-20},
	booktitle = {{arXiv}:1511.06448 [cs]},
	author = {Bashivan, Pouya and Rish, Irina and Yeasin, Mohammed and Codella, Noel},
	year = {2016},
	note = {arXiv: 1511.06448},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Learning},
	annote = {Comment: To be published as a conference paper at ICLR 2016}
}

@article{schack_phase-coupling_2002,
	title = {Phase-coupling of theta–gamma {EEG} rhythms during short-term memory processing},
	volume = {44},
	url = {http://www.sciencedirect.com/science/article/pii/S0167876001001994},
	number = {2},
	urldate = {2017-01-09},
	journal = {International Journal of Psychophysiology},
	author = {Schack, B. and Vath, N. and Petsche, H. and Geissler, H.-G. and Möller, E.},
	year = {2002},
	pages = {143--163}
}

@article{pfurtscheller_central_1981,
	title = {Central beta rhythm during sensorimotor activities in man},
	volume = {51},
	issn = {0013-4694},
	url = {http://www.sciencedirect.com/science/article/pii/0013469481901395},
	doi = {10.1016/0013-4694(81)90139-5},
	abstract = {Blocking or desynchronization of the central beta rhythm prior to and parallel to voluntary movement was found in 31 of 33 normal subjects investigated. The beta blocking was short lasting (1–3 sec), very often accompanied by blocking of the mu rhythm and localized in the central region. Phasic beta desynchronization was also observed after somatosensory stimulation. The beta rhythm showed a bilateral symmetrical blocking pattern with unilateral movement or stimulation. Patients with unilateral cerebral ischaemia showed an asymmetric blocking response and therefore demonstrated a high degree of hemispheric independence of the rhythmic generating systems. Central beta desynchronization is, therefore, a normal physiological phenomenon caused by activation processes of the sensorimotor cortex and detectable on the scalp very easily with closely spaced electrodes.},
	number = {3},
	urldate = {2017-01-09},
	journal = {Electroencephalography and Clinical Neurophysiology},
	author = {Pfurtscheller, G},
	month = mar,
	year = {1981},
	pages = {253--264}
}

@inproceedings{george_single-trial_2016,
	title = {Single-trial {EEG} {RSVP} classification using convolutional neural networks},
	volume = {9836},
	url = {http://proceedings.spiedigitallibrary.org/proceeding.aspx?doi=10.1117/12.2224172},
	doi = {10.1117/12.2224172},
	urldate = {2017-02-14},
	booktitle = {{SPIE} {Defense}+ {Security}},
	publisher = {International Society for Optics and Photonics},
	author = {Shamwell, Jared and Lee, Hyungtae and Kwon, Heesung and Marathe, Amar R. and Lawhern, Vernon and Nothwang, William},
	editor = {George, Thomas and Dutta, Achyut K. and Islam, M. Saif},
	month = may,
	year = {2016}
}

@inproceedings{li_constructing_2015,
	title = {Constructing long short-term memory based deep recurrent neural networks for large vocabulary speech recognition},
	doi = {10.1109/ICASSP.2015.7178826},
	abstract = {Long short-term memory (LSTM) based acoustic modeling methods have recently been shown to give state-of-the-art performance on some speech recognition tasks. To achieve a further performance improvement, in this research, deep extensions on LSTM are investigated considering that deep hierarchical model has turned out to be more efficient than a shallow one. Motivated by previous research on constructing deep recurrent neural networks (RNNs), alternative deep LSTM architectures are proposed and empirically evaluated on a large vocabulary conversational telephone speech recognition task. Meanwhile, regarding to multi-GPU devices, the training process for LSTM networks is introduced and discussed. Experimental results demonstrate that the deep LSTM networks benefit from the depth and yield the state-of-the-art performance on this task.},
	booktitle = {2015 {IEEE} {International} {Conference} on {Acoustics}, {Speech} and {Signal} {Processing} ({ICASSP})},
	author = {Li, X. and Wu, X.},
	month = apr,
	year = {2015},
	keywords = {acoustic modeling, acoustic modeling method, Acoustics, Computer architecture, deep LSTM network, deep neural networks, deep recurrent neural network, graphics processing units, hidden Markov models, hierarchical model, large vocabulary speech recognition, learning (artificial intelligence), long short-term memory, multiGPU device, recurrent neural nets, Recurrent neural networks, RNN, Speech, Speech recognition, telephone speech recognition task, Training, training process},
	pages = {4520--4524}
}

@inproceedings{sainath_convolutional_2015,
	title = {Convolutional, {Long} {Short}-{Term} {Memory}, fully connected {Deep} {Neural} {Networks}},
	doi = {10.1109/ICASSP.2015.7178838},
	abstract = {Both Convolutional Neural Networks (CNNs) and Long Short-Term Memory (LSTM) have shown improvements over Deep Neural Networks (DNNs) across a wide variety of speech recognition tasks. CNNs, LSTMs and DNNs are complementary in their modeling capabilities, as CNNs are good at reducing frequency variations, LSTMs are good at temporal modeling, and DNNs are appropriate for mapping features to a more separable space. In this paper, we take advantage of the complementarity of CNNs, LSTMs and DNNs by combining them into one unified architecture. We explore the proposed architecture, which we call CLDNN, on a variety of large vocabulary tasks, varying from 200 to 2,000 hours. We find that the CLDNN provides a 4-6\% relative improvement in WER over an LSTM, the strongest of the three individual models.},
	booktitle = {2015 {IEEE} {International} {Conference} on {Acoustics}, {Speech} and {Signal} {Processing} ({ICASSP})},
	author = {Sainath, T. N. and Vinyals, O. and Senior, A. and Sak, H.},
	month = apr,
	year = {2015},
	keywords = {CNN, Context, convolutional memory, convolutional neural networks, DNN, frequency variations, fully connected deep neural networks, hidden Markov models, long short-term memory, LSTM, neural nets, Neural networks, Noise measurement, Speech, Speech recognition, Training},
	pages = {4580--4584}
}

@article{meinel_pre-trial_2016-1,
	title = {Pre-{Trial} {EEG}-{Based} {Single}-{Trial} {Motor} {Performance} {Prediction} to {Enhance} {Neuroergonomics} for a {Hand} {Force} {Task}},
	volume = {10},
	issn = {1662-5161},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4843706/},
	doi = {10.3389/fnhum.2016.00170},
	abstract = {We propose a framework for building electrophysiological predictors of single-trial motor performance variations, exemplified for SVIPT, a sequential isometric force control task suitable for hand motor rehabilitation after stroke. Electroencephalogram (EEG) data of 20 subjects with mean age of 53 years was recorded prior to and during 400 trials of SVIPT. They were executed within a single session with the non-dominant left hand, while receiving continuous visual feedback of the produced force trajectories. The behavioral data showed strong trial-by-trial performance variations for five clinically relevant metrics, which accounted for reaction time as well as for the smoothness and precision of the produced force trajectory. 18 out of 20 tested subjects remained after preprocessing and entered offline analysis. Source Power Comodulation (SPoC) was applied on EEG data of a short time interval prior to the start of each SVIPT trial. For 11 subjects, SPoC revealed robust oscillatory EEG subspace components, whose bandpower activity are predictive for the performance of the upcoming trial. Since SPoC may overfit to non-informative subspaces, we propose to apply three selection criteria accounting for the meaningfulness of the features. Across all subjects, the obtained components were spread along the frequency spectrum and showed a variety of spatial activity patterns. Those containing the highest level of predictive information resided in and close to the alpha band. Their spatial patterns resemble topologies reported for visual attention processes as well as those of imagined or executed hand motor tasks. In summary, we identified subject-specific single predictors that explain up to 36\% of the performance fluctuations and may serve for enhancing neuroergonomics of motor rehabilitation scenarios.},
	urldate = {2017-01-09},
	journal = {Frontiers in Human Neuroscience},
	author = {Meinel, Andreas and Castaño-Candamil, Sebastián and Reis, Janine and Tangermann, Michael},
	month = apr,
	year = {2016},
	pmid = {27199701},
	pmcid = {PMC4843706}
}

@inproceedings{page_wearable_2016,
	title = {Wearable seizure detection using convolutional neural networks with transfer learning},
	doi = {10.1109/ISCAS.2016.7527433},
	abstract = {The ability to accurately and robustly detect seizures in an ambulatory setting using scalp-based EEG has been the focus of much research over the last several decades. However, its numerous challenges and obstacles have impeded the realization of a definitive solution. This work aims to build upon our existing research and apply newer advanced machine learning and hardware techniques to this issue. The novelty proposed is two-fold. First, we utilize max-pooling convolutional neural networks (MPCNN) to perform end-to-end learning. Second, we demonstrate that transfer-learning can be used to teach MPCNNs generalized features of both normal and epileptiform patterns from a pool of subjects' raw EEG data. Using this hybrid approach, the system is able to detect all 184 seizure onsets from 24 cases with average latency of 1.47 seconds and 3.2 false-alarms/day. To demonstrate the full system, the entire design is efficiently implemented onto a highly parallel, highly granular embedded SoC (NVIDIA Jetson TK1). When utilizing the GPU, the system is able to classify 15-second segments in 308 μs and last over 80 hours.},
	booktitle = {2016 {IEEE} {International} {Symposium} on {Circuits} and {Systems} ({ISCAS})},
	author = {Page, A. and Shea, C. and Mohsenin, T.},
	month = may,
	year = {2016},
	keywords = {Brain models, convolution, Databases, Data models, electroencephalography, end-to-end learning, learning (artificial intelligence), machine learning, max pooling convolutional neural networks, medical signal detection, neural nets, scalp based EEG, Sensitivity, Training, Transfer learning, wearable seizure detection},
	pages = {1086--1089}
}

@article{pfurtscheller_patterns_1989,
	title = {Patterns of cortical activation during planning of voluntary movement},
	volume = {72},
	issn = {0013-4694},
	url = {http://www.sciencedirect.com/science/article/pii/0013469489902502},
	doi = {10.1016/0013-4694(89)90250-2},
	abstract = {The influence of planning of self-paced voluntary finger movements on alpha band components was studied in 6 volunteers. Brain potentials from 29 electrodes, referred to the right ear, were recorded 4 sec before and 2 sec after movement onset. These data were transformed to obtain the laplacian operator, which was done by computing the local average reference. The event-related desynchronization (ERD) of upper alpha components was then calculated in each record at intervals of 250 msec and topographically displayed in the form of serial ERD maps. A first significant ERD (P \&lt; 0.01, sign test) was found 1.75 sec +/− 0.61 before the movement, most prominent over the contralateral sensorimotor area and over midfrontal areas (the latter can probably be interpreted as an activation of the supplementary motor area). From these data we can conclude that the side of movement is predetermined more than 1 sec before movement onset.},
	number = {3},
	urldate = {2016-12-21},
	journal = {Electroencephalography and Clinical Neurophysiology},
	author = {Pfurtscheller, G. and Berghold, A.},
	month = mar,
	year = {1989},
	keywords = {Cortical activation, event-related desynchronization, mu rhythm, Voluntary movement},
	pages = {250--258}
}

@article{brunner_bci_2008,
	title = {{BCI} {Competition} 2008–{Graz} data set {A}},
	url = {http://www.bbci.de/competition/iv/desc_2a.pdf},
	urldate = {2017-01-09},
	journal = {Institute for Knowledge Discovery (Laboratory of Brain-Computer Interfaces), Graz University of Technology},
	author = {Brunner, C. and Leeb, R. and Müller-Putz, G. and Schlögl, A. and Pfurtscheller, G.},
	year = {2008},
	pages = {136--142}
}

@article{pfurtscheller_differentiation_1994,
	title = {Differentiation between finger, toe and tongue movement in man based on 40 {Hz} {EEG}},
	volume = {90},
	issn = {0013-4694},
	url = {http://www.sciencedirect.com/science/article/pii/0013469494901376},
	doi = {10.1016/0013-4694(94)90137-6},
	abstract = {Movements of right and left index fingers, right toe and tongue were studied by EEG measurement in the alpha and gamma (30–40 Hz) bands. The EEG was recorded with a 56-electrode array over pre- and postcentral areas. For each movement the average power decrease, as a measurment of the event-related desynchronization or power increase in narrow frequency bands, was calculated. Single-trial data from 8 electrodes, 3 frequency bands and 4 time points within a 1 sec window were subject to a classification task. It was found that, based on single EEG trials, the data from the 4 movements could be differentiated with an accuracy of 70\% when alpha and gamma band activity were used but only with 58\% in the case of the alpha band activity alone. This shows that the gamma band activity or 40 Hz EEG is strongly related to planning of a specific movement and therefore, improves the accuracy of classification significantly.},
	number = {6},
	urldate = {2016-12-21},
	journal = {Electroencephalography and Clinical Neurophysiology},
	author = {Pfurtscheller, Gert and Flotzinger, Doris and Neuper, Christa},
	month = jun,
	year = {1994},
	keywords = {40 Hz EEG, Event-related desynchronization (ERD), Event-related synchronization (ERS), Gamma band activity, Movement},
	pages = {456--460}
}

@article{ganin_domain-adversarial_2016,
	title = {Domain-{Adversarial} {Training} of {Neural} {Networks}},
	volume = {17},
	url = {http://jmlr.org/papers/v17/15-239.html},
	number = {59},
	urldate = {2016-12-21},
	journal = {Journal of Machine Learning Research},
	author = {Ganin, Yaroslav and Ustinova, Evgeniya and Ajakan, Hana and Germain, Pascal and Larochelle, Hugo and Laviolette, François and Marchand, Mario and Lempitsky, Victor},
	year = {2016},
	pages = {1--35}
}

@inproceedings{wang_deep_2013,
	address = {Beijing, China},
	series = {{IJCAI} '13},
	title = {Deep {Feature} {Learning} {Using} {Target} {Priors} with {Applications} in {ECoG} {Signal} {Decoding} for {BCI}},
	isbn = {978-1-57735-633-2},
	url = {http://dl.acm.org/citation.cfm?id=2540128.2540384},
	abstract = {Recent years have seen a great interest in using deep architectures for feature learning from data. One drawback of the commonly used unsupervised deep feature learning methods is that for supervised or semi-supervised learning tasks, the information in the target variables are not used until the final stage when the classifier or regressor is trained on the learned features. This could lead to over-generalized features that are not competitive on the specific supervised or semi-supervised learning tasks. In this work, we describe a new learning method that combines deep feature learning on mixed labeled and unlabeled data sets. Specifically, we describe a weakly supervised learning method of a prior supervised convolutional stacked auto-encoders (PCSA), of which information in the target variables is represented probabilistically using a Gaussian Bernoulli restricted Boltzmann machine (RBM). We apply this method to the decoding problem of an ECoG based Brain Computer Interface (BCI) system. Our experimental results show that PCSA achieves significant improvement in decoding performance on benchmark data sets compared to the unsupervised feature learning as well as to the current state-of-the-art algorithms that are based on manually crafted features.},
	urldate = {2017-01-16},
	booktitle = {Proceedings of the {Twenty}-{Third} {International} {Joint} {Conference} on {Artificial} {Intelligence}},
	publisher = {AAAI Press},
	author = {Wang, Zuoguan and Lyu, Siwei and Schalk, Gerwin and Ji, Qiang},
	year = {2013},
	pages = {1785--1791}
}

@inproceedings{nasse_face_2009,
	title = {Face detection using gpu-based convolutional neural networks},
	url = {http://link.springer.com/chapter/10.1007/978-3-642-03767-2_10},
	urldate = {2017-01-09},
	booktitle = {International {Conference} on {Computer} {Analysis} of {Images} and {Patterns}},
	publisher = {Springer},
	author = {Nasse, Fabian and Thurau, Christian and Fink, Gernot A.},
	year = {2009},
	pages = {83--90}
}

@inproceedings{szegedy_intriguing_2014,
	title = {Intriguing properties of neural networks},
	url = {http://arxiv.org/abs/1312.6199},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Szegedy, Christian and Zaremba, Wojciech and Sutskever, Ilya and Bruna, Joan and Erhan, Dumitru and Goodfellow, Ian and Fergus, Rob},
	year = {2014}
}

@article{cecotti_convolutional_2011,
	title = {Convolutional {Neural} {Networks} for {P}300 {Detection} with {Application} to {Brain}-{Computer} {Interfaces}},
	volume = {33},
	issn = {0162-8828},
	url = {http://dx.doi.org/10.1109/TPAMI.2010.125},
	doi = {10.1109/TPAMI.2010.125},
	abstract = {A Brain-Computer Interface (BCI) is a specific type of human-computer interface that enables the direct communication between human and computers by analyzing brain measurements. Oddball paradigms are used in BCI to generate event-related potentials (ERPs), like the P300 wave, on targets selected by the user. A P300 speller is based on this principle, where the detection of P300 waves allows the user to write characters. The P300 speller is composed of two classification problems. The first classification is to detect the presence of a P300 in the electroencephalogram (EEG). The second one corresponds to the combination of different P300 responses for determining the right character to spell. A new method for the detection of P300 waves is presented. This model is based on a convolutional neural network (CNN). The topology of the network is adapted to the detection of P300 waves in the time domain. Seven classifiers based on the CNN are proposed: four single classifiers with different features set and three multiclassifiers. These models are tested and compared on the Data set II of the third BCI competition. The best result is obtained with a multiclassifier solution with a recognition rate of 95.5 percent, without channel selection before the classification. The proposed approach provides also a new way for analyzing brain activities due to the receptive field of the CNN models.},
	number = {3},
	urldate = {2016-12-20},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Cecotti, Hubert and Graser, Axel},
	month = mar,
	year = {2011},
	keywords = {Brain-computer interface (BCI), convolution, Electroencephalogram (EEG), gradient-based learning, Neural network, P300., spatial filters},
	pages = {433--445}
}

@article{tang_single-trial_2017,
	title = {Single-trial {EEG} classification of motor imagery using deep convolutional neural networks},
	volume = {130},
	issn = {0030-4026},
	url = {http://www.sciencedirect.com/science/article/pii/S0030402616312980},
	doi = {10.1016/j.ijleo.2016.10.117},
	abstract = {Electroencephalogram (EEG) signal recorded during motor imagery (MI) has been widely applied in non-invasive brain–computer interface (BCI) as a communication approach. In this paper, we propose a new method based on the deep convolutional neural network (CNN) to perform feature extraction and classification for single-trial MI EEG. Firstly, based on the spatio-temporal characteristics of EEG, a 5-layer CNN model is built to classify MI tasks (left hand and right hand movement); then the CNN model is applied in the experimental data set collected from subjects, and compared with other three conventional classification methods (power + SVM, CSP + SVM and AR + SVM). The results demonstrate that CNN can further improve classification performance: the average accuracy using CNN (86.41 ± 0.77\%) is 9.24\%, 3.80\% and 5.16\% higher than those using power + SVM, CSP + SVM and AR + SVM, respectively. The present study shows that the proposed method is effective to classify MI, and provides a practical method by non-invasive EEG signal in BCI applications.},
	urldate = {2017-02-14},
	journal = {Optik - International Journal for Light and Electron Optics},
	author = {Tang, Zhichuan and Li, Chao and Sun, Shouqian},
	month = feb,
	year = {2017},
	keywords = {Brain–computer interface, deep convolutional neural network, Motor Imagery, Non-invasive EEG},
	pages = {11--18}
}

@article{duchi_adaptive_2011,
	title = {Adaptive {Subgradient} {Methods} for {Online} {Learning} and {Stochastic} {Optimization}},
	volume = {12},
	issn = {ISSN 1533-7928},
	url = {http://jmlr.org/papers/v12/duchi11a.html},
	number = {Jul},
	urldate = {2016-12-21},
	journal = {Journal of Machine Learning Research},
	author = {Duchi, John and Hazan, Elad and Singer, Yoram},
	year = {2011},
	pages = {2121--2159}
}

@article{tabar_novel_2017,
	title = {A novel deep learning approach for classification of {EEG} motor imagery signals},
	volume = {14},
	issn = {1741-2552},
	url = {http://stacks.iop.org/1741-2552/14/i=1/a=016003},
	doi = {10.1088/1741-2560/14/1/016003},
	abstract = {Objective . Signal classification is an important issue in brain computer interface (BCI) systems. Deep learning approaches have been used successfully in many recent studies to learn features and classify different types of data. However, the number of studies that employ these approaches on BCI applications is very limited. In this study we aim to use deep learning methods to improve classification performance of EEG motor imagery signals. Approach . In this study we investigate convolutional neural networks (CNN) and stacked autoencoders (SAE) to classify EEG Motor Imagery signals. A new form of input is introduced to combine time, frequency and location information extracted from EEG signal and it is used in CNN having one 1D convolutional and one max-pooling layers. We also proposed a new deep network by combining CNN and SAE. In this network, the features that are extracted in CNN are classified through the deep network SAE. Main results . The classification performance obtained by the proposed method on BCI competition IV dataset 2b in terms of kappa value is 0.547. Our approach yields 9\% improvement over the winner algorithm of the competition. Significance . Our results show that deep learning methods provide better classification performance compared to other state of art approaches. These methods can be applied successfully to BCI systems where the amount of data is large due to daily recording.},
	language = {en},
	number = {1},
	urldate = {2017-02-14},
	journal = {Journal of Neural Engineering},
	author = {Tabar, Yousef Rezaei and Halici, Ugur},
	year = {2017},
	pages = {016003}
}

@article{strumbelj_explaining_2014,
	title = {Explaining prediction models and individual predictions with feature contributions},
	volume = {41},
	issn = {0219-1377, 0219-3116},
	url = {https://link.springer.com/article/10.1007/s10115-013-0679-x},
	doi = {10.1007/s10115-013-0679-x},
	abstract = {We present a sensitivity analysis-based method for explaining prediction models that can be applied to any type of classification or regression model. Its advantage over existing general methods is that all subsets of input features are perturbed, so interactions and redundancies between features are taken into account. Furthermore, when explaining an additive model, the method is equivalent to commonly used additive model-specific methods. We illustrate the method’s usefulness with examples from artificial and real-world data sets and an empirical analysis of running times. Results from a controlled experiment with 122 participants suggest that the method’s explanations improved the participants’ understanding of the model.},
	language = {en},
	number = {3},
	urldate = {2017-04-24},
	journal = {Knowledge and Information Systems},
	author = {Štrumbelj, Erik and Kononenko, Igor},
	month = dec,
	year = {2014},
	pages = {647--665}
}

@inproceedings{clevert_fast_2016,
	title = {Fast and {Accurate} {Deep} {Network} {Learning} by {Exponential} {Linear} {Units} ({ELUs})},
	volume = {1511},
	url = {http://adsabs.harvard.edu/abs/2015arXiv151107289C},
	abstract = {We introduce the "exponential linear unit" (ELU) which speeds up learning in deep neural networks and leads to higher classification accuracies. Like rectified linear units (ReLUs), leaky ReLUs (LReLUs) and parametrized ReLUs (PReLUs), ELUs alleviate the vanishing gradient problem via the identity for positive values. However, ELUs have improved learning characteristics compared to the units with other activation functions. In contrast to ReLUs, ELUs have negative values which allows them to push mean unit activations closer to zero like batch normalization but with lower computational complexity. Mean shifts toward zero speed up learning by bringing the normal gradient closer to the unit natural gradient because of a reduced bias shift effect. While LReLUs and PReLUs have negative values, too, they do not ensure a noise-robust deactivation state. ELUs saturate to a negative value with smaller inputs and thereby decrease the forward propagated variation and information. Therefore, ELUs code the degree of presence of particular phenomena in the input, while they do not quantitatively model the degree of their absence. In experiments, ELUs lead not only to faster learning, but also to significantly better generalization performance than ReLUs and LReLUs on networks with more than 5 layers. On CIFAR-100 ELUs networks significantly outperform ReLU networks with batch
normalization while batch normalization does not improve ELU networks. ELU networks are among the top 10 reported CIFAR-10 results and yield the best published result on CIFAR-100, without resorting to multi-view evaluation or model averaging. On ImageNet, ELU networks considerably speed up learning compared to a ReLU network with the same architecture, obtaining less than 10\% classification error for a single crop, single model network.},
	urldate = {2016-12-21},
	booktitle = {{ArXiv} e-prints},
	author = {Clevert, Djork-Arné and Unterthiner, Thomas and Hochreiter, Sepp},
	year = {2016},
	keywords = {Computer Science - Learning},
	pages = {arXiv:1511.07289}
}

@inproceedings{sak_fast_2015,
	title = {Fast and {Accurate} {Recurrent} {Neural} {Network} {Acoustic} {Models} for {Speech} {Recognition}},
	url = {http://arxiv.org/abs/1507.06947},
	abstract = {We have recently shown that deep Long Short-Term Memory (LSTM) recurrent neural networks (RNNs) outperform feed forward deep neural networks (DNNs) as acoustic models for speech recognition. More recently, we have shown that the performance of sequence trained context dependent (CD) hidden Markov model (HMM) acoustic models using such LSTM RNNs can be equaled by sequence trained phone models initialized with connectionist temporal classification (CTC). In this paper, we present techniques that further improve performance of LSTM RNN acoustic models for large vocabulary speech recognition. We show that frame stacking and reduced frame rate lead to more accurate models and faster decoding. CD phone modeling leads to further improvements. We also present initial results for LSTM RNN models outputting words directly.},
	urldate = {2016-12-21},
	booktitle = {{arXiv}:1507.06947 [cs, stat]},
	author = {Sak, Haşim and Senior, Andrew and Rao, Kanishka and Beaufays, Françoise},
	month = jul,
	year = {2015},
	note = {arXiv: 1507.06947},
	keywords = {Computer Science - Computation and Language, Computer Science - Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning},
	annote = {Comment: To be published in the INTERSPEECH 2015 proceedings}
}

@book{goodfellow_deep_2016,
	title = {Deep {Learning}},
	publisher = {MIT Press},
	author = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
	year = {2016},
	note = {http://www.deeplearningbook.org}
}

@article{montavon_explaining_2017,
	title = {Explaining nonlinear classification decisions with deep {Taylor} decomposition},
	volume = {65},
	issn = {0031-3203},
	url = {http://www.sciencedirect.com/science/article/pii/S0031320316303582},
	doi = {10.1016/j.patcog.2016.11.008},
	abstract = {Nonlinear methods such as Deep Neural Networks (DNNs) are the gold standard for various challenging machine learning problems such as image recognition. Although these methods perform impressively well, they have a significant disadvantage, the lack of transparency, limiting the interpretability of the solution and thus the scope of application in practice. Especially DNNs act as black boxes due to their multilayer nonlinear structure. In this paper we introduce a novel methodology for interpreting generic multilayer neural networks by decomposing the network classification decision into contributions of its input elements. Although our focus is on image classification, the method is applicable to a broad set of input data, learning tasks and network architectures. Our method called deep Taylor decomposition efficiently utilizes the structure of the network by backpropagating the explanations from the output to the input layer. We evaluate the proposed method empirically on the MNIST and ILSVRC data sets.},
	urldate = {2017-01-17},
	journal = {Pattern Recognition},
	author = {Montavon, Grégoire and Lapuschkin, Sebastian and Binder, Alexander and Samek, Wojciech and Müller, Klaus-Robert},
	month = may,
	year = {2017},
	keywords = {deep neural networks, Heatmapping, Image recognition, Relevance propagation, Taylor decomposition},
	pages = {211--222}
}

@article{silver_mastering_2016,
	title = {Mastering the game of {Go} with deep neural networks and tree search},
	volume = {529},
	copyright = {© 2016 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	issn = {0028-0836},
	url = {http://www.nature.com/nature/journal/v529/n7587/full/nature16961.html},
	doi = {10.1038/nature16961},
	abstract = {The game of Go has long been viewed as the most challenging of classic games for artificial intelligence owing to its enormous search space and the difficulty of evaluating board positions and moves. Here we introduce a new approach to computer Go that uses ‘value networks’ to evaluate board positions and ‘policy networks’ to select moves. These deep neural networks are trained by a novel combination of supervised learning from human expert games, and reinforcement learning from games of self-play. Without any lookahead search, the neural networks play Go at the level of state-of-the-art Monte Carlo tree search programs that simulate thousands of random games of self-play. We also introduce a new search algorithm that combines Monte Carlo simulation with value and policy networks. Using this search algorithm, our program AlphaGo achieved a 99.8\% winning rate against other Go programs, and defeated the human European Go champion by 5 games to 0. This is the first time that a computer program has defeated a human professional player in the full-sized game of Go, a feat previously thought to be at least a decade away.},
	language = {en},
	number = {7587},
	urldate = {2016-12-21},
	journal = {Nature},
	author = {Silver, David and Huang, Aja and Maddison, Chris J. and Guez, Arthur and Sifre, Laurent and van den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and Dieleman, Sander and Grewe, Dominik and Nham, John and Kalchbrenner, Nal and Sutskever, Ilya and Lillicrap, Timothy and Leach, Madeleine and Kavukcuoglu, Koray and Graepel, Thore and Hassabis, Demis},
	month = jan,
	year = {2016},
	keywords = {Computational science, Computer science, Reward},
	pages = {484--489}
}

@article{sun_remembered_2016,
	title = {Remembered or {Forgotten}?—{An} {EEG}-{Based} {Computational} {Prediction} {Approach}},
	volume = {11},
	issn = {1932-6203},
	shorttitle = {Remembered or {Forgotten}?},
	url = {http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0167497},
	doi = {10.1371/journal.pone.0167497},
	abstract = {Prediction of memory performance (remembered or forgotten) has various potential applications not only for knowledge learning but also for disease diagnosis. Recently, subsequent memory effects (SMEs)—the statistical differences in electroencephalography (EEG) signals before or during learning between subsequently remembered and forgotten events—have been found. This finding indicates that EEG signals convey the information relevant to memory performance. In this paper, based on SMEs we propose a computational approach to predict memory performance of an event from EEG signals. We devise a convolutional neural network for EEG, called ConvEEGNN, to predict subsequently remembered and forgotten events from EEG recorded during memory process. With the ConvEEGNN, prediction of memory performance can be achieved by integrating two main stages: feature extraction and classification. To verify the proposed approach, we employ an auditory memory task to collect EEG signals from scalp electrodes. For ConvEEGNN, the average prediction accuracy was 72.07\% by using EEG data from pre-stimulus and during-stimulus periods, outperforming other approaches. It was observed that signals from pre-stimulus period and those from during-stimulus period had comparable contributions to memory performance. Furthermore, the connection weights of ConvEEGNN network can reveal prominent channels, which are consistent with the distribution of SME studied previously.},
	number = {12},
	urldate = {2017-02-14},
	journal = {PLOS ONE},
	author = {Sun, Xuyun and Qian, Cunle and Chen, Zhongqin and Wu, Zhaohui and Luo, Benyan and Pan, Gang},
	month = dec,
	year = {2016},
	keywords = {convolution, electroencephalography, Event-related potentials, Kernel methods, Learning, Memory, Neurons, Support vector machines},
	pages = {e0167497}
}

@article{darvas_high_2010,
	title = {High gamma mapping using {EEG}},
	volume = {49},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811909009513},
	doi = {10.1016/j.neuroimage.2009.08.041},
	abstract = {High gamma (HG) power changes during motor activity, especially at frequencies above 70 Hz, play an important role in functional cortical mapping and as control signals for BCI (brain–computer interface) applications. Most studies of HG activity have used ECoG (electrocorticography) which provides high-quality spatially localized signals, but is an invasive method. Recent studies have shown that non-invasive modalities such as EEG and MEG can also detect task-related HG power changes. We show here that a 27 channel EEG (electroencephalography) montage provides high-quality spatially localized signals non-invasively for HG frequencies ranging from 83 to 101 Hz. We used a generic head model, a weighted minimum norm least squares (MNLS) inverse method, and a self-paced finger movement paradigm. The use of an inverse method enables us to map the EEG onto a generic cortex model. We find the HG activity during the task to be well localized in the contralateral motor area. We find HG power increases prior to finger movement, with average latencies of 462 ms and 82 ms before EMG (electromyogram) onset. We also find significant phase-locking between contra- and ipsilateral motor areas over a similar HG frequency range; here the synchronization onset precedes the EMG by 400 ms. We also compare our results to ECoG data from a similar paradigm and find EEG mapping and ECoG in good agreement. Our findings demonstrate that mapped EEG provides information on two important parameters for functional mapping and BCI which are usually only found in HG of ECoG signals: spatially localized power increases and bihemispheric phase-locking.},
	number = {1},
	urldate = {2017-01-10},
	journal = {NeuroImage},
	author = {Darvas, F. and Scherer, R. and Ojemann, J. G. and Rao, R. P. and Miller, K. J. and Sorensen, L. B.},
	month = jan,
	year = {2010},
	keywords = {BCI, EEG, High gamma, Motor Cortex, Synchronization},
	pages = {930--938}
}

@article{monto_very_2008,
	title = {Very slow {EEG} fluctuations predict the dynamics of stimulus detection and oscillation amplitudes in humans},
	volume = {28},
	url = {http://www.jneurosci.org/content/28/33/8268.short},
	number = {33},
	urldate = {2017-01-09},
	journal = {The Journal of neuroscience},
	author = {Monto, Simo and Palva, Satu and Voipio, Juha and Palva, J. Matias},
	year = {2008},
	pages = {8268--8272}
}

@article{wentland_dynamics_2009,
	title = {Dynamics of movement related high gamma band amplitude modulations in the human electrocorticogram},
	author = {Wentland, Johanna and Kern, Markus and Zapf, Marc Patrick Hans and Mutschler, Isabella and Aertsen, Ad and Schulze-Bonhage, Andreas and Ball, Tonio},
	year = {2009}
}

@inproceedings{stober_learning_2016,
	title = {Learning {Discriminative} {Features} from {Electroencephalography} {Recordings} by {Encoding} {Similarity} {Constraints}},
	doi = {10.12751/nncn.bc2016.0223},
	booktitle = {Bernstein {Conference} 2016},
	author = {Stober, Sebastian},
	year = {2016}
}

@inproceedings{salimans_improved_2016,
	title = {Improved techniques for training gans},
	url = {http://papers.nips.cc/paper/6124-improved-techniques-for-training-gans.pdf},
	urldate = {2017-04-24},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Salimans, Tim and Goodfellow, Ian and Zaremba, Wojciech and Cheung, Vicki and Radford, Alec and Chen, Xi},
	year = {2016},
	pages = {2226--2234}
}

@article{benjamini_controlling_1995,
	title = {Controlling the {False} {Discovery} {Rate}: {A} {Practical} and {Powerful} {Approach} to {Multiple} {Testing}},
	volume = {57},
	issn = {0035-9246},
	shorttitle = {Controlling the {False} {Discovery} {Rate}},
	url = {http://www.jstor.org/stable/2346101},
	abstract = {The common approach to the multiplicity problem calls for controlling the familywise error rate (FWER). This approach, though, has faults, and we point out a few. A different approach to problems of multiple significance testing is presented. It calls for controlling the expected proportion of falsely rejected hypotheses-the false discovery rate. This error rate is equivalent to the FWER when all hypotheses are true but is smaller otherwise. Therefore, in problems where the control of the false discovery rate rather than that of the FWER is desired, there is potential for a gain in power. A simple sequential Bonferroni-type procedure is proved to control the false discovery rate for independent test statistics, and a simulation study shows that the gain in power is substantial. The use of the new procedure and the appropriateness of the criterion are illustrated with examples.},
	number = {1},
	urldate = {2017-05-24},
	journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
	author = {Benjamini, Yoav and Hochberg, Yosef},
	year = {1995},
	pages = {289--300}
}

@inproceedings{sainath_learning_2015,
	title = {Learning the speech front-end with raw waveform {CLDNNs}},
	url = {http://www.ee.columbia.edu/~ronw/pubs/interspeech2015-waveform_cldnn.pdf},
	urldate = {2017-05-29},
	booktitle = {Sixteenth {Annual} {Conference} of the {International} {Speech} {Communication} {Association}},
	author = {Sainath, Tara N. and Weiss, Ron J. and Senior, Andrew and Wilson, Kevin W. and Vinyals, Oriol},
	year = {2015},
	file = {[PDF] columbia.edu:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/QHJ4P3IE/Sainath et al. - 2015 - Learning the speech front-end with raw waveform CL.pdf:application/pdf}
}

@inproceedings{nguyen_deep_2015,
	title = {Deep neural networks are easily fooled: {High} confidence predictions for unrecognizable images},
	shorttitle = {Deep neural networks are easily fooled},
	url = {http://www.cv-foundation.org/openaccess/content_cvpr_2015/html/Nguyen_Deep_Neural_Networks_2015_CVPR_paper.html},
	urldate = {2017-05-30},
	booktitle = {Proceedings of the {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}},
	author = {Nguyen, Anh and Yosinski, Jason and Clune, Jeff},
	year = {2015},
	pages = {427--436},
	file = {[PDF] cv-foundation.org:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/FKDU2ECH/Nguyen et al. - 2015 - Deep neural networks are easily fooled High confi.pdf:application/pdf;Snapshot:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/MFIIDQBM/Nguyen_Deep_Neural_Networks_2015_CVPR_paper.html:text/html}
}

@article{daly_braincomputer_2008,
	title = {Brain–computer interfaces in neurological rehabilitation},
	volume = {7},
	issn = {1474-4422},
	url = {http://www.sciencedirect.com/science/article/pii/S1474442208702230},
	doi = {10.1016/S1474-4422(08)70223-0},
	abstract = {Summary
Recent advances in analysis of brain signals, training patients to control these signals, and improved computing capabilities have enabled people with severe motor disabilities to use their brain signals for communication and control of objects in their environment, thereby bypassing their impaired neuromuscular system. Non-invasive, electroencephalogram (EEG)-based brain–computer interface (BCI) technologies can be used to control a computer cursor or a limb orthosis, for word processing and accessing the internet, and for other functions such as environmental control or entertainment. By re-establishing some independence, BCI technologies can substantially improve the lives of people with devastating neurological disorders such as advanced amyotrophic lateral sclerosis. BCI technology might also restore more effective motor control to people after stroke or other traumatic brain disorders by helping to guide activity-dependent brain plasticity by use of EEG brain signals to indicate to the patient the current state of brain activity and to enable the user to subsequently lower abnormal activity. Alternatively, by use of brain signals to supplement impaired muscle control, BCIs might increase the efficacy of a rehabilitation protocol and thus improve muscle control for the patient.},
	number = {11},
	urldate = {2017-05-30},
	journal = {The Lancet Neurology},
	author = {Daly, Janis J and Wolpaw, Jonathan R},
	month = nov,
	year = {2008},
	pages = {1032--1043},
	file = {ScienceDirect Full Text PDF:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/J42MAUD6/Daly and Wolpaw - 2008 - Brain–computer interfaces in neurological rehabili.pdf:application/pdf;ScienceDirect Snapshot:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/E59X9HEG/S1474442208702230.html:text/html}
}

@article{van_dokkum_brain_2015,
	title = {Brain computer interfaces for neurorehabilitation – its current status as a rehabilitation strategy post-stroke},
	volume = {58},
	issn = {1877-0657},
	url = {http://www.sciencedirect.com/science/article/pii/S1877065714018338},
	doi = {10.1016/j.rehab.2014.09.016},
	abstract = {The idea of using brain computer interfaces (BCI) for rehabilitation emerged relatively recently. Basically, BCI for neurorehabilitation involves the recording and decoding of local brain signals generated by the patient, as he/her tries to perform a particular task (even if imperfect), or during a mental imagery task. The main objective is to promote the recruitment of selected brain areas involved and to facilitate neural plasticity. The recorded signal can be used in several ways: (i) to objectify and strengthen motor imagery-based training, by providing the patient feedback on the imagined motor task, for example, in a virtual environment; (ii) to generate a desired motor task via functional electrical stimulation or rehabilitative robotic orthoses attached to the patient's limb – encouraging and optimizing task execution as well as “closing” the disrupted sensorimotor loop by giving the patient the appropriate sensory feedback; (iii) to understand cerebral reorganizations after lesion, in order to influence or even quantify plasticity-induced changes in brain networks. For example, applying cerebral stimulation to re-equilibrate inter-hemispheric imbalance as shown by functional recording of brain activity during movement may help recovery. Its potential usefulness for a patient population has been demonstrated on various levels and its diverseness in interface applications makes it adaptable to a large population. The position and status of these very new rehabilitation systems should now be considered with respect to our current and more or less validated traditional methods, as well as in the light of the wide range of possible brain damage. The heterogeneity in post-damage expression inevitably complicates the decoding of brain signals and thus their use in pathological conditions, asking for controlled clinical trials.},
	number = {1},
	urldate = {2017-05-30},
	journal = {Annals of Physical and Rehabilitation Medicine},
	author = {van Dokkum, L. E. H. and Ward, T. and Laffont, I.},
	month = feb,
	year = {2015},
	keywords = {Brain computer interfaces, Brain signal, Mental imagery, Neurorehabilitation, Stroke},
	pages = {3--8},
	file = {ScienceDirect Full Text PDF:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/AMQ2QI6Q/van Dokkum et al. - 2015 - Brain computer interfaces for neurorehabilitation .pdf:application/pdf;ScienceDirect Snapshot:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/88PZ9TEW/S1877065714018338.html:text/html}
}

@article{leeb_bci_2008,
	title = {{BCI} {Competition} 2008–{Graz} data set {B}},
	journal = {Graz University of Technology, Austria},
	author = {Leeb, R and Brunner, C and Müller-Putz, GR and Schlögl, A and Pfurtscheller, G},
	year = {2008}
}

@article{georgopoulos_neuronal_1986,
	title = {Neuronal population coding of movement direction},
	volume = {233},
	copyright = {© 1986},
	issn = {0036-8075, 1095-9203},
	url = {http://science.sciencemag.org/content/233/4771/1416},
	doi = {10.1126/science.3749885},
	abstract = {Although individual neurons in the arm area of the primate motor cortex are only broadly tuned to a particular direction in three-dimensional space, the animal can very precisely control the movement of its arm. The direction of movement was found to be uniquely predicted by the action of a population of motor cortical neurons. When individual cells were represented as vectors that make weighted contributions along the axis of their preferred direction (according to changes in their activity during the movement under consideration) the resulting vector sum of all cell vectors (population vector) was in a direction congruent with the direction of movement. This population vector can be monitored during various tasks, and similar measures in other neuronal populations could be of heuristic value where there is a neural representation of variables with vectorial attributes.},
	language = {en},
	number = {4771},
	urldate = {2017-05-30},
	journal = {Science},
	author = {Georgopoulos, A. P. and Schwartz, A. B. and Kettner, R. E.},
	month = sep,
	year = {1986},
	pmid = {3749885},
	pages = {1416--1419},
	file = {Full Text PDF:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/HTWT3BGC/Georgopoulos et al. - 1986 - Neuronal population coding of movement direction.pdf:application/pdf;Snapshot:/home/osboxes/firefox-portable/linux_portable_firefox/profilordner/zotero/storage/UZDI4UWE/1416.html:text/html}
}